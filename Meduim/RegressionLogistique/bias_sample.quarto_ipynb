{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \" Sampling Bias and Class Imbalance in Maximum-likelihood Logistic Regression\"\n",
        "sidebar: auto\n",
        "author:\n",
        "  - Jumbong Junior \n",
        "categories: [article]\n",
        "tags: [Bias, Sampling, Class Imbalance, Logistic Regression, AUC, Precision, Recall, F1-score, Monte-Carlo Simulation, Maximum-likelihood Logistic Regression,python]\n",
        "\n",
        "title-block-banner: false\n",
        "format: \n",
        "  html: \n",
        "    mainfont: Times New Roman\n",
        "    fontsize: 16pt\n",
        "\n",
        "jupyter: python3\n",
        "        \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Introduction \n",
        "\n",
        "In this article, the impact of sampling bias (sample dataset distribution different from the population distribution) \n",
        "and class imbalance on logistic regression models is explored. We hypothesize that the predictive performance of a logistic regression model is related to the sampling bias associated with the data and it has a performance advantage when the data is balanced. The hypothesis is testing with two simulated datasets : a balanced dataset (50:50) and an imbalanced dataset (80:20).  Each dataset will be sampled to produce samples with the following distribution : 50:50, 60:40, 70:30, 80:20, 90:10, 95:5, 99:1. \n",
        "\n",
        "The performance of the logistic regression model will be evaluated using the Area Under the Curve (AUC), Area Under the Precision-Recall Curve (AU-PCR), Precision, Recall, and F1-score. \n",
        "\n",
        "Monte-Carlo simulations will be carried out to evaluate the distribution of the performance metrics for each of the samples and insure the robustness of the results.\n",
        "\n",
        "This study gives three main results :\n",
        "\n",
        "A. The predicted probability using a maximum logistic regression (MLLR) model is closest to the true probability when the sample has the same class distribution as the original population. Therefore, in probabilistic modeling with MLLR, it is important to create a sample that matches the class distribution of the original population rather than ensuring equal class sampling, see @fig-plotsamplecasea and @fig-plotsamplecaseb.\n",
        "\n",
        "B. AUC measures how well probabilistic classifiers predict. It ranges from 0.5 (random) to 1 (perfect). AUC shows class separability regardless of class imbalance or sampling bias, see @fig-plot_metrics_a and @fig-plot_metrics_b.\n",
        "\n",
        "C. We recommend AUC to evaluate class separability in probabilistic models. To analyse sampling biais as well as the difference in the true and predicted probabilities, AUC-PR, Recall, precision and f1-score can be used as indicator.\n",
        "\n",
        "The protocol of this paper is as follows. First, we describe how to simulate data. Next, we present the methodology. Finally, we present the results.\n",
        "\n",
        "\n",
        "# 1. Simulated Data Generation\n",
        "\n",
        "\n",
        "Many authors document that, for logistic regression , the probability distribution of the dependent variable is assumed to be Bernoulli and the mass function f is given by :\n",
        "\n",
        "$$\n",
        "f(y, x, \\alpha, \\beta) = p(x, \\alpha, \\beta)^y(1-p(x, \\alpha, \\beta))^{1-y}\n",
        "$$\n",
        "\n",
        "where \n",
        "$$\n",
        "p(x, \\alpha, \\beta) = \\frac{\\exp(\\alpha + \\beta x)}{1 + \\exp(\\alpha + \\beta x)} \n",
        "$$\n",
        "\n",
        "and where y is the dependent variable, x is the independent variable, $\\alpha$ and $\\beta$ are the parameters to be estimated using the maximum likelihood method (MLE).\n",
        "\n",
        "For generating the the bernouilli trial y using for a fixed parameter P, we use the following equation :\n",
        "\n",
        "$$\n",
        "y(p) = \n",
        "\\begin{cases}\n",
        "\\text{dummy} \\leftarrow \\mathrm{rnd}(1), \\\\\n",
        "0, & \\text{if dummy} < p, \\\\\n",
        "1, & \\text{otherwise}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where rnd(1) is a random number generator that generates a random number between 0 and 1.\n",
        "\n",
        "The conditional bernouilli trials y are then generated by substituting of $p(x, \\alpha, \\beta)$ :\n",
        "\n",
        "$$\n",
        "y(x, \\alpha, \\beta) =\n",
        "\\begin{cases}\n",
        "0, & \\text{if rnd(1)} < p(x, \\alpha, \\beta), \\\\\n",
        "1, & \\text{otherwise}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "In order to generate the data, the following steps will be respected : \n",
        "- Generate x the predictor variable from a uniform distribution, which ranges from 0 to 10.\n",
        "- Choose the parameters $\\alpha$ and $\\beta$, which will help to genererate the distribution of the dependent variable y.\n",
        "- Generate the dependent variable y using the logistic function $p(x, \\alpha, \\beta)$.\n",
        "\n",
        "\n",
        "## 1.1 Numerical Approach to determine parameters $\\alpha$ and $\\beta$ knowing the proportion of y=1.\n",
        "\n",
        "The numerical approach consists to determine, for a given value of $\\alpha =-10$, the value of $\\beta$ that will allow to have a proportion of y=1 equal to 0.5 in the case of a balanced dataset and 0.2 in the case of an imbalanced dataset.\n",
        "\n",
        "The optimization problem can be formulated as follows :\n",
        "\n",
        "\n",
        "$$\n",
        "\\min_{\\beta} \\left( \\text{prop} - \\frac{1}{n}\\sum_{i=1}^{n} \\frac{\\exp(\\alpha + \\beta x_i)}{1 + \\exp(\\alpha + \\beta x_i)} \\right)^2 \n",
        "$$\n",
        "\n",
        "where $\\text{prop}$ is the proportion of y=1 in the dataset, $x_i$ is the predictor variable, and $n$ is the number of observations.\n",
        "\n",
        "The optimization problem can be solved using the `scipy.optimize.minimize` function with the Nelder-Mead method.\n"
      ],
      "id": "3e8d0156"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "# Define the logistic function\n",
        "def logistic_function(x, alpha, beta):\n",
        "    return 1 / (1 + np.exp(-(alpha + beta * x)))\n",
        "\n",
        "# Objective function: minimize the squared difference between mean(pi) and 0.2\n",
        "\n",
        "def objective(alpha, prop, beta, n):\n",
        "    x = np.random.uniform(0, 10, n)  # Simulate x values\n",
        "    pi = logistic_function(x, alpha, beta)\n",
        "    return (np.mean(pi) - 0.2)**2  # Target mean(pi) = 0.2\n",
        "\n",
        "# Initial guesses for alpha and beta\n",
        "\n",
        "initial_params = [0]\n",
        "\n",
        "# Optimize alpha and beta\n",
        "result = minimize(lambda params: objective(-10, 0.2, params, 50000), initial_params, method='Nelder-Mead')\n",
        "\n",
        "# Get optimized alpha and beta\n",
        "\n",
        "beta_opt = result.x\n",
        "print(f\"Optimized alpha: {-10}, beta: {beta_opt}\")\n",
        "\n",
        "# Generate x and simulate y\n",
        "x = np.random.uniform(0, 10, 1000)\n",
        "pi = logistic_function(x, -10, beta_opt)\n",
        "y = (np.random.uniform(0, 1, 1000) < pi).astype(int)\n",
        "\n",
        "# Verify proportions\n",
        "y_mean = np.mean(y)\n",
        "print(f\"Proportion of y=1: {y_mean:.2f}, y=0: {1-y_mean:.2f}\")"
      ],
      "id": "fd5b2aa7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulated Data Generation with $\\alpha = -10$ \n",
        "\n",
        "\n",
        "\n",
        "Let's consider two cases :\n",
        "\n",
        "  - Case A : A balanced dataset with 50:50 distribution of y=0 and y=1.\n",
        "  - Case B : An imbalanced dataset with 80:20 distribution of y=0 and y=1.\n",
        "\n",
        "The code below generates the data for the two cases and plots the proportion of y=1 as a function of beta.\n",
        "\n",
        "The graph @fig-simulate_case_data, both the datasets have a total of 50,000 events, with the Case A dataset having a class distribution of about 50:50 and Case B dataset having a class distribution of about 80:20.\n"
      ],
      "id": "efcb92d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-simulate_case_data\n",
        "#| fig-cap: 'Simulated data from logistic model with alpha=-10, beta=2 and alpha=-10, beta=beta_opt'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Inputs : n_events, alpha, beta, random_state\n",
        "# Outputs : x, y, prop_y0, prop_y1\n",
        "# Objective : Simulate data from a logistic model with given alpha, beta.\n",
        "\n",
        "def simulate_case_data(n_events, alpha, beta, random_state=42):\n",
        "    \"\"\"\n",
        "    Simulate data from a logistic model with given alpha, beta.\n",
        "    \n",
        "    x ~ Uniform(0, 10), y ~ Bernoulli(pi(x)), \n",
        "    where pi(x) = exp(alpha + beta*x) / (1 + exp(alpha + beta*x)).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_events : int\n",
        "        Number of observations (events) to generate.\n",
        "    alpha : float\n",
        "        Intercept (alpha) for the logistic function.\n",
        "    beta : float\n",
        "        Slope (beta) for the logistic function.\n",
        "    random_state : int\n",
        "        Seed for reproducibility.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x : np.ndarray of shape (n_events,)\n",
        "        Predictor values sampled from Uniform(0,10).\n",
        "    y : np.ndarray of shape (n_events,)\n",
        "        Binary outcomes (0 or 1) from Bernoulli trials.\n",
        "    prop_y0 : float\n",
        "        Proportion of y==0 in the dataset.\n",
        "    prop_y1 : float\n",
        "        Proportion of y==1 in the dataset.\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    \n",
        "    # 1) Draw x from Uniform(0,10)\n",
        "    x = np.random.uniform(0, 10, size=n_events)\n",
        "    \n",
        "    # 2) Compute pi(x, alpha, beta)\n",
        "    logit = alpha + beta*x\n",
        "    pi = np.exp(logit) / (1.0 + np.exp(logit))\n",
        "    \n",
        "    # 3) Generate y via Bernoulli(pi)\n",
        "    dummy = np.random.rand(n_events)\n",
        "    y = (dummy < pi).astype(int)\n",
        "    \n",
        "    # 4) Calculate proportions of 0 and 1\n",
        "    prop_y0 = np.mean(y == 0)\n",
        "    prop_y1 = np.mean(y == 1)\n",
        "    \n",
        "    return x, y, prop_y0, prop_y1\n",
        "\n",
        "# ---------------- Example usage ----------------\n",
        "\n",
        "\n",
        "# Case A: alpha=-10, beta=2 --> expected ~50:50 distribution\n",
        "xA, yA, p0_A, p1_A = simulate_case_data(\n",
        "    n_events=50000,\n",
        "    alpha=-10,\n",
        "    beta=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Case B: alpha=-10, beta=3.85 --> expected ~80:20 distribution\n",
        "xB, yB, p0_B, p1_B = simulate_case_data(\n",
        "    n_events=50000,\n",
        "    alpha=-10,\n",
        "    beta=beta_opt,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Verify proportions\n",
        "\n",
        "# Suppose p0_A, p1_A, p0_B, p1_B are already defined\n",
        "# e.g., p0_A = 0.50; p1_A = 0.50; p0_B = 0.80; p1_B = 0.20\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(5, 3))  # 1 ligne, 2 colonnes\n",
        "\n",
        "colors = ['royalblue', 'darkorange']  # Couleurs distinctes pour y=0 et y=1\n",
        "\n",
        "# -------- LEFT SUBPLOT: Case A -----------\n",
        "ax1 = axes[0]\n",
        "bar_container_A = ax1.bar(['y=0', 'y=1'], [p0_A, p1_A], color=colors)\n",
        "ax1.set_title('Case A')\n",
        "ax1.set_xlabel('Classe')\n",
        "ax1.set_ylabel('Proportion')\n",
        "ax1.set_ylim([0, 1])  # Echelle de 0 à 1\n",
        "ax1.bar_label(bar_container_A, fmt='%.2f')\n",
        "\n",
        "# -------- RIGHT SUBPLOT: Case B -----------\n",
        "ax2 = axes[1]\n",
        "bar_container_B = ax2.bar(['y=0', 'y=1'], [p0_B, p1_B], color=colors)\n",
        "ax2.set_title('Case B')\n",
        "ax2.set_xlabel('Classe')\n",
        "ax2.set_ylabel('Proportion')\n",
        "ax2.set_ylim([0, 1])\n",
        "ax2.bar_label(bar_container_B, fmt='%.2f')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-simulate_case_data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The theoretical properties of the simulated datasets are presented in @fig-plot_logit_vs_x. The left subplot shows the probability of y=1 as a function of x for Case A and Case B. The right subplot shows the logit function as a function of x for Case A and Case B. The logit function is given by $\\alpha + \\beta x$.\n"
      ],
      "id": "bec9e043"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-plot_logit_vs_x\n",
        "#| fig-cap: Logit vs. x for Case A and Case B\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def logistic(x, alpha, beta):\n",
        "    return np.exp(alpha + beta*x) / (1.0 + np.exp(alpha + beta*x))\n",
        "\n",
        "x_values = np.linspace(0, 10, 50000)\n",
        "\n",
        "# Case A\n",
        "alpha_A, beta_A = -10, 2\n",
        "pi_A = logistic(x_values, alpha_A, beta_A)\n",
        "logit_A = alpha_A + beta_A * x_values\n",
        "\n",
        "# Case B\n",
        "alpha_B, beta_B = -10, beta_opt\n",
        "pi_B = logistic(x_values, alpha_B, beta_B)\n",
        "logit_B = alpha_B + beta_B * x_values\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(5, 5))  # Taille un peu plus grande\n",
        "\n",
        "# (a) Probability vs. x for Case A\n",
        "axes[0, 0].plot(x_values, pi_A, color='b', label='Probability')\n",
        "axes[0, 0].set_title('Case A: Probability vs. x')\n",
        "axes[0, 0].set_xlabel('x')\n",
        "axes[0, 0].set_ylabel(r'$\\pi(x,\\alpha,\\beta)$')\n",
        "axes[0, 0].axhline(y=0.5, color='k', linestyle='--', label='y=0.5')\n",
        "axes[0, 0].axvline(x=5, color='gray', linestyle='--', label='x=5')\n",
        "axes[0, 0].set_ylim([0,1])  # Probabilité entre 0 et 1\n",
        "axes[0, 0].legend(loc='best')\n",
        "\n",
        "# (b) Logit vs. x for Case A\n",
        "axes[0, 1].plot(x_values, logit_A, color='b', label='Logit')\n",
        "axes[0, 1].set_title('Case A: Logit vs. x')\n",
        "axes[0, 1].set_xlabel('x')\n",
        "axes[0, 1].set_ylabel(r'$\\alpha + \\beta x$')\n",
        "axes[0, 1].legend(loc='best')\n",
        "\n",
        "# (c) Probability vs. x for Case B\n",
        "axes[1, 0].plot(x_values, pi_B, color='r', label='Probability')\n",
        "axes[1, 0].set_title('Case B: Probability vs. x')\n",
        "axes[1, 0].set_xlabel('x')\n",
        "axes[1, 0].set_ylabel(r'$\\pi(x,\\alpha,\\beta)$')\n",
        "axes[1, 0].axhline(y=0.2, color='k', linestyle='--', label='y=0.2')\n",
        "axes[1, 0].axvline(x=5, color='gray', linestyle='--', label='x=5')\n",
        "axes[1, 0].set_ylim([0,1])\n",
        "axes[1, 0].legend(loc='best')\n",
        "\n",
        "# (d) Logit vs. x for Case B\n",
        "axes[1, 1].plot(x_values, logit_B, color='r', label='Logit')\n",
        "axes[1, 1].set_title('Case B: Logit vs. x')\n",
        "axes[1, 1].set_xlabel('x')\n",
        "axes[1, 1].set_ylabel(r'$\\alpha + \\beta x$')\n",
        "axes[1, 1].legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-plot_logit_vs_x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Methodology\n",
        "\n",
        "To test the hypothesis that sampling bias controls the optimal class balance required for the best predictive performance of maximum-likelihood logistic regression, samples will be drawn from the two datasets (Case A and Case B) with varying class distributions. The class distributions will be as follows: 50:50, 60:40, 70:30, 80:20, 90:10, 95:5, and 99:1, respectively.\n",
        "\n",
        "For each each class sample distribution, 1000 monte-carlo simulations will be carried out and for each simulation the maximum-likelihood logistic regression model will be fitted. The predictive performance of the model will be evaluated using AUC(Area Under the Curve), AU-PCR(Area Under the Precision-Recall Curve), Precision, Recall, F1-score. Those metrics are computed from elements of the confusion matrix : True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN). The confusion matrix is the matrix with the observed in columns and the predicted in rows. \n",
        "\n",
        "# Results\n",
        "\n",
        "## Case A : Balanced Dataset\n",
        "\n",
        "The Case A dataset has a balanced class distribution of 50:50. This will be the true distribution of the dataset. Eight random samples will be extracted from the Case A population with varying class distributions of 50:50, 60:40, 70:30, 80:20, 90:10, 95:5, and 99:1. \n",
        "A sample with a class distributiion of 60:40 from the Case A is referred as $A_{60:40}$.\n",
        "The sample size for each of the eight samples is determined by fixing the lenght of the majority class (class 0) at 5000. In order word, for the $A_{60:40}$ sample, the number of observations in class 0 is 5000 and the number of observations in class 1 is :\n",
        "\n",
        "$$\n",
        "\\text{Number of observations in class 1} = \\frac{40}{60} \\times 5000 = 3333\n",
        "$$\n",
        "\n",
        "### Eight sub-samples generated from Case A.\n",
        "\n",
        "The code below generates the eight sub-samples from the Case A dataset with varying class distributions. \n"
      ],
      "id": "b5eb5883"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_subsample_fixed_majority(\n",
        "    X, y, \n",
        "    fraction_class0=0.6,  # e.g., 0.6 => 60:40\n",
        "    majority_class0_size=5000,\n",
        "    random_state=42\n",
        "):\n",
        "    \"\"\"\n",
        "    Extract a subsample where the number of class-0 = majority_class0_size,\n",
        "    and overall fraction of class-0 is fraction_class0.\n",
        "    \n",
        "    Returns X_sub, y_sub.\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    \n",
        "    # Indices of class 0 and 1 in the population\n",
        "    idx_0 = np.where(y == 0)[0]\n",
        "    idx_1 = np.where(y == 1)[0]\n",
        "    \n",
        "    # We fix #class0 = 5000\n",
        "    n0 = majority_class0_size\n",
        "    \n",
        "    # fraction_class0 = n0 / (n0 + n1) => n1 = n0 * (1 - p)/p\n",
        "    p = fraction_class0\n",
        "    n1 = int(round(n0 * (1 - p) / p))\n",
        "    \n",
        "    chosen_0 = np.random.choice(idx_0, size=n0, replace=False)\n",
        "    chosen_1 = np.random.choice(idx_1, size=n1, replace=False)\n",
        "    \n",
        "    chosen_indices = np.concatenate([chosen_0, chosen_1])\n",
        "    np.random.shuffle(chosen_indices)\n",
        "    \n",
        "    return X[chosen_indices], y[chosen_indices]"
      ],
      "id": "c48e9d4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code below gives examples of generating the eight sub-samples from the Case A dataset with varying class distributions. @fig-plotsamplecasea shows the distribution of the dependent variable y for each of the eight sub-samples.\n"
      ],
      "id": "af50ba70"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig": true
      },
      "source": [
        "#| label: fig-plotsamplecasea\n",
        "#| fig-cap: Distribution of y for Case A sub-samples\n",
        "\n",
        "# Module : Generation\n",
        "# Inputs : fraction_class0 = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99], create_subsample_fixed_majority.\n",
        "# Ourputs : A dictionnarie with keys in fraction_class0 and values a tuple (X_sub, y_sub).\n",
        "\n",
        "fractions_class0 = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.98, 0.99]\n",
        "\n",
        "samples_A = {}\n",
        "for frac0 in fractions_class0:\n",
        "    X_sub, y_sub = create_subsample_fixed_majority(\n",
        "        xA, yA, \n",
        "        fraction_class0=frac0, \n",
        "        majority_class0_size=5000,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Store or process each sample\n",
        "    samples_A[frac0] = (X_sub, y_sub)\n",
        "\n",
        "\n",
        "ffig, axes = plt.subplots(4, 2, figsize=(6, 8))\n",
        "axes = axes.ravel()  # on a maintenant 8 sous-graphiques\n",
        "\n",
        "# 1) Déterminer la fréquence max pour fixer une échelle cohérente\n",
        "all_counts = [np.bincount(y_sub) for _, (_, y_sub) in samples_A.items()]\n",
        "global_max_count = max(counts.max() for counts in all_counts)\n",
        "\n",
        "for i, (label, (X_sub, y_sub)) in enumerate(samples_A.items()):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # 2) Histogramme sur 2 bins => classes 0 et 1\n",
        "    ax.hist(y_sub, bins=[-0.5, 0.5, 1.5],  # histogramme \"catégoriel\"\n",
        "            color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    \n",
        "    # 3) Titre + proportion de y=1\n",
        "    mean_y = np.mean(y_sub)\n",
        "    ax.set_title(f\"{label}:{mean_y:.2f}\", fontsize=9)\n",
        "    \n",
        "    # 4) Ajuster l’axe X pour forcer l’affichage (0,1)\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_xticklabels(['0', '1'], fontsize=8)\n",
        "    \n",
        "    # 5) Limiter l’axe Y pour comparer visuellement entre les sous-figures\n",
        "    ax.set_ylim(0, global_max_count)\n",
        "    \n",
        "    # 6) N’afficher “Frequency” que sur la première colonne\n",
        "    #    pour éviter la répétition\n",
        "    if i % 2 == 0:\n",
        "        ax.set_ylabel('Frequency', fontsize=9)\n",
        "    else:\n",
        "        ax.set_ylabel('')\n",
        "    \n",
        "    # 7) Ajouter un label X plus discret\n",
        "    ax.set_xlabel('y', fontsize=9)\n",
        "    \n",
        "    # 8) Afficher le count exact sur chacune des barres\n",
        "    counts = np.bincount(y_sub)\n",
        "    for j, c in enumerate(counts):\n",
        "        ax.text(j, c + 0.5, str(c), ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "fig-plotsamplecasea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A maximum-likelihood logistic regression model will be fitted to each of the eight sub-samples. A plot of the true $p(x)$ versus the estimated $p(x)$ is presented in @fig-testpa.\n"
      ],
      "id": "cd011e25"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-testpa\n",
        "#| fig-cap: True vs. estimated p(x) for Case A sub-samples\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Inputs : samples_A, fractions_class0\n",
        "# Outputs : fig\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# For illustration, let's create a 2 x 4 grid to show all eight ratio-samples\n",
        "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(6,8))\n",
        "axes = axes.ravel()  # flatten into 1D array [ax0, ax1, ..., ax7]\n",
        "\n",
        "# Hardcode alpha=-10, beta=2 for \"true\" logistic in Case A\n",
        "ALPHA_TRUE = -10\n",
        "BETA_TRUE  = 2\n",
        "\n",
        "for i, (label, (X_sub, y_sub)) in enumerate(samples_A.items()):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # 1) Put the data into a DataFrame for convenience\n",
        "    df_sub = pd.DataFrame({\n",
        "        'X': X_sub,       # predictor\n",
        "        'y': y_sub        # binary outcome\n",
        "    })\n",
        "    \n",
        "    # 2) Add a constant column for the intercept in statsmodels\n",
        "    df_sub = sm.add_constant(df_sub, has_constant='add')  \n",
        "    # Now df_sub has columns ['const', 'X', 'y']\n",
        "    \n",
        "    # 3) Fit the logistic model\n",
        "    model = sm.Logit(df_sub['y'], df_sub[['const', 'X']])\n",
        "    results = model.fit(disp=False)  # disp=False to suppress output\n",
        "    \n",
        "    # 4) Predict the fitted probability\n",
        "    df_sub['pi_pred'] = results.predict(df_sub[['const', 'X']])\n",
        "    \n",
        "    # 5) Compute the \"true\" pi for comparison\n",
        "    df_sub['pi_true'] = logistic(df_sub['X'].values, alpha=ALPHA_TRUE, beta=BETA_TRUE)\n",
        "    \n",
        "    # 6) Plot pi_true vs. pi_pred\n",
        "    ax.scatter(df_sub['pi_true'], df_sub['pi_pred'], \n",
        "               alpha=0.3, s=10, color='blue', edgecolors='none')\n",
        "    # Add a diagonal line for reference\n",
        "    ax.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
        "    # 7) Decorate the subplot\n",
        "    ax.set_xlabel(\"True pi(x)\")\n",
        "    ax.set_ylabel(\"Predicted pi_hat(x)\")\n",
        "    ax.set_title(f\"{label}:{1-label:.2f}\")  # e.g., \"Case A60:40\"\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-testpa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "@fig-testpa shows that the sample (Case $A_{50:50}$) with no class imbalance and sampling bias has the best fit between the true and estimated probabilities. As the class imbalance increases from 60:40 to 99:1, the fit between the true and estimated probabilities deteriorates. To have more confidence in the results, the distribution of the performance metrics for each of the eight sub-samples using monte-carlo simulations will be carried out.  \n",
        "\n",
        "### Distribution of the performance metrics for the eight sub-samples from Case A with monte-carlo simulations.\n",
        "\n",
        "We perform 1000 monte-carlo simulations for each of the eight sub-samples from Case A. For each simulation, we fit a maximum-likelihood logistic regression model and compute the performance metrics : AUC, AU-PCR, Precision, Recall, F1-score. In order words, in the end of this exercise, we will have 1000 values for each of the performance metrics for each of the eight sub-samples. \n",
        "\n",
        "The code below gives the distribution of the performance metrics for each of the eight sub-samples from Case A with monte-carlo simulations.\n"
      ],
      "id": "61bee566"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "def evaluate_model_performance(y_true, y_proba, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Given true labels and predicted probabilities, compute AUC, AU-PRC,\n",
        "    Precision, Recall, and F1 at a chosen threshold.\n",
        "    \"\"\"\n",
        "    # 1) AUC (ROC)\n",
        "    auc = roc_auc_score(y_true, y_proba)\n",
        "    \n",
        "    # 2) AU-PRC (average precision)\n",
        "    auprc = average_precision_score(y_true, y_proba)\n",
        "    \n",
        "    # 3) Convert probas -> hard predictions\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "    \n",
        "    # 4) Precision, Recall, F1\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    \n",
        "    return auc, auprc, prec, rec, f1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MC_RUNS = 1000\n",
        "SAMPLE_SIZE = 5000  # e.g., majority class size if using a fixed majority approach\n",
        "ratios = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.98, 0.99]\n",
        "results_list = []\n",
        "\n",
        "#for r, (X_sub, y_sub) in samples_A.items():\n",
        "for r in ratios:\n",
        "    for mc_i in range(MC_RUNS):\n",
        "        \n",
        "        \n",
        "        # 2) Split the subsample into train/test\n",
        "        #    stratify ensures class distribution is preserved\n",
        "        X_sub, y_sub = create_subsample_fixed_majority(\n",
        "          xA, yA,\n",
        "          fraction_class0=r,\n",
        "          majority_class0_size=SAMPLE_SIZE,\n",
        "          random_state=None\n",
        "      )\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_sub,\n",
        "            y_sub,\n",
        "            test_size=0.3,\n",
        "            random_state=42,\n",
        "            stratify=y_sub\n",
        "        )\n",
        "        \n",
        "        # Prepare DataFrame for the training set\n",
        "        df_train = pd.DataFrame({'X': X_train, 'y': y_train})\n",
        "        df_train = sm.add_constant(df_train, prepend=True, has_constant='add')  \n",
        "        # => columns: ['const', 'X', 'y']\n",
        "        \n",
        "        # 3) Fit logistic regression on the TRAIN portion\n",
        "        logit_model = sm.Logit(df_train['y'], df_train[['const', 'X']])\n",
        "        result = logit_model.fit(disp=False)\n",
        "        \n",
        "        # 4) Predict probabilities on the TEST portion\n",
        "        df_test = pd.DataFrame({'X': X_test})\n",
        "        df_test = sm.add_constant(df_test, prepend=True, has_constant='add')\n",
        "        \n",
        "        y_proba_test = result.predict(df_test[['const', 'X']])\n",
        "        \n",
        "        # 5) Evaluate performance metrics on the TEST set\n",
        "        auc, auprc, prec, rec, f1 = evaluate_model_performance(y_test, y_proba_test, threshold=0.5)\n",
        "        \n",
        "        # 6) Store results\n",
        "        results_list.append({\n",
        "            'ratio_0': r,\n",
        "            'auc': auc,\n",
        "            'auprc': auprc,\n",
        "            'precision': prec,\n",
        "            'recall': rec,\n",
        "            'f1': f1\n",
        "        })\n",
        "\n",
        "# Convert collected results to a DataFrame\n",
        "df_results_A = pd.DataFrame(results_list)\n",
        "# Compute the mean performance metrics for each ratio\n",
        "df_results_A.groupby('ratio_0').mean()"
      ],
      "id": "ce390c01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mean of the performance metrics for each of the eight sub-samples from Case A is presented in @fig-plot_metrics_a.\n"
      ],
      "id": "a3385b4c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-plot_metrics_a\n",
        "#| fig-cap: Performance metrics Vs. Ratios for Case A\n",
        "\n",
        "# Module : Plotting\n",
        "# Inputs : df_results_A\n",
        "# Outputs : fig showing the performance metrics vs the ratios\n",
        "# Objective : Group data by ratio_0 and plot the performance metrics.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df_grouped_A = df_results_A.groupby('ratio_0').mean().reset_index()\n",
        "metrics = ['auc', 'auprc', 'precision', 'recall', 'f1']\n",
        "colours = ['blue', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "for metric, colour in zip(metrics, colours):\n",
        "    plt.plot(df_grouped_A['ratio_0'], df_grouped_A[metric], label=metric, color=colour, marker='o')\n",
        "\n",
        "# Improve readability with grid and styling\n",
        "plt.xlabel(\"Rate of Y = 0\", fontsize=12, weight='bold')\n",
        "plt.ylabel(\"Mean of Performance Metrics\", fontsize=12, weight='bold')\n",
        "plt.title(\"Mean of Performance Metrics vs Ratios\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(False)\n",
        "plt.legend(title=\"Metrics\", fontsize=10, title_fontsize=12, loc=\"best\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "id": "fig-plot_metrics_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the class imbalance and sampling bias increase, the performance metrics deteriorate except for the AUC metric. It seems that the AUC metric is not sensitive to class imbalance and sampling bias.\n",
        "\n",
        "## Case B : Imbalanced Dataset\n",
        "\n",
        "The Case B dataset has an imbalanced class distribution of 80:20. This will be the true distribution of the dataset. Eight random samples will be extracted from the Case B population with varying class distributions of 50:50, 60:40, 70:30, 80:20, 90:10, 95:5, and 99:1.\n",
        "\n",
        "### Eight sub-samples generated from Case B.\n",
        "\n",
        "The code below generates the eight sub-samples from the Case B dataset with varying class distributions. @fig-plotsamplecaseb shows the distribution of the dependent variable y for each of the eight sub-samples.\n"
      ],
      "id": "05f51130"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-plotsamplecaseb\n",
        "#| fig-cap: Distribution of y for Case B sub-samples\n",
        "\n",
        "\n",
        "# Module : Generation\n",
        "# Inputs : fraction_class0 = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99], create_subsample_fixed_majority.\n",
        "# Ourputs : A dictionnarie with keys in fraction_class0 and values a tuple (X_sub, y_sub).\n",
        "\n",
        "fractions_class0 = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.98, 0.99]\n",
        "\n",
        "samples_B = {}\n",
        "for frac0 in fractions_class0:\n",
        "    X_sub, y_sub = create_subsample_fixed_majority(\n",
        "        xB, yB, \n",
        "        fraction_class0=frac0, \n",
        "        majority_class0_size=5000,\n",
        "        random_state=42\n",
        "    )\n",
        "    # Store or process each sample\n",
        "    samples_B[frac0] = (X_sub, y_sub)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(4, 2, figsize=(6, 8))\n",
        "axes = axes.ravel()  # on a maintenant 8 sous-graphiques\n",
        "\n",
        "# 1) Déterminer la fréquence max pour fixer une échelle cohérente\n",
        "all_counts = [np.bincount(y_sub) for _, (_, y_sub) in samples_B.items()]\n",
        "global_max_count = max(counts.max() for counts in all_counts)\n",
        "\n",
        "for i, (label, (X_sub, y_sub)) in enumerate(samples_B.items()):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # 2) Histogramme sur 2 bins => classes 0 et 1\n",
        "    ax.hist(y_sub, bins=[-0.5, 0.5, 1.5],  # histogramme \"catégoriel\"\n",
        "            color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    \n",
        "    # 3) Titre + proportion de y=1\n",
        "    mean_y = np.mean(y_sub)\n",
        "    ax.set_title(f\"{label}:{mean_y:.2f}\", fontsize=9)\n",
        "    \n",
        "    # 4) Ajuster l’axe X pour forcer l’affichage (0,1)\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_xticklabels(['0', '1'], fontsize=8)\n",
        "    \n",
        "    # 5) Limiter l’axe Y pour comparer visuellement entre les sous-figures\n",
        "    ax.set_ylim(0, global_max_count)\n",
        "    \n",
        "    # 6) N’afficher “Frequency” que sur la première colonne\n",
        "    #    pour éviter la répétition\n",
        "    if i % 2 == 0:\n",
        "        ax.set_ylabel('Frequency', fontsize=9)\n",
        "    else:\n",
        "        ax.set_ylabel('')\n",
        "    \n",
        "    # 7) Ajouter un label X plus discret\n",
        "    ax.set_xlabel('y', fontsize=9)\n",
        "    \n",
        "    # 8) Afficher le count exact sur chacune des barres\n",
        "    counts = np.bincount(y_sub)\n",
        "    for j, c in enumerate(counts):\n",
        "        ax.text(j, c + 0.5, str(c), ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-plotsamplecaseb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A maximum-likelihood logistic regression model will be fitted to each of the eight sub-samples. A plot of the true $p(x)$ versus the estimated $p(x)$ is presented in @fig-plot_true_vs_estimated_p_b.\n"
      ],
      "id": "d4a53aaa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-plot_true_vs_estimated_p_b\n",
        "#| fig-cap: True vs. estimated p(x) for Case B sub-samples\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Inputs : samples_B, fractions_class0\n",
        "# Outputs : fig\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# For illustration, let's create a 2 x 4 grid to show all eight ratio-samples\n",
        "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(6,8))\n",
        "axes = axes.ravel()  # flatten into 1D array [ax0, ax1, ..., ax7]\n",
        "\n",
        "# Hardcode alpha=-10, beta=2 for \"true\" logistic in Case A\n",
        "ALPHA_TRUE = -10\n",
        "BETA_TRUE  = beta_opt\n",
        "print(BETA_TRUE)\n",
        "\n",
        "for i, (label, (X_sub, y_sub)) in enumerate(samples_B.items()):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # 1) Put the data into a DataFrame for convenience\n",
        "    df_sub = pd.DataFrame({\n",
        "        'X': X_sub,       # predictor\n",
        "        'y': y_sub        # binary outcome\n",
        "    })\n",
        "    \n",
        "    # 2) Add a constant column for the intercept in statsmodels\n",
        "    df_sub = sm.add_constant(df_sub, has_constant='add')  \n",
        "    # Now df_sub has columns ['const', 'X', 'y']\n",
        "    \n",
        "    # 3) Fit the logistic model\n",
        "    model = sm.Logit(df_sub['y'], df_sub[['const', 'X']])\n",
        "    results = model.fit(disp=False)  # disp=False to suppress output\n",
        "    \n",
        "    # 4) Predict the fitted probability\n",
        "    df_sub['pi_pred'] = results.predict(df_sub[['const', 'X']])\n",
        "    \n",
        "    # 5) Compute the \"true\" pi for comparison\n",
        "    df_sub['pi_true'] = logistic(df_sub['X'].values, alpha=ALPHA_TRUE, beta=BETA_TRUE)\n",
        "    \n",
        "    \n",
        "    # 6) Plot pi_true vs. pi_pred\n",
        "    ax.scatter(df_sub['pi_true'], df_sub['pi_pred'], \n",
        "               alpha=0.3, s=10, color='blue', edgecolors='none')\n",
        "    # Add a diagonal line for reference\n",
        "    ax.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
        "    # 7) Decorate the subplot\n",
        "    ax.set_xlabel(\"True pi(x)\")\n",
        "    ax.set_ylabel(\"Predicted pi_hat(x)\")\n",
        "    ax.set_title(f\"{label}:{1-label:.2f}\")  # e.g., \"Case A60:40\"\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-plot_true_vs_estimated_p_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, it is evident from @fig-plot_true_vs_estimated_p_b that the sample (Case $B_{50:50}$) with balance class no longer has the best fit between the true and estimated probabilities.\n",
        "\n",
        "The sample (Case $B_{80:20}$) that performs the best does not have the sampling bias because it that case, the class distribution of the sample (80:20) is equal to the class distribution of the population (80:20). Furthermore, as the sample bias increases, the maximum-likelihood logistic regression model's highly under- or overpredicts the probability.\n",
        "\n",
        "When the distribution of the minority in the sample is less than the distribution of the minority in the population, the model underpredicts the probability. Conversely, when the distribution of the minority in the sample is greater than the distribution of the minority in the population, the model overpredicts the probability.\n",
        "\n",
        "### Distribution of the performance metrics for the eight sub-samples from Case B with monte-carlo simulations.\n",
        "\n",
        "We perform 1000 monte-carlo simulations for each of the eight sub-samples from Case B. For each simulation, we fit a maximum-likelihood logistic regression model and compute the performance metrics : AUC, AU-PCR, Precision, Recall, F1-score. In order words, in the end of this exercise, we will have 1000 values for each of the performance metrics for each of the eight sub-samples.\n",
        "\n",
        "The code below gives the distribution of the performance metrics for each of the eight sub-samples from Case B with monte-carlo simulations.\n"
      ],
      "id": "e788af0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "C_RUNS = 1000\n",
        "SAMPLE_SIZE = 5000  # e.g., majority class size if using a fixed majority approach\n",
        "ratios = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.98, 0.99]\n",
        "results_list = []\n",
        "\n",
        "#for r, (X_sub, y_sub) in samples_B.items():\n",
        "for r in ratios:\n",
        "    # 1) Create a random subsample\n",
        "    #    Use None or vary random_state so each iteration is unique\n",
        "    for mc_i in range(MC_RUNS):\n",
        "      X_sub, y_sub = create_subsample_fixed_majority(\n",
        "          xB, yB,\n",
        "          fraction_class0=r,\n",
        "          majority_class0_size=SAMPLE_SIZE,\n",
        "          random_state=None\n",
        "      )\n",
        "      \n",
        "      # 2) Split the subsample into train/test\n",
        "      #    stratify ensures class distribution is preserved\n",
        "      X_train, X_test, y_train, y_test = train_test_split(\n",
        "          X_sub,\n",
        "          y_sub,\n",
        "          test_size=0.3,\n",
        "          random_state=42,\n",
        "          stratify=y_sub\n",
        "      )\n",
        "      \n",
        "      # Prepare DataFrame for the training set\n",
        "      df_train = pd.DataFrame({'X': X_train, 'y': y_train})\n",
        "      df_train = sm.add_constant(df_train, prepend=True, has_constant='add')  \n",
        "      # => columns: ['const', 'X', 'y']\n",
        "      \n",
        "      # 3) Fit logistic regression on the TRAIN portion\n",
        "      logit_model = sm.Logit(df_train['y'], df_train[['const', 'X']])\n",
        "      result = logit_model.fit(disp=False)\n",
        "      \n",
        "      # 4) Predict probabilities on the TEST portion\n",
        "      df_test = pd.DataFrame({'X': X_test})\n",
        "      df_test = sm.add_constant(df_test, prepend=True, has_constant='add')\n",
        "      \n",
        "      y_proba_test = result.predict(df_test[['const', 'X']])\n",
        "      \n",
        "      # 5) Evaluate performance metrics on the TEST set\n",
        "      auc, auprc, prec, rec, f1 = evaluate_model_performance(y_test, y_proba_test, threshold=0.5)\n",
        "      \n",
        "      # 6) Store results\n",
        "      results_list.append({\n",
        "          'ratio_0': r,\n",
        "          'auc': auc,\n",
        "          'auprc': auprc,\n",
        "          'precision': prec,\n",
        "          'recall': rec,\n",
        "          'f1': f1\n",
        "      })\n",
        "\n",
        "# Convert collected results to a DataFrame\n",
        "df_results_B = pd.DataFrame(results_list)\n",
        "# Compute the mean performance metrics for each ratio\n",
        "df_results_B.groupby('ratio_0').mean()\n"
      ],
      "id": "79eb4f4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mean of the performance metrics for each of the eight sub-samples from Case B is presented in @fig-plot_metrics_b.\n"
      ],
      "id": "a192204f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-plot_metrics_b\n",
        "#| fig-cap: Performance metrics Vs. Ratios for Case B\n",
        "# Module : Plotting\n",
        "# Inputs : df_results_B\n",
        "# Objective : Group data by ratio_0 and plot the performance metrics.\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_grouped_B = df_results_B.groupby('ratio_0').mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "for metric, colour in zip(metrics, colours):\n",
        "    plt.plot(df_grouped_B['ratio_0'], df_grouped_B[metric], label=metric, color=colour, marker='o')\n",
        "\n",
        "# Improve readability with grid and styling\n",
        "\n",
        "# Add vertical lines at 0.8.\n",
        "plt.axvline(x=0.8, color='black', linestyle='--', linewidth=1.0)\n",
        "plt.xlabel(\"Ratio of Y=0\", fontsize=12, weight='bold')\n",
        "plt.ylabel(\"Mean of Performance Metrics\", fontsize=12, weight='bold')\n",
        "plt.title(\"Mean of Performance Metrics vs Ratios\", fontsize=14, weight='bold')\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "#plt.grid(False, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "plt.legend(title=\"Metrics\", fontsize=10, title_fontsize=12, loc=\"best\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "id": "fig-plot_metrics_b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the distribution of the minority in the sample is less than the distribution of the minority in the population, the performance metrics deteriorate considerably; when the distribution of the minority in the sample is greater than the distribution of the minority in the population, the performance metrics improve. Similar to Case A, there is not a significant change in the AUC metric values due to class imbalance and sampling bias.\n",
        "\n",
        "Next, it can be interesting to compare the performance measures from the samples that have the best performance in Case A (Case $A_{50:50}$) and Case B (Case $B_{80:20}$). In case, the sample $A_{50:50}$ that performs the best has no sampling bias and class imbalance, while the sample $B_{80:20}$ that performs the best has no sampling bias but has class imbalance. From these comparisons, it can be concluded that the performance of maximum-likelihood logistic regression is more sensitive to sampling bias than class imbalance. \n"
      ],
      "id": "15d6bcc8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/juniorjumbong/Desktop/personal-website/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}