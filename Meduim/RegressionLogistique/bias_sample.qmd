---
title: " Sampling Bias and Class Imbalance (Oversampling and Undersampling) in Maximum-likelihood Logistic Regression"
sidebar: auto
author:
  - Jumbong Junior 
categories: []
tags: []
title-block-banner: false
html:
    code-fold : true
jupyter: python3

---

# Introduction 

In this article, the impact of sampling bias and class imbalance on logistic regression models is explored. The article covers two topics :

- First, we hypothesize that the predictive performance of a logistic regression model is related to the sampling bias associated with the data and it has a perrformance advantage when the data is balanced. The hypothesis is testing with two simulated datasets : a balanced dataset (50:50) and an imbalanced dataset (80:20).  Each dataset will be sampled to produce samples with the following distribution : 50:50, 60:40, 70:30, 80:20, 90:10, 95:5, 99:1. 

- Second, in the case of class imbalance data, if the oversampling technique is used the intercept of the logistic regression model after oversampling need to be adjusted. In other words, let denote $\hat{\beta_0}$ the intercept of the logistic regression model after oversampling, then the following correction needs to be performed on it : 

beta_hat - log[((1 - tau)/tau)(bar(y)/(1 - bar(y)))] 
In latex ,the formular is given by :
$$
\hat{\beta}_0 - \ln\left[\left(\frac{1-\tau}{\tau}\right)\left(\frac{\bar{y}}{1-\bar{y}}\right)\right]
$$

where $\hat{\beta_0}$ is the intercept of the logistic regression model after oversampling, $\tau$ is the proportion of the minority class in the original dataset (or in population), and $\bar{y}$ is the proportion of the minority class in the oversampled dataset (or in sample).

1. Simulated Data Generation

Many authors document that, for logistic regressionthe , the probability distribution of the dependent variable is assumed to be Bernoulli and the mass function f is given by :

$$
f(y, x, \alpha, \beta) = p(x, \alpha, \beta)^y(1-p(x, \alpha, \beta))^{1-y}
$$

where 
$$
p(x, \alpha, $\beta) = \frac{\exp(\alpha + \beta x)}{1 + \exp(\alpha + \beta x)} 
$$

and where y is the dependent variable, x is the independent variable, $\alpha$ and $\beta$ are the parameters to be estimated using the maximum likelihood method (MLE).

For generating the the bernouilli trial y using for a fixed parameter P, we use the following equation :

$$
y(p) = 
\begin{cases}
\text{dummy} \leftarrow \mathrm{rnd}(1), \\
0, & \text{if dummy} < p, \\
1, & \text{otherwise}.
\end{cases}
$$

where rnd(1) is a random number generator that generates a random number between 0 and 1.

The conditional bernouilli trials y are then generated by substituting of $p(x, \alpha, \beta)$ :

$$
y(x, \alpha, \beta) =
\begin{cases}
0, & \text{if rnd(1)} < p(x, \alpha, \beta), \\
1, & \text{otherwise}.
\end{cases}

