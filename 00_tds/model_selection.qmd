---
title: "Model Selection"
subtitle: ""
date: last-modified
sidebar: auto
number-sections: false
toc: true
author:
  - Jumbong Junior 

categories: []
tags: ["Model Selection"]
title-block-banner: false
bibliography: references.bib
format: 
  html: 
    mainfont: Times New Roman
    fontsize: 1.1em

jupyter: python3
notice: |
    @wasserman2004all 
---


# Introduction 
We will discuss the problem that may arise in multiple regression in practice. We have data with many variables but we may not want to include all of them in the model. We may not want to include all of them because some variables may be irrelevat, or because a smaller model with fewer variables has several advantages: It might give better predictions than a larger model and it is more parimonious [simple] then easier to interpret.In fact, as you add more variables, the bias of the model decreases, but the variance increases. This is known as the bias-variance trade-off. Too few variables yield high bias [this called underfitting].Too many covariates yields high variance [this called overfitting]. Good prediction requires a balance between bias and variance.

Même après avoir utilisé une approche experte, [ou éliminer les rédondances entre les variables fortement corrélés, ou les variables qui ont un vif élévé dans le cadre de certains modèles de régressions] pour select relevant variables, il est possible que nous ayons encore trop de variables. A smaller model with fewer variables has several advantages: It might give better predictions than a larger model and it is more parimonious [simple] then easier to interpret. If we take the example of regression, as you add more variables, the bias of the model decreases, but the variance increases. This is known as the bias-variance trade-off. Too few variables yield high bias [this called underfitting].Too many covariates yields high variance [this called overfitting]. Good prediction requires a balance between bias and variance.

C'est dans ce contexte que les mèthodes de sélection de variables sont utiles. There exists two main approaches to variable selection that we will explore : the first method consists to minimize the risk prediction and the second method assumes some subset of the $\beta$ coefficients are exactly equal to 0 and tries to find the true model, that is, the smallest sub-model consisting of nonzero $\beta$ terms.

