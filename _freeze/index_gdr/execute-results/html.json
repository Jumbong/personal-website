{
  "hash": "151c1401532b3fd9723b448e98812516",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat: \n  html: \n    fontsize: 1.3em\n---\n\n\n\n\n<div class=\"box\">\nVous trouverez ici certains exercices de la fiche de TD, qui vous permettront de mieux comprendre les concepts abordés par le professeur pendant les cours. N'hésitez pas à me contacter si vous avez des questions ou des suggestions. Je mettrai l'accent sur la rédaction des corrections.\n</div>\n\n# Espaces probabilisés\n\nJe reviendrai ici sur l'exercice 5 que nous n'avons pas eu la possibilité de mettre oeuvre la simulation monte Carlo.\n\n## Correction de l'exercice 5\n\nNous sélectionnons un entier au hasard parmi les N = 5,000 entiers qui sont dans l'intervalle [0, 4999]. \nQuelle est la probabilité qu’il soit divisible par 4,7 ou 10 ?\n\nModifier le code R vu en cours pour estimer cette probabilité par une simulation\nde Monte-Carlo pour vérifier ce résultat. Vous utiliserez au moins 50,000\nsimulations.\n\nPour résoudre cette exercice, il faut d'abord définir l'espace probabilisé. \nL'espace probabilisé est défini par le triplet (Ω, F, P) où:\n\n\n- Ω est l'ensemble des résultats possibles. Dans notre cas, Ω = {0, 1, 2, ..., 4999}.\n\n- F est la σ-algèbre des événements. Ici, nous pouvons considérer les événements comme les sous-ensembles de Ω.\n\n- P est la mesure de probabilité. Dans notre cas, chaque entier a une probabilité égale d'être sélectionné. On dit encore que la loi de probabilité est uniforme sur Ω.\n\nLe cardinal de l'ensemble Ω est |Ω| = 5000.\nLa probabilité d'un élément spécifique dans Ω est donc $P({x}) = \\frac{1}{5000}$ pour tout x dans Ω.\n\nAprès avoir défini l'espace probabilisé, nous pouvons maintenant définir l'événement A que nous voulons étudier. \nDe ce fait, définissons les événements suivants:\n\n- $A_4$ : l'événement que l'entier sélectionné est divisible par 4.\n- $A_7$ : l'événement que l'entier sélectionné est divisible par 7.\n- $A_{10}$ : l'événement que l'entier sélectionné est divisible par 10.\nL'événement A que nous voulons étudier est l'union de ces trois événements:\n\n$$\nA = A_4 \\cup A_7 \\cup A_{10}\n$$\n\nNous cherchons à calculer la probabilité de l'événement A, c'est-à-dire $P(A)$. Pour cela, nous allons utiliser la formule inclusion-exclusion:\n$$\n\\begin{aligned}\n\\mathbb{P}(A_4 \\cup A_7 \\cup A_{10})\n&= \\mathbb{P}(A_4) + \\mathbb{P}(A_7) + \\mathbb{P}(A_{10}) \\\\\n&\\quad - \\big\\{\\, \\mathbb{P}(A_4 \\cap A_7) + \\mathbb{P}(A_4 \\cap A_{10}) + \\mathbb{P}(A_7 \\cap A_{10}) \\,\\big\\} \\\\\n&\\quad + \\mathbb{P}(A_4 \\cap A_7 \\cap A_{10}).\n\\end{aligned}\n$$\n\nCalculons maintenant chaque terme de cette formule:\nPour calculer chaque probabilité, nous devons compter le nombre d'entiers dans Ω qui satisfont chaque condition $A_i$.\nEt la probabilité de chaque événement est donnée par le rapport du nombre d'entiers satisfaisant la condition sur le cardinal de l'ensemble Ω : \n\n$$\nP(A_i) = \\frac{\\text{nombre d'entiers satisfaisant } A_i}{5000}.\n$$\n\n\n- Pour $A_4$ : Les entiers divisibles par 4 sont 0, 4, 8, ..., 4996. Ainsi le nombre d'entiers divisibles par 4 est de la forme $4k$ et qui vérifient $0 \\leq 4(k+1) \\leq 5000 < 4(k+2)$, donc de cette inégalité, on déduit que $k$ vérifie l'inégalité sous dessous :\n\n$$\nk \\leq \\frac{4999}{4} < k+1.\n$$\n\nDonc le nombre d'entiers divisibles par 4 correspond à la partie entière de $\\frac{4999}{4}$ plus 1 (pour inclure le 0), soit:\n$$\n\\text{nombre d'entiers divisibles par 4} = \\left\\lfloor\\frac{4999}{4}\\right\\rfloor + 1 = 1249 + 1 = 1250.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 4 est:\n$$\nP(A_4) = \\frac{1250}{5000} = 0.25.\n$$\n\n- Pour $A_7$ : Les entiers divisibles par 7 sont 0, 7, 14, ..., 4996. En suivant le même raisonnement que pour $A_4$, nous trouvons:\n\n$$\n\\text{nombre d'entiers divisibles par 7} = \\left\\lfloor\\frac{4999}{7}\\right\\rfloor + 1 = 714 + 1 = 715.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 7 est:\n$$\nP(A_7) = \\frac{715}{5000} = 0.143.\n$$\n\n- Pour $A_{10}$ : Les entiers divisibles par 10 sont 0, 10, 20, ..., 4990. En suivant le même raisonnement que pour $A_4$, nous trouvons:\n$$\n\\text{nombre d'entiers divisibles par 10} = \\left\\lfloor\\frac{4999}{10}\\right\\rfloor + 1 = 499 + 1 = 500.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 10 est:\n$$\nP(A_{10}) = \\frac{500}{5000} = 0.1.\n$$  \n\n- Pour $A_4 \\cap A_7$ : Les entiers qui sont divisibles par 4 et 7 sont ceux qui sont divisibles par 28 qui est le PPCM de 4 et 7. En suivant le même raisonnement que pour $A_4$, nous trouvons:\n$$\n\\text{nombre d'entiers divisibles par 28} = \\left\\lfloor\\frac{4999}{28}\\right\\rfloor + 1 = 178 + 1 = 179.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 4 et 7 est:\n\n$$\nP(A_4 \\cap A_7) = \\frac{179}{5000} = 0.0358.\n$$\n\n- Pour $A_4 \\cap A_{10}$ : Les entiers qui sont divisibles par 4 et 10 sont ceux qui sont divisibles par 20 qui est le PPCM de 4 et 10. En suivant le même raisonnement que pour $A_4, nous trouvons:\n$$\n\\text{nombre d'entiers divisibles par 20} = \\left\\lfloor\\frac{4999}{20}\\right\\rfloor + 1 = 249 + 1 = 250.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 4 et 10 est:\n$$\nP(A_4 \\cap A_{10}) = \\frac{250}{5000} = 0.05.\n$$\n\n- Pour $A_7 \\cap A_{10}$ : Les entiers qui sont divisibles par 7 et 10 sont ceux qui sont divisibles par 70 qui est le PPCM de 7 et 10. En suivant le même raisonnement que pour $A_4, nous trouvons:\n\n$$\n\\text{nombre d'entiers divisibles par 70} = \\left\\lfloor\\frac{4999}{70}\\right\\rfloor + 1 = 71 + 1 = 72.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 7 et 10 est:\n$$\nP(A_7 \\cap A_{10}) = \\frac{72}{5000} = 0.0144.\n$$\n\n- Pour $A_4 \\cap A_7 \\cap A_{10}$ : Les entiers qui sont divisibles par 4, 7 et 10 sont ceux qui sont divisibles par 140 qui est le PPCM de 4, 7 et 10. En suivant le même raisonnement que pour $A_4$, nous trouvons:\n\n$$\n\\text{nombre d'entiers divisibles par 140} = \\left\\lfloor\\frac{4999}{140}\\right\\rfloor + 1 = 35 + 1 = 36.\n$$\n\nDonc, la probabilité que l'entier sélectionné soit divisible par 4, 7 et 10 est:\n$$\nP(A_4 \\cap A_7 \\cap A_{10}) = \\frac{36}{5000} = 0.0072.\n$$  \n\nEn substituant ces valeurs dans la formule d'inclusion-exclusion, nous obtenons:\n$$\n\\begin{aligned}\nP(A)\n&= P(A_4) + P(A_7) + P(A_{10}) \\\\\n&\\quad - \\big\\{\\, P(A_4 \\cap A_7) + P(A_4 \\cap A_{10}) + P(A_7 \\cap A_{10}) \\,\\big\\} \\\\\n&\\quad + P(A_4 \\cap A_7 \\cap A_{10}) \\\\\n&= 0.25 + 0.143 + 0.1 \\\\\n&\\quad - \\big\\{\\, 0.0358 + 0.05 + 0.0144 \\,\\big\\} \\\\\n&\\quad + 0.0072 \\\\\n&= 0.493 - 0.1002 + 0.0072 \\\\\n&= 0.4.\n\\end{aligned}\n$$  \n\nDonc, la probabilité qu'un entier sélectionné au hasard parmi les 5000 entiers soit divisible par 4, 7 ou 10 est de 0.4 ou 40%.\n\nMaintenant, nous allons vérifier ce résultat par une simulation de Monte-Carlo en R avec au moins 50,000 simulations.\nUne simulation de Monte-Carlo est une méthode statistique qui utilise des échantillons aléatoires pour estimer des propriétés mathématiques ou physiques comme des espérances, des intégrales ou des probabilités. Cette méthode fonctionne en générant un grand nombre de scénarios aléatoires et en observant les résultats pour obtenir une estimation statistique :\n\n- On fixe le nombre de simulations, disons n = 50000.\n- On initialise un compteur pour le nombre de succès (entiers divisibles par 4, 7 ou 10).\n- Pour chaque simulation, on génère un entier aléatoire entre 0 et 4999.\n- On vérifie si cet entier est divisible par 4, 7 ou 10. Si c'est le cas, on incrémente le compteur de succès.\n- Après avoir effectué toutes les simulations, on calcule la probabilité estimée comme le ratio du nombre de succès sur le nombre total de simulations.\n\nVoici un exemple de code R pour effectuer cette simulation de Monte-Carlo :\n\n::: {#c0285cdd .cell execution_count=1}\n``` {.python .cell-code}\n# Monte Carlo in Python with running estimate and plot (matplotlib only)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# --- Parameters (mirror your R snippet) ---\nseed = 123\nN = 4999               # sample from 0..N (inclusive)\nM = 50_000             # number of simulations\n\nrng = np.random.default_rng(seed)\nx = rng.integers(low=0, high=N+1, size=M)  # uniform integers in [0, N]\n\nis_div = (x % 4 == 0) | (x % 7 == 0) | (x % 10 == 0)\n\n# Final Monte Carlo estimate (same as R's mean(is_div))\np_hat = is_div.mean()\n\n# Running estimates vs number of simulations\nrunning_est = np.cumsum(is_div) / np.arange(1, M + 1)\n\n# Mean of the running estimates (to draw an horizontal reference line)\nmean_running = running_est.mean()\n\n# --- Plot ---\nplt.figure(figsize=(7.24, 4.07), dpi=100)  # ~724x407 px\n\nplt.plot(np.arange(1, M + 1), running_est, linewidth=2)\nplt.axhline(mean_running, linestyle=\"--\", linewidth=2)\nplt.xlabel(\"Nombre de simulations\")\nplt.ylabel(\"Estimation de la probabilité\")\nplt.title(\"Convergence de l’estimation Monte-Carlo\", fontsize=14, weight=\"bold\")\nplt.suptitle(\n    \"Courbe de l’estimation cumulée; ligne horizontale = moyenne des estimations\",\n    fontsize=10, color=\"gray\"\n)\n\n# Style cues similar to the provided seaborn example\nax = plt.gca()\nfor spine in [\"top\", \"right\"]:\n    ax.spines[spine].set_visible(False)\nplt.grid(False)\n\nplt.tight_layout()\nplt.show()\n\np_hat\n\n```\n\n::: {.cell-output .cell-output-display}\n![](index_gdr_files/figure-html/cell-2-output-1.png){width=714 height=403}\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nnp.float64(0.3965)\n```\n:::\n:::\n\n\n::: {.byline}\n<span class=\"date\">May 28, 2025</span>\n:::\n\n# Rappels de la séance précédente\n\nL'objectif de la prémière séance de TD était de consolider vos connaissances sur les espaces probabilisés et sur les probabilités conditionnelles.\n\nVous devez actuellement être capable de :\n\n- Définir un espace probabilisé (Ω, F, P).\n\n- Utiliser les propriétés des probabilités pour calculer des probabilités d'événements simples et composés.\n\n- Vous devez maitriser les lois de Morgan :\n\n  - La loi de Morgan pour l'union : $\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B}$\n  - La loi de Morgan pour l'intersection : $\\overline{A \\cap B} = \\overline{A} \\cup \\overline{B}$\n\n- Appliquer la formule d'inclusion-exclusion pour calculer la probabilité de l'union de deux événements :\n\n  $$\n  P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n  $$\n\n- Appliquer la formule d'inclusion-exclusion pour calculer la probabilité de l'union de plusieurs événements :\n\n  $$\n  \\begin{aligned}\n  P\\left(\\bigcup_{i=1}^{n} A_i\\right) &= \\sum_{i=1}^{n} P(A_i) - \\sum_{1 \\leq i < j \\leq n} P(A_i \\cap A_j) \\\\\n  &\\quad + \\sum_{1 \\leq i < j < k \\leq n} P(A_i \\cap A_j \\cap A_k) - \\ldots + (-1)^{n+1} P(A_1 \\cap A_2 \\cap \\ldots \\cap A_n)\n  \\end{aligned}\n  $$\n- Calculer des probabilités conditionnelles en utilisant la formule de Bayes :\n\n$$\n  P(A|B) = \\frac{P(A \\cap B)}{P(B)}.\n$$\n\nou bien encore :\n\n$$\n  P(A\\cap B) = P(A|B) \\cdot P(B).\n$$\n\n- Appliquer la loi des probabilités totales pour décomposer des probabilités complexes en utilisant des événements disjoints et exhaustifs :\n\nPar exemple, si $C_1, C_2$ sont deux événements disjoints et exhaustifs, c'est-à-dire que $C_1 \\cap C_2 = \\emptyset$ et $C_1 \\cup C_2 = \\Omega$, alors pour tout événement A, on a :\n\n$$\nP(A) = P(A|C_1) \\cdot P(C_1) + P(A|C_2) \\cdot P(C_2).\n$$\n\nEt finalement, cela nous permet de calculer la probabilité de $C_1$ sachant A en utilisant la formule de Bayes :\n\n$$\nP(C_1|A) = \\frac{P(A|C_1) \\cdot P(C_1)}{P(A|C_1) \\cdot P(C_1) + P(A|C_2) \\cdot P(C_2)}.\n$$\n\n\ndigraph {\n  rankdir=LR;\n  node [shape=box, style=rounded, fontsize=11];\n\n  A [label=\"(Ω, F, P) — espace probabilisé\"];\n  B [label=\"X : variable aléatoire\"];\n  C [label=\"Loi de X\"];\n  D [label=\"Type de variable\", shape=diamond];\n  E [label=\"Discrète\"];\n  F [label=\"Continue\"];\n  G [label=\"Fonction de répartition  F_X\"];\n  H [label=\"Fonction génératrice des moments  M_X(t)\"];\n  I [label=\"Moments : E[X], Var(X)\"];\n\n  A -> B [label=\"mesure\"];\n  B -> C [label=\"théorème de transfert\"];\n  B -> D;\n  D -> E;\n  D -> F;\n  C -> G;\n  C -> H;\n  C -> I;\n}```\n\n",
    "supporting": [
      "index_gdr_files"
    ],
    "filters": [],
    "includes": {}
  }
}