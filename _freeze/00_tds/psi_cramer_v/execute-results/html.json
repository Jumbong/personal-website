{
  "hash": "c5a432f01c6e2ffd0883645fd9d9c755",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Representiveness\"\nsubtitle: \"\"\ndate: last-modified\nsidebar: auto\nnumber-sections: false\ntoc: true\nauthor:\n  - Jumbong Junior \n\ncategories: []\ntags: [\"Population Stability Index (PSI)\", \"Cramér's V\"]\ntitle-block-banner: false\nbibliography: references.bib\nformat: \n  html: \n    mainfont: Times New Roman\n    fontsize: 1.1em\n\njupyter: python3\nnotice: |\n    @wasserman2004all \n---\n\n\n\n\n\n\n\nThe issue of data representativeness arises frequently in modeling projects, whether academic or professional. Beyond its apparent simplicity, it raises a fundamental question: are the data used to build a model representative of the data the model will face in the real world?\n\nBy representativeness, we mean the extent to which a sample reflects the characteristics of the population it is supposed to model. In practice, this means that the distributions, proportions, and patterns observed in the training data should be consistent with those the model will encounter once implemented or deployed.\n\nThe first time I encountered this issue was while building a credit scoring model for a bank’s business clients. Like many others, I had been taught to split data into train, test, and sometimes out-of-sample sets. However, I realized that the real challenge was not simply achieving strong performance on the training data, but ensuring that the model remained reliable when applied to a different dataset or a new population of clients. Addressing this required comparing the distributions of key variables across datasets and verifying that they followed the same distribution.\n\nIn practice, comparing distributions is not just a theoretical exercise; it’s a critical step throughout the entire lifecycle of a model:\n\n* **During design**, to check whether the training sample reflects the global dataset.\n* **In production**, to detect population drift over time.\n* **In regulatory validation**, to demonstrate that the model is robust and generalizable.\n\nTo address this, we can use a variety of tools. Visual methods—such as histograms, boxplots, and density plots—provide quick intuition, while statistical methods allow us to quantify differences and make the analysis more objective.\n\nIn this article, we will focus on two particularly useful and complementary indicators:\n\n* the **Population Stability Index (PSI)**, which measures distributional drift, and\n* **Cramér’s V**, which evaluates the strength of association between categories and helps assess whether two populations share the same structure.\n\nOur goal is twofold:\n\n1. to show why comparing distributions is crucial in credit scoring, and\n2. to illustrate, through a concrete example, how PSI and Cramér’s V can be applied to evaluate representativeness between two datasets.\n\n\n\n## I. Comparing Distributions: A Key Challenge Throughout the Lifecycle of a Credit Model\n\nFrom a statistician’s perspective, the lifecycle of a credit model can be summed up in three main stages. \n\n**The construction phase**: this is where it all begins. You gather the data, clean it, split it into training, test, and out-of-time samples, estimate the parameters, and carefully document every decision. You ensure that the test and the out-of-time samples are representative of the training data.\n\n**The application phase**: once the model is built, it must be confronted with reality. And here a crucial question arises: do the new datasets truly resemble the ones used during construction? If not, much of the previous work may quickly lose its value.\n\n**The monitoring phase, or backtesting**: over time, populations evolve. The model must therefore be regularly challenged. Do its predictions remain valid? Is the representativeness of the target portfolio still ensured?\n\nAt each of these stages, the same recurring question plays like a refrain:\n**Is the model still representative of the population it is supposed to score?**\n\n\n### Practical Illustrations\n\nTo make this more concrete, let me share two situations I’ve encountered—or could easily have encountered in practice.\n\n**Case 1: A change in scope**\n\nImagine a bank developing a scoring model for small businesses. The model performs well and is recognized internally. Encouraged by this success, the leadership decides to extend its use to large corporations. But here every statistician would pause to ask: do the characteristic variables of large corporations follow the same distributions as those of small businesses? If not, the model risks becoming fragile.\n\n**Case 2: A banking merger**\n\nNow consider Bank A, equipped with a proven model to assess client default risk. It merges with Bank B and seeks to harmonize its tools. The challenge: Bank B operates in a different economic environment, with a portfolio of clients that may not share the same structure. Before transferring the model, the distributions of key variables across the two portfolios must be compared. Once again, representativeness is at stake.\n\n\n## II. Comparing Distributions to Assess Representativeness Between Datasets\n\nThese examples show that behind every strategic decision; whether changing scope, merging models, or tracking their evolution over time—there lies the same underlying question: **are the variable distributions sufficiently similar to guarantee the model’s robustness?**\n\nTo answer it, statisticians can rely on a wide range of tools. Some are visual and intuitive:\n\n* overlaying histograms to instantly spot divergent densities,\n* using boxplots to compare medians and spreads,\n* plotting cumulative distribution functions or estimated densities to get a global view.\n\nOthers are statistical and more formalized:\n\n* the **Kolmogorov-Smirnov test**, which measures the maximum gap between two cumulative distributions,\n* the **Chi-square test**, well suited for categorical variables,\n* the **Anderson-Darling test**, particularly sensitive to differences in the tails.\n\nThese methods form a solid foundation, and Matteo Courthoud offers a clear and comprehensive overview of them in his article *[How to Compare Two (or More) Distributions](https://towardsdatascience.com/how-to-compare-two-or-more-distributions-9b06ee4d30bf/)*.\n\nBut in credit risk, I’ve found that two indicators deserve special attention because they are simple, easy to use, and they address representativeness issues very directly:\n\n* the **Population Stability Index (PSI)**, widely used to detect distribution shifts over time, and\n* **Cramér’s V**, which measures the strength of association between two categorical variables and helps assess the coherence between populations.\n\nThe next part of this article will focus on these two tools, showing how they complement classical approaches and illustrating their use with a concrete example.\n\n\n## III. Two Indicators to Assess Representativeness: PSI and Cramér’s V\n\nWhen comparing distributions, we often start by examining the basic elements: cumulative curves or density graphs. These visualizations provide an initial overview of the differences and help to form an intuition. But intuition is not always enough: in practice, decision-makers also expect quantified measurements, not just graphs or pictures.\n\nThat’s where two tools come in: the Population Stability Index (PSI) and Cramér’s V. They’re easy to calculate, easy to read, and most importantly, they turn what a chart suggests into clear numbers. Instead of just saying “these distributions look different”, they tell us “this is how different they really are.” Whether you’re checking for risk drift or following portfolio stability, they make comparison both precise and practical.\n\n\n\n### 1. The Population Stability Index (PSI)\n\nThe PSI is a fundamental tool in the credit industry. It measures the difference between two distributions of the same variable:\n\n* for example, between the training dataset and a more recent application dataset,\n* or between a reference dataset at time $T_0$ and another at time $T_1$.\n\nIn other words, the **PSI quantifies how much a population has drifted over time or across different scopes**.\n\nHere’s how it works in practice:\n\n* For a **categorical variable**, we compute the proportion of observations in each category for both datasets.\n* For a **continuous variable**, we first **discretize it into bins**. In practice, deciles are often used to obtain a balanced distribution.\n\nThe PSI then compares, bin by bin, the proportions observed in the reference dataset versus the target dataset. The final indicator aggregates these differences using a logarithmic formula:\n\n$$\nPSI = \\sum_{i=1}^{k} (p_i - q_i) \\cdot \\ln\\!\\left(\\frac{p_i}{q_i}\\right)\n$$\n\nwhere $p_i$ and $q_i$ represent the proportions in bin $i$ for the reference dataset and the target dataset, respectively.\n\nThe interpretation is highly intuitive:\n\n* A smaller PSI means the two distributions are closer.\n* A PSI of **0** means the distributions are identical.\n* A very large PSI (tending toward infinity) means the two distributions are fundamentally different.\n\nIn practice, industry guidelines often use the following thresholds:\n\n* **PSI < 0.1**: the population is stable,\n* **0.1 ≤ PSI < 0.25**: the shift is noticeable—monitor closely,\n* **PSI ≥ 0.25**: the shift is significant—the model may no longer be reliable.\n\n## 2. Cramér’s V\n\nWhen assessing the representativeness of a categorical variable (or a discretized continuous variable) between two datasets, a natural starting point is the **Chi-square test of independence**.\n\nWe build a contingency table crossing:\n\n* the categories (modalities) of the variable of interest, and\n* an indicator variable for dataset membership (Dataset 1 / Dataset 2).\n\nThe test is based on the following statistic:\n\n$$\n\\chi^2 = \\sum_{i=1}^{r}\\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n$$\n\nwhere $O_{ij}$ are the observed counts and $E_{ij}$ are the expected counts under the assumption of independence.\n\n* **Null hypothesis $H_0$**: the variable has the same distribution in both datasets (independence).\n* **Alternative hypothesis $H_1$**: the distributions differ.\n\nIf $H_0$ is rejected, we conclude that the variable does not follow the same distribution across the two datasets.\n\nHowever, the Chi-square test has a major limitation: it only provides a binary answer (reject / do not reject), and its power is highly sensitive to sample size. With very large datasets, even tiny differences can appear statistically significant.\n\nTo address this limitation, we use **Cramér’s V**, which rescales the Chi-square statistic to produce a normalized measure of association bounded between 0 and 1:\n\n$$\nV = \\sqrt{\\frac{\\chi^2}{n \\cdot \\min(r-1,\\,c-1)}}\n$$\n\nwhere \\$n\\$ is the total sample size, \\$r\\$ is the number of rows, and \\$c\\$ is the number of columns in the contingency table.\n\nThe interpretation is intuitive:\n\n* $V \\approx 0$ → the distributions are very similar; representativeness is strong.\n* $V$ close to 1 → the difference between distributions is large; the datasets are structurally different.\n\nUnlike the Chi-square test, which simply answers “yes” or “no,” Cramér’s V provides a graded measure of the strength of the difference. This allows us to assess whether the difference is negligible, moderate, or substantial.\n\n\n\n# Applying PSI and Cramér’s V: A Simple Python Example\n\nIn a previous article, we applied different variable selection methods to reduce the *Communities & Crime* dataset to just **16 explanatory variables**. This step was essential to simplify the model while keeping the most relevant information.\n\nThis dataset also includes a variable called **fold**, which splits the data into **10 subsamples**. These folds are commonly used in cross-validation: they allow us to test the robustness of a model by training it on one part of the data and validating it on another.\n\n\n\n## Why Compare a Fold to the Global Dataset?\n\nIf a fold is **representative** of the overall dataset, then working with this subsample—and aggregating the results across all folds—should yield reliable conclusions at the full-dataset level.\n\nIn this article, we’ll look at a concrete example: checking whether **fold 1** is representative of the global dataset.\n\n\n## Step 1: Start with the Target Variable\n\nWe begin with the **target variable**. The idea is simple: compare its distribution between fold 1 and the entire dataset. To quantify this difference, we’ll use two complementary indicators:\n\n* the **Population Stability Index (PSI)**, which measures distributional shifts,\n* **Cramér’s V**, which measures the strength of association between two categorical variables.\n\n\n\n## Step 2: Automating the Analysis for All Variables\n\nAfter illustrating the approach with the target, we extend it to all features.\nWe’ll build a **Python function** that computes PSI and Cramér’s V for each of the **19 explanatory variables**, as well as for the target variable.\n\nTo make the results easy to interpret, we’ll export everything into an **Excel file** with:\n\n* one **sheet per variable**, showing the detailed comparison by segment,\n* a **Summary tab**, aggregating results across all variables.\n\n## Comparing the target variable `ViolentCrimesPerPop` between the global dataset (reference) and fold 1 (target)\n\nBefore applying statistical tests or building decision indicators, it is essential to conduct a descriptive and graphical analysis. There are not just formalities; they provide an early intuition about the differences between populations and help interpreting the results.\nIn practice, a well-chosen chart often reveals the conclusions that indicators like PSI or Cramér’s V will later confirm (or challenge).\n\n\nFor visualization, we proceed in three steps:\n\n**1. Comparing continuous distributions**\nWe begin with graphical tools such as boxplots, cumulative distribution functions, and probability density plots. These visualizations provide an intuitive way to examine differences in the target variable’s distribution between the two datasets.\n\n**2. Discretization into quantiles**\nNext, we discretize the variable in the reference dataset using quartiles (Q1, Q2, Q3, Q4), which creates five classes (Q1 through Q5). We then apply the exact same cut-off points to the target dataset, ensuring that each observation is mapped to intervals defined from the reference. This guarantees comparability between the two distributions.\n\n**3. Comparing categorical distributions**\nFinally, once the variable has been discretized, we can use visualization methods suited for categorical data — such as bar charts — to compare how frequencies are distributed across the two datasets.\n\nThe process depends on the type of variable:\n\n**For a continuous variable:**\n\n* Start with standard visualizations (boxplots, cumulative distributions, and density plots).\n* Next, split the variable into segments (Q1 to Q5) based on the reference dataset’s quantiles.\n* Finally, treat these segments as categories and compare their distributions.\n\n**For a categorical variable:**\n\n* No discretization is needed — it’s already in categorical form.\n* Go straight to comparing category distributions, for example with a bar chart.\n\nThe code below prepares the two datasets we want to compare and then visualizes the target variable with a boxplot, showing its distribution in both the global dataset and in fold 1.\n\n::: {#846d82fe .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2_contingency, ks_2samp\n\ndata = pd.read_csv(\"data/communities_data.csv\")\n# filter sur fold =1\n\ndata_ref = data\ndata_target = data[data[\"fold\"] == 1]\n\n# compare the two distribution of \"ViolentCrimesPerPop\" in the reference and target datasets with boxplots\n\n\n\n# Build datasets with a \"Group\" column\ndf_ref = pd.DataFrame({\n    \"ViolentCrimesPerPop\": data_ref[\"ViolentCrimesPerPop\"],\n    \"Group\": \"Reference\"\n})\n\ndf_target = pd.DataFrame({\n    \"ViolentCrimesPerPop\": data_target[\"ViolentCrimesPerPop\"],\n    \"Group\": \"Target\"\n})\n\n# Merge them\ndf_all = pd.concat([df_ref, df_target])\n\n\nplt.figure(figsize=(8, 6))\n\n# Boxplot with both distributions overlayed\nsns.boxplot(\n    x=\"Group\", \n    y=\"ViolentCrimesPerPop\", \n    data=df_all,\n    palette=\"Set2\",\n    width=0.6,\n    fliersize=3\n)\n\n\n# Add mean points\nmeans = df_all.groupby(\"Group\")[\"ViolentCrimesPerPop\"].mean()\nfor i, m in enumerate(means):\n    plt.scatter(i, m, color=\"red\", marker=\"D\", s=50, zorder=3, label=\"Mean\" if i == 0 else \"\")\n\n# Title tells the story\nplt.title(\"Violent Crimes Per Population by Group\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"Both groups show nearly identical distributions\", \n             fontsize=10, color=\"gray\")\n\nplt.ylabel(\"Violent Crimes (Per Pop)\", fontsize=12)\nplt.xlabel(\"\")\n\n# Cleaner look\nsns.despine()\nplt.grid(visible=False)\nplt.legend()\n\nplt.show()\n\n\nprint(len(data.columns))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/v8/l5q0bw4s2ln17s59y7cc86rm0000gn/T/ipykernel_35159/1831008403.py:35: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-2-output-2.png){width=666 height=543}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n18\n```\n:::\n:::\n\n\nThe figure above suggests that both groups share similar distributions for the `ViolentCrimesPerPop` variable. To take a closer look, we can use Kernel Density Estimation (KDE) plots, which provide a smooth view of the underlying distribution and make it easier to spot subtle differences.\n\n::: {#dc92c558 .cell execution_count=2}\n``` {.python .cell-code}\nplt.figure(figsize=(8, 6))\n\n# KDE plots with better styling\nsns.kdeplot(\n    data=df_all,\n    x=\"ViolentCrimesPerPop\",\n    hue=\"Group\",\n    fill=True,         # use shading for overlap\n    alpha=0.4,         # transparency to show overlap\n    common_norm=False,\n    palette=\"Set2\",\n    linewidth=2\n)\n\n# KS-test for distribution difference\ng1 = df_all[df_all[\"Group\"] == df_all[\"Group\"].unique()[0]][\"ViolentCrimesPerPop\"]\ng2 = df_all[df_all[\"Group\"] == df_all[\"Group\"].unique()[1]][\"ViolentCrimesPerPop\"]\nstat, pval = ks_2samp(g1, g2)\n\n# Add annotation\nplt.text(df_all[\"ViolentCrimesPerPop\"].mean(),\n         plt.ylim()[1]*0.9,\n         f\"KS-test p-value = {pval:.3f}\\nNo significant difference observed\",\n         ha=\"center\", fontsize=10, color=\"black\")\n\n# Titles with story\nplt.title(\"Kernel Density Estimation of Violent Crimes Per Population\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"Distributions overlap almost completely between groups\", fontsize=10, color=\"gray\")\n\nplt.xlabel(\"Violent Crimes (Per Pop)\")\nplt.ylabel(\"Density\")\n\nsns.despine()\nplt.grid(False)\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-3-output-1.png){width=678 height=561}\n:::\n:::\n\n\nThe KDE graph confirms that the two distributions are very similar, showing a high degree of overlap. The Kolmogorov-Smirnov (KS) statistical test of 0.976 also indicates that there is no significant difference between the two groups. To extend the analysis, we can now examine the cumulative distribution of the target variable.\n\n::: {#3501b9ee .cell execution_count=3}\n``` {.python .cell-code}\n# Cumulative distribution\nplt.figure(figsize=(9, 6))\nsns.histplot(\n    data=df_all,\n    x=\"ViolentCrimesPerPop\",\n    hue=\"Group\",\n    stat=\"density\",\n    common_norm=False,\n    fill=False,\n    element=\"step\",\n    bins=len(df_all),\n    cumulative=True,\n)\n\n# Titles tell the story\nplt.title(\"Cumulative Distribution of Violent Crimes Per Population\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"ECDFs overlap extensively; central tendencies are nearly identical\", fontsize=10)\n\n# Labels & cleanup\nplt.xlabel(\"Violent Crimes (Per Pop)\")\nplt.ylabel(\"Cumulative proportion\")\nplt.grid(visible=False)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-4-output-1.png){width=738 height=561}\n:::\n:::\n\n\nThe cumulative distribution plot provides additional evidence that the two groups are very similar. The curves overlap almost completely, suggesting that their distributions are nearly identical in both central tendency and spread.\n\nAs a next step, we’ll discretize the variable into quantiles in the reference dataset and then apply the same cut-off points to the target dataset (fold 1). The code below demonstrates how to do this. Finally, we’ll compare the resulting distributions using a bar chart.\n\n::: {#20d47dc9 .cell execution_count=4}\n``` {.python .cell-code}\ndef bin_numeric(ref, tgt, n_bins=5):\n    \"\"\"\n    Discretize a numeric variable into quantile bins (ex: quintiles).\n    - Quantile thresholds are computed only on the reference dataset.\n    - Extend bins with -inf and +inf to cover all possible values.\n    - Returns:\n        * ref binned\n        * tgt binned\n        * bin labels (Q1, Q2, ...)\n    \"\"\"\n    edges = np.unique(ref.dropna().quantile(np.linspace(0, 1, n_bins + 1)).values)\n    if len(edges) < 3:  # if variable is almost constant\n        edges = np.array([-np.inf, np.inf])\n    else:\n        edges[0], edges[-1] = -np.inf, np.inf\n    labels = [f\"Q{i}\" for i in range(1, len(edges))]\n    return (\n        pd.cut(ref, bins=edges, labels=labels, include_lowest=True),\n        pd.cut(tgt, bins=edges, labels=labels, include_lowest=True),\n        labels\n    )\n\n# Apply binning\nref_binned, tgt_binned, bin_labels = bin_numeric(data_ref[\"ViolentCrimesPerPop\"], data_target[\"ViolentCrimesPerPop\"], n_bins=5)\n\n\n\n\n# Effectifs par segment pour Reference et Target\nref_counts = ref_binned.value_counts().reindex(bin_labels, fill_value=0)\ntgt_counts = tgt_binned.value_counts().reindex(bin_labels, fill_value=0)\n\n# Convertir en proportions\nref_props = ref_counts / ref_counts.sum()\ntgt_props = tgt_counts / tgt_counts.sum()\n\n# Construire un DataFrame pour seaborn\ndf_props = pd.DataFrame({\n    \"Segment\": bin_labels,\n    \"Reference\": ref_props.values,\n    \"Target\": tgt_props.values\n})\n\n# Restructurer en format long\ndf_long = df_props.melt(id_vars=\"Segment\", \n                        value_vars=[\"Reference\", \"Target\"], \n                        var_name=\"Source\", \n                        value_name=\"Proportion\")\n\n# Style sobre\nsns.set_theme(style=\"whitegrid\")\n\n# Barplot avec proportions\nplt.figure(figsize=(8,6))\nsns.barplot(\n    x=\"Segment\", y=\"Proportion\", hue=\"Source\",\n    data=df_long, palette=[\"#4C72B0\", \"#55A868\"]  # bleu & vert sobres\n)\n\n# Titre et légende\n# Titles with story\nplt.title(\"Proportion Comparison by Segment (ViolentCrimesPerPop)\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"Across all quantile segments (Q1–Q5), proportions are nearly identical\", fontsize=10, color=\"gray\")\n\nplt.xlabel(\"Quantile Segment (Q1 - Q5)\")\nplt.ylabel(\"Proportion\")\nplt.legend(title=\"Dataset\", loc=\"upper right\")\nplt.grid(False)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-5-output-1.png){width=676 height=567}\n:::\n:::\n\n\nAs before, we reach the same conclusion: the distributions in the reference and target datasets are very similar. To move beyond visual inspection, we will now compute the Population Stability Index (PSI) and Cramér’s V statistic. These metrics allow us to quantify the differences between distributions; both for all variables in general and for the target variable ViolentCrimesPerPop in particular.\n\n::: {#598ea42a .cell execution_count=5}\n``` {.python .cell-code}\nEPS = 1e-12  # A very small constant to avoid division by zero or log(0)\n\n# ============================================================\n# 1. Basic functions\n# ============================================================\n\ndef safe_proportions(counts):\n    \"\"\"\n    Convert raw counts into proportions in a safe way.\n    - If the total count = 0, return all zeros (to avoid division by zero).\n    - Clip values so no proportion is exactly 0 or 1 (numerical stability).\n    \"\"\"\n    total = counts.sum()\n    if total == 0:\n        return np.zeros_like(counts, dtype=float)\n    p = counts / total\n    return np.clip(p, EPS, 1.0)\n\ndef calculate_psi(p_ref, p_tgt):\n    \"\"\"\n    Compute the Population Stability Index (PSI) between two distributions.\n\n    PSI = sum( (p_ref - p_tgt) * log(p_ref / p_tgt) )\n\n    Interpretation:\n    - PSI < 0.1  → stable\n    - 0.1–0.25   → moderate shift\n    - > 0.25     → major shift\n    \"\"\"\n    p_ref = np.clip(p_ref, EPS, 1.0)\n    p_tgt = np.clip(p_tgt, EPS, 1.0)\n    return float(np.sum((p_ref - p_tgt) * np.log(p_ref / p_tgt)))\n\ndef calculate_cramers_v(contingency):\n    \"\"\"\n    Compute Cramér's V statistic for association between two categorical variables.\n    - Input: a 2 x K contingency table (counts).\n    - Uses Chi² test.\n    - Normalizes the result to [0, 1].\n      * 0   → no association\n      * 1   → perfect association\n    \"\"\"\n    chi2, _, _, _ = chi2_contingency(contingency, correction=False)\n    n = contingency.sum()\n    r, c = contingency.shape\n    if n == 0 or min(r - 1, c - 1) == 0:\n        return 0.0\n    return np.sqrt(chi2 / (n * (min(r - 1, c - 1))))\n\n# ============================================================\n# 2. Preparing variables\n# ============================================================\n\ndef bin_numeric(ref, tgt, n_bins=5):\n    \"\"\"\n    Discretize a numeric variable into quantile bins (ex: quintiles).\n    - Quantile thresholds are computed only on the reference dataset.\n    - Extend bins with -inf and +inf to cover all possible values.\n    - Returns:\n        * ref binned\n        * tgt binned\n        * bin labels (Q1, Q2, ...)\n    \"\"\"\n    edges = np.unique(ref.dropna().quantile(np.linspace(0, 1, n_bins + 1)).values)\n    if len(edges) < 3:  # if variable is almost constant\n        edges = np.array([-np.inf, np.inf])\n    else:\n        edges[0], edges[-1] = -np.inf, np.inf\n    labels = [f\"Q{i}\" for i in range(1, len(edges))]\n    return (\n        pd.cut(ref, bins=edges, labels=labels, include_lowest=True),\n        pd.cut(tgt, bins=edges, labels=labels, include_lowest=True),\n        labels\n    )\n\ndef prepare_counts(ref, tgt, n_bins=5):\n    \"\"\"\n    Prepare frequency counts for one variable.\n    - If numeric: discretize into quantile bins.\n    - If categorical: take all categories present in either dataset.\n    Returns:\n      segments, counts in reference, counts in target\n    \"\"\"\n    if pd.api.types.is_numeric_dtype(ref) and pd.api.types.is_numeric_dtype(tgt):\n        ref_b, tgt_b, labels = bin_numeric(ref, tgt, n_bins)\n        segments = labels\n    else:\n        segments = sorted(set(ref.dropna().unique()) | set(tgt.dropna().unique()))\n        ref_b, tgt_b = ref.astype(str), tgt.astype(str)\n\n    ref_counts = ref_b.value_counts().reindex(segments, fill_value=0)\n    tgt_counts = tgt_b.value_counts().reindex(segments, fill_value=0)\n    return segments, ref_counts, tgt_counts\n\n# ============================================================\n# 3. Analysis per variable\n# ============================================================\n\ndef analyze_variable(ref, tgt, n_bins=5):\n    \"\"\"\n    Analyze a single variable between two datasets.\n    Steps:\n    - Build counts by segment (bin for numeric, category for categorical).\n    - Compute PSI by segment and Global PSI.\n    - Compute Cramér's V from the contingency table.\n    - Return:\n        DataFrame with details\n        Summary dictionary (psi, v_cramer)\n    \"\"\"\n    segments, ref_counts, tgt_counts = prepare_counts(ref, tgt, n_bins)\n    p_ref, p_tgt = safe_proportions(ref_counts.values), safe_proportions(tgt_counts.values)\n\n    # PSI\n    psi_global = calculate_psi(p_ref, p_tgt)\n    psi_by_segment = (p_ref - p_tgt) * np.log(p_ref / p_tgt)\n\n    # Cramér's V\n    contingency = np.vstack([ref_counts.values, tgt_counts.values])\n    v_cramer = calculate_cramers_v(contingency)\n\n    # Build detailed results table\n    df = pd.DataFrame({\n        \"Segment\": segments,\n        \"Count Reference\": ref_counts.values,\n        \"Count Target\": tgt_counts.values,\n        \"Percent Reference\": p_ref,\n        \"Percent Target\": p_tgt,\n        \"PSI by Segment\": psi_by_segment\n    })\n\n    # Add summary lines at the bottom of the table\n    df.loc[len(df)] = [\"Global PSI\", np.nan, np.nan, np.nan, np.nan, psi_global]\n    df.loc[len(df)] = [\"Cramer's V\", np.nan, np.nan, np.nan, np.nan, v_cramer]\n\n    return df, {\"psi\": psi_global, \"v_cramer\": v_cramer}\n\n# ============================================================\n# 4. Excel reporting utilities\n# ============================================================\n\ndef apply_traffic_light(ws, wb, first_row, last_row, col, low, high):\n    \"\"\"\n    Apply conditional formatting (traffic light colors) to a numeric column in Excel:\n    - green  if value < low\n    - orange if low <= value <= high\n    - red    if value > high\n\n    Note: first_row, last_row, and col are zero-based indices (xlsxwriter convention).\n    \"\"\"\n    green  = wb.add_format({\"bg_color\": \"#C6EFCE\", \"font_color\": \"#006100\"})\n    orange = wb.add_format({\"bg_color\": \"#FCD5B4\", \"font_color\": \"#974706\"})\n    red    = wb.add_format({\"bg_color\": \"#FFC7CE\", \"font_color\": \"#9C0006\"})\n\n    if last_row < first_row:\n        return  # nothing to color\n\n    ws.conditional_format(first_row, col, last_row, col,\n        {\"type\": \"cell\", \"criteria\": \"<\", \"value\": low, \"format\": green})\n    ws.conditional_format(first_row, col, last_row, col,\n        {\"type\": \"cell\", \"criteria\": \"between\", \"minimum\": low, \"maximum\": high, \"format\": orange})\n    ws.conditional_format(first_row, col, last_row, col,\n        {\"type\": \"cell\", \"criteria\": \">\", \"value\": high, \"format\": red})\n\ndef representativity_report(ref_df, tgt_df, variables, output=\"representativity.xlsx\",\n                            n_bins=5, psi_thresholds=(0.10, 0.25),\n                            v_thresholds=(0.10, 0.25), color_summary=True):\n    \"\"\"\n    Build a representativity report across multiple variables and export to Excel.\n\n    For each variable:\n      - Create a sheet with detailed PSI by segment, Global PSI, and Cramer's V.\n      - Apply traffic light colors for easier interpretation.\n\n    Create one \"Résumé\" sheet with overall Global PSI and Cramer's V for all variables.\n    \"\"\"\n    summary = []\n\n    with pd.ExcelWriter(output, engine=\"xlsxwriter\") as writer:\n        wb = writer.book\n        fmt_header = wb.add_format({\"bold\": True, \"bg_color\": \"#0070C0\",\n                                    \"font_color\": \"white\", \"align\": \"center\"})\n        fmt_pct   = wb.add_format({\"num_format\": \"0.00%\"})\n        fmt_ratio = wb.add_format({\"num_format\": \"0.000\"})\n        fmt_int   = wb.add_format({\"num_format\": \"0\"})\n\n        for var in variables:\n            # Analyze variable\n            df, meta = analyze_variable(ref_df[var], tgt_df[var], n_bins)\n            sheet = var[:31]  # Excel sheet names are limited to 31 characters\n            df.to_excel(writer, sheet_name=sheet, index=False)\n            ws = writer.sheets[sheet]\n\n            # Format headers and columns\n            for j, col in enumerate(df.columns):\n                ws.write(0, j, col, fmt_header)\n            ws.set_column(0, 0, 18)\n            ws.set_column(1, 2, 16, fmt_int)\n            ws.set_column(3, 4, 20, fmt_pct)\n            ws.set_column(5, 5, 18, fmt_ratio)\n\n            nrows = len(df)   # number of data rows (excluding header)\n            col_psi = 5       # \"PSI by Segment\" column index\n\n            # PSI by Segment rows\n            apply_traffic_light(ws, wb, first_row=1, last_row=max(1, nrows-2),\n                                col=col_psi, low=psi_thresholds[0], high=psi_thresholds[1])\n\n            # Global PSI row (second to last)\n            apply_traffic_light(ws, wb, first_row=nrows-1, last_row=nrows-1,\n                                col=col_psi, low=psi_thresholds[0], high=psi_thresholds[1])\n\n            # Cramer's V row (last row) \n            apply_traffic_light(ws, wb, first_row=nrows, last_row=nrows,\n                                col=col_psi, low=v_thresholds[0], high=v_thresholds[1])\n\n            # Add summary info for Résumé sheet\n            summary.append({\"Variable\": var,\n                            \"Global PSI\": meta[\"psi\"],\n                            \"Cramer's V\": meta[\"v_cramer\"]})\n\n        # Résumé sheet\n        df_sum = pd.DataFrame(summary)\n        df_sum.to_excel(writer, sheet_name=\"Résumé\", index=False)\n        ws = writer.sheets[\"Résumé\"]\n        for j, col in enumerate(df_sum.columns):\n            ws.write(0, j, col, fmt_header)\n        ws.set_column(0, 0, 28)\n        ws.set_column(1, 2, 16, fmt_ratio)\n\n        # Apply traffic light to summary sheet\n        if color_summary and len(df_sum) > 0:\n            last = len(df_sum)\n            # PSI column\n            apply_traffic_light(ws, wb, 1, last, 1, psi_thresholds[0], psi_thresholds[1])\n            # Cramer's V column\n            apply_traffic_light(ws, wb, 1, last, 2, v_thresholds[0], v_thresholds[1])\n\n    return output\n\n# ============================================================\n# Example\n# ============================================================\n\nif __name__ == \"__main__\":\n    # columns namees privées de fold\n    columns = [x for x in data.columns if x != \"fold\"]\n    print(columns)\n    # Generate the report\n    path = representativity_report(data_ref, data_target, columns, output=\"representativity.xlsx\")\n    print(f\" Report generated: {path}\")\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['PctKids2Par', 'PctWorkMom', 'LandArea', 'PopDens', 'MedYrHousBuilt', 'PctVacantBoarded', 'LemasPctOfficDrugUn', 'AsianPerCap', 'PctUsePubTrans', 'MedOwnCostPctIncNoMtg', 'PctSameHouse85', 'PctVacMore6Mos', 'PctEmplProfServ', 'PctEmplManu', 'PctImmigRec10', 'MedRentPctHousInc', 'ViolentCrimesPerPop']\n Report generated: representativity.xlsx\n```\n:::\n:::\n\n\nAs mentioned earlier, the results of the distribution comparisons for each variable between the two datasets, calculated using PSI and Cramér’s V, are presented in separate sheets within a single Excel file.\n\nTo illustrate, we will first look at the results for the target variable. This example shows how both PSI and Cramér’s V are computed and how their values can be interpreted in practice.\n\nFinally, we will introduce the last sheet of the file, titled Summary, which consolidates the results for all variables of interest. This synthesis provides a global view of representativeness between the two datasets and makes interpretation and decision-making much easier.\n\n::: {#c818958a .cell execution_count=6}\n``` {.python .cell-code}\nimport os, time, requests, pandas as pd\n\n# --- paramètres de base ---\nAPI_URL = \"https://api.football-data.org/v4/competitions/PL/matches\"\nSEASONS = [2023, 2024]  # 2023-24 et 2024-25\n\n# --- hardcoder la clé pour un test local ---\nTOKEN = \"46ff0dc946b740059274353d6889b27b\"  # <-- colle ici ta clé brute\n\n# hardcoder la clé\nif not TOKEN:\n    raise RuntimeError(\"Variable d'environnement FOOTBALL_DATA_TOKEN absente.\")\n\nheaders = {\"X-Auth-Token\": TOKEN}\nrows = []\n\nfor season in SEASONS:\n    params = {\"season\": season}\n    r = requests.get(API_URL, params=params, headers=headers, timeout=30)\n    if r.status_code == 429:\n        # rate-limit: petite pause puis retry\n        time.sleep(10)\n        r = requests.get(API_URL, params=params, headers=headers, timeout=30)\n    r.raise_for_status()\n\n    for m in r.json().get(\"matches\", []):\n        # On garde les matches terminés ou attribués\n        if m.get(\"status\") in {\"FINISHED\", \"AWARDED\"}:\n            md = m.get(\"matchday\")\n            score = m.get(\"score\", {}).get(\"fullTime\", {})\n            hg, ag = score.get(\"home\"), score.get(\"away\")\n            if hg is None or ag is None or md is None:\n                continue\n            rows.append({\n                \"season\": season,\n                \"match_id\": m.get(\"id\"),\n                \"utcDate\": m.get(\"utcDate\"),\n                \"matchday\": int(md),\n                \"homeTeam\": m.get(\"homeTeam\", {}).get(\"name\"),\n                \"awayTeam\": m.get(\"awayTeam\", {}).get(\"name\"),\n                \"homeGoals\": int(hg),\n                \"awayGoals\": int(ag),\n                \"totalGoals\": int(hg) + int(ag),\n                \"venue\": (m.get(\"area\") or {}).get(\"name\"),  # parfois vide\n                \"status\": m.get(\"status\"),\n            })\n\n# --- ton export \"par match\" (inchangé) ---\ndf = pd.DataFrame(rows).sort_values([\"season\", \"matchday\", \"utcDate\"])\noutfile = \"data/premier_league_goals_by_match_2023_2024.csv\"\ndf.to_csv(outfile, index=False, encoding=\"utf-8\")\nprint(f\"Écrit {len(df)} lignes dans {outfile}\")\n\n# --- agrégat par journée (inchangé) ---\nagg = (df.groupby([\"season\",\"matchday\"], as_index=False)[\"totalGoals\"]\n         .sum()\n         .rename(columns={\"totalGoals\":\"goals_by_matchday\"}))\nagg.to_csv(\"data/premier_league_goals_by_matchday_2023_2024.csv\", index=False, encoding=\"utf-8\")\nprint(\"Agrégat par journée écrit dans premier_league_goals_by_matchday_2023_2024.csv\")\n\n# --- NOUVEAU : table large (DRY/orthogonale) -> matchday, goals_2023, goals_2024 ---\nwide = (agg.pivot(index=\"matchday\", columns=\"season\", values=\"goals_by_matchday\")\n           .sort_index())\n\n# renommer colonnes -> goals_<season>\nwide.columns = [f\"goals_{s}\" for s in wide.columns]\n\n# (option) remplir les journées manquantes par 0 (cas saison en cours)\nif not wide.empty:\n    full_index = range(1, int(wide.index.max()) + 1)\n    wide = wide.reindex(full_index)\n\nwide = wide.fillna(0).astype(int).reset_index().rename(columns={\"index\": \"matchday\"})\n\n# garantir l'ordre des colonnes : matchday, goals_2023, goals_2024, ...\ncols = [\"matchday\"] + sorted([c for c in wide.columns if c != \"matchday\"])\nwide = wide[cols]\n\nwide_outfile = \"data/goals_by_matchday_wide_2023_2024.csv\"\nwide.to_csv(wide_outfile, index=False, encoding=\"utf-8\")\nprint(f\"Table large écrite dans {wide_outfile}\")\nprint(wide.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nÉcrit 760 lignes dans data/premier_league_goals_by_match_2023_2024.csv\nAgrégat par journée écrit dans premier_league_goals_by_matchday_2023_2024.csv\nTable large écrite dans data/goals_by_matchday_wide_2023_2024.csv\n   matchday  goals_2023  goals_2024\n0         1          28          21\n1         2          30          32\n2         3          31          30\n3         4          41          23\n4         5          24          30\n```\n:::\n:::\n\n\n::: {#928c7101 .cell execution_count=7}\n``` {.python .cell-code}\n# Compute the total number of goals in 2023 and 2024\ntotal_goals_2023 = wide[\"goals_2023\"].sum()\ntotal_goals_2024 = wide[\"goals_2024\"].sum()\n\nprint(f\"Total goals in 2023: {total_goals_2023}\")\nprint(f\"Total goals in 2024: {total_goals_2024}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal goals in 2023: 1246\nTotal goals in 2024: 1115\n```\n:::\n:::\n\n\n::: {#536d3b83 .cell execution_count=8}\n``` {.python .cell-code}\n# Create global data.\n\n# Build datasets with a \"Group\" column\ndata_2023 = pd.DataFrame({\n    \"Goals\": wide[\"goals_2023\"],\n    \"Season\": \"2023/2024\"\n})\n\ndata_2024 = pd.DataFrame({\n    \"Goals\": wide[\"goals_2024\"],\n    \"Season\": \"2024/2025\"\n})\n\n# Merge them\ndata_2_seasons = pd.concat([data_2023, data_2024])\ndata_2_seasons\nprint(\"Data for 2023/2024:\")\ndata_2023\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData for 2023/2024:\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Goals</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>29</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>27</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>33</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>37</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>34</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>38</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>27</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>28</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>23</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>39</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>35</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>39</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>45</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>37</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>34</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>34</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>36</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>30</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>32</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>29</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>35</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>40</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>32</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>33</td>\n      <td>2023/2024</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>2023/2024</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#46e85a87 .cell execution_count=9}\n``` {.python .cell-code}\n# Boxplot des buts par saison\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6, 4))\n\n# Boxplot with both distributions overlayed\nsns.boxplot(\n    x=\"Season\", \n    y=\"Goals\", \n    data=data_2_seasons,\n    palette=\"Set2\",\n    width=0.6,\n    fliersize=3\n)\n\n\n# Add mean points\nmedian = data_2_seasons.groupby(\"Season\")[\"Goals\"].median()\nfor i, m in enumerate(median):\n    plt.scatter(i, m, color=\"red\", marker=\"D\", s=50, zorder=3, label=\"Median\" if i == 0 else \"\")\n\n# Title tells the story\nplt.title(\"Goals Per Season\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"Goals were higher in 2023/2024 than in 2024/2025.\",\n             fontsize=10, color=\"gray\")\n\nplt.ylabel(\"Goals\", fontsize=12)\nplt.xlabel(\"\")\n\n# Cleaner look\nsns.despine()\nplt.grid(visible=False)\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/v8/l5q0bw4s2ln17s59y7cc86rm0000gn/T/ipykernel_35159/619544620.py:8: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-10-output-2.png){width=515 height=380}\n:::\n:::\n\n\nTo take a closer look, we can use Kernel Density Estimation (KDE) plots, which provide a smooth view of the underlying distribution and make it easier to spot subtle differences.\n\n::: {#a6f70beb .cell execution_count=10}\n``` {.python .cell-code}\nplt.figure(figsize=(7.24, 4.07), dpi=100)  # ~724x407 px\n\nsns.kdeplot(\n    data=data_2_seasons,\n    x=\"Goals\",\n    hue=\"Season\",\n    fill=True,\n    alpha=0.4,\n    common_norm=False,\n    palette=\"Set2\",\n    linewidth=2\n)\n\nplt.title(\"Kernel Density Estimation of Goals Per Season\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"2023/2024 shows greater variability, while 2024/2025 is more concentrated around 30 goals.\", \n             fontsize=10, color=\"gray\")\n\nplt.xlabel(\"Goals\")\nplt.ylabel(\"Density\")\n\nsns.despine()\nplt.grid(False)\n\n  # ≈ 50 KB\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-11-output-1.png){width=645 height=422}\n:::\n:::\n\n\nThe KDE graph confirms that the two distributions are very similar, showing a high degree of overlap. The Kolmogorov-Smirnov (KS) statistical test of 0.976 also indicates that there is no significant difference between the two groups. To extend the analysis, we can now examine the cumulative distribution of the target variable.\n\n::: {#1640dc88 .cell execution_count=11}\n``` {.python .cell-code}\n# Cumulative distribution\nplt.figure(figsize=(7.24, 4.07), dpi=100)  # ~724x407 px\nsns.histplot(\n    data=data_2_seasons,\n    x=\"Goals\",\n    hue=\"Season\",\n    stat=\"density\",\n    common_norm=False,\n    fill=False,\n    element=\"step\",\n    bins=len(df_all),\n    cumulative=True,\n    palette=\"Set2\"\n)\n\n# Titles tell the story\nplt.title(\"Cumulative Distribution of Goals\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"Comparing goal distributions between 2023/2024 and 2024/2025\", fontsize=10)\n\n# Labels & cleanup\nplt.xlabel(\"Goals\")\nplt.ylabel(\"Cumulative proportion\")\nplt.grid(visible=False)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-12-output-1.png){width=636 height=422}\n:::\n:::\n\n\n::: {#4a54a14d .cell execution_count=12}\n``` {.python .cell-code}\ndef bin_numeric(ref, tgt, n_bins=5):\n    \"\"\"\n    Discretize a numeric variable into quantile bins (ex: quintiles).\n    - Quantile thresholds are computed only on the reference dataset.\n    - Extend bins with -inf and +inf to cover all possible values.\n    - Returns:\n        * ref binned\n        * tgt binned\n        * bin labels (Q1, Q2, ...)\n    \"\"\"\n    edges = np.unique(ref.dropna().quantile(np.linspace(0, 1, n_bins + 1)).values)\n    if len(edges) < 3:  # if variable is almost constant\n        edges = np.array([-np.inf, np.inf])\n    else:\n        edges[0], edges[-1] = -np.inf, np.inf\n    labels = [f\"Q{i}\" for i in range(1, len(edges))]\n    return (\n        pd.cut(ref, bins=edges, labels=labels, include_lowest=True),\n        pd.cut(tgt, bins=edges, labels=labels, include_lowest=True),\n        labels\n    )\n\n# Apply binning\nref_binned, tgt_binned, bin_labels = bin_numeric(data_2023[\"Goals\"], data_2024[\"Goals\"], n_bins=5)\n\n# Effectifs par segment pour Reference et Target\nref_counts = ref_binned.value_counts().reindex(bin_labels, fill_value=0)\ntgt_counts = tgt_binned.value_counts().reindex(bin_labels, fill_value=0)\n\n# Convertir en proportions\nref_props = ref_counts / ref_counts.sum()\ntgt_props = tgt_counts / tgt_counts.sum()\n\n# Construire un DataFrame pour seaborn\ndf_props = pd.DataFrame({\n    \"Segment\": bin_labels,\n    \"2023/2024\": ref_props.values,\n    \"2024/2025\": tgt_props.values\n})\n\n# Restructurer en format long\ndf_long = df_props.melt(id_vars=\"Segment\", \n                        value_vars=[\"2023/2024\", \"2024/2025\"], \n                        var_name=\"Source\", \n                        value_name=\"Proportion\")\n\n# Style sobre\nsns.set_theme(style=\"whitegrid\")\n\n# Barplot avec proportions\nplt.figure(figsize=(7.24, 4.07), dpi=100)  # ~724x407 px\nsns.barplot(\n    x=\"Segment\", y=\"Proportion\", hue=\"Source\",\n    data=df_long, palette=\"Set2\"\n)\n\n# Titre et légende\n# Titles with story\nplt.title(\"Proportion Comparison by Segment (Goals)\", fontsize=14, weight=\"bold\")\nplt.suptitle(\"Across all quantile segments (Q1–Q5), proportions are different\", fontsize=10, color=\"gray\")\n\nplt.xlabel(\"Quantile Segment (Q1 - Q5)\")\nplt.ylabel(\"Proportion\")\nplt.legend(title=\"Dataset\", loc=\"upper right\")\nplt.grid(False)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-13-output-1.png){width=645 height=422}\n:::\n:::\n\n\n::: {#6e2495e9 .cell execution_count=13}\n``` {.python .cell-code}\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Example: goals data\nx = np.sort(data_2023[\"Goals\"].dropna().values)\ny = np.sort(data_2024[\"Goals\"].dropna().values)\n\n# Compute common quantiles\nquantiles = np.linspace(0, 1, min(len(x), len(y)))\nqx = np.quantile(x, quantiles)\nqy = np.quantile(y, quantiles)\n\n# Apply seaborn style\nsns.set_style(\"white\")          # removes background grid\npalette = sns.color_palette(\"Set2\", 2)\n\n# Scatter\nsns.scatterplot(x=qx, y=qy, color=palette[0], s=60, label=\"Q-Q Points\")\n\n# 45° reference line\nplt.plot([min(qx.min(), qy.min()), max(qx.max(), qy.max())],\n         [min(qx.min(), qy.min()), max(qx.max(), qy.max())],\n         color=palette[1], linestyle=\"--\", label=\"2024 = 2023\")\n\n# Titles and labels\nplt.title(\"Q-Q Plot of Goals (2023/2024 vs 2024/2025)\", fontsize=14)\nplt.xlabel(\"Quantiles of 2023/2024\", fontsize=12)\nplt.ylabel(\"Quantiles of 2024/2025\", fontsize=12)\n\n# No grid\nplt.grid(False)\n\n# Legend\nplt.legend()\n\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-14-output-1.png){width=589 height=457}\n:::\n:::\n\n\n::: {#9f65f9b4 .cell execution_count=14}\n``` {.python .cell-code}\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Extract the two series\nx = data_2023[\"Goals\"].dropna().values\ny = data_2024[\"Goals\"].dropna().values\n\n# Compute QQ plot\nplt.figure(figsize=(7.24, 4.07), dpi=100)  # ~724x407 px\nsm.qqplot_2samples(x, y, line='45')   # '45' draws y=x line\nplt.title(\"Q-Q Plot of Goals: 2023/2024 vs 2024/2025\")\nplt.xlabel(\"Quantiles of 2023/2024\")\nplt.ylabel(\"Quantiles of 2024/2025\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 724x407 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](psi_cramer_v_files/figure-html/cell-15-output-2.png){width=589 height=455}\n:::\n:::\n\n\n::: {#d178f2e5 .cell execution_count=15}\n``` {.python .cell-code}\ncolumns = [x for x in data_2023.columns if x != \"Season\"]\nprint(data_2023[\"Goals\"].value_counts())\n    # Generate the report\npath = representativity_report(data_2023, data_2024, columns, output=\"representativity_plot.xlsx\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGoals\n30    8\n34    3\n37    3\n33    3\n32    2\n36    2\n35    2\n39    2\n28    2\n27    2\n29    2\n38    1\n23    1\n24    1\n45    1\n41    1\n31    1\n40    1\nName: count, dtype: int64\n```\n:::\n:::\n\n\n",
    "supporting": [
      "psi_cramer_v_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}