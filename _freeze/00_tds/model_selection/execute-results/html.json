{
  "hash": "2a2bc27976db1ab552c39f26752fa2e9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Model Selection\"\nsubtitle: \"\"\ndate: last-modified\nsidebar: auto\nnumber-sections: false\ntoc: true\nauthor:\n  - Jumbong Junior \n\ncategories: []\ntags: [\"Model Selection\"]\ntitle-block-banner: false\nbibliography: references.bib\nformat: \n  html: \n    mainfont: Times New Roman\n    fontsize: 1.1em\n\njupyter: python3\nnotice: |\n    @wasserman2004all \n---\n\n\n\n\n\n\n\n\n\n\n\n**Introduction**\n\nReducing the number of variables in a regression model is not merely a technical exercise; it is a strategic choice that must be guided by the objectives of the analysis. In a previous work, we demonstrated how simple tools, such as correlation analysis or the Variance Inflation Factor (VIF), can already shrink a dataset with hundreds of predictors into a far more compact model. Yet, even after this initial reduction, models often still contain too many variables to work effectively. A smaller model with fewer predictors offers several advantages: it may yield better predictions than a larger model, it is more parsimonious—hence easier to interpret—and it often generalizes better. As more variables are added, the model’s bias decreases but its variance increases. This is the essence of the bias–variance trade-off: too few variables lead to high bias (underfitting), whereas too many lead to high variance (overfitting). Good predictive performance requires a balance between the two.\n\nThis is where variable selection and dimension reduction methods come into play. There are multiple approaches to address this challenge. Some methods inherently handle multicollinearity, such as Principal Component Analysis (PCA) combined with linear regression, or sparse regression techniques like the Lasso. Others—such as traditional model selection methods—require explicit treatment of multicollinearity, for example by monitoring the VIF. In model selection, two core problems arise: (i) assigning a score to each model that reflects, in some sense, how “good” the model is, and (ii) searching through the set of candidate models to identify the one with the best score.\n\nImportantly, the choice of scoring criterion depends on the fundamental objective of the regression. In linear regression, three main objectives can be distinguished:\n\n1. **Parameter estimation** – obtaining stable and precise coefficient estimates.\n2. **Variable selection** – identifying the predictors whose coefficients are truly nonzero and significant.\n3. **Prediction** – forecasting future values of the response variable as accurately as possible.\n\nA model chosen to minimize the mean squared error of the coefficients (parameter estimation) is not necessarily the best for identifying the most relevant variables (variable selection) or for maximizing predictive accuracy (prediction). In this article, we focus on model selection methods. We first review the different scoring criteria used for model selection, and then present the strategies that allow us to navigate the space of possible models and select the most relevant variables according to the goal of the regression. The first section introduces the framework of model selection. The second section discusses the different scoring criteria used to evaluate models.\n\n\n# Framework of this paper.\n\nIn this section, we provide a brief overview of the linear regression model. We begin by describing the dataset, including the number of observations and the number of covariates. We then introduce the model itself and outline the assumptions made about the data.\n\nWe assume that we have a dataset with $n$ observations and $p$ covariates. The response variable is denoted by $Y$ is continuous and the covariates are denoted by $X_1, \\ldots, X_p$. We assume that the relationship between the response variable and the covariates is linear, that is:\n$$\nY_i = \\beta_0 + \\sum_{j=1}^{p} \\beta_j X_{ij} + \\epsilon_i\n$$\n\nfor $i = 1, \\ldots, n$, where $\\beta_0$ is the intercept, $\\beta_j$ is the coefficient of the $j$-th covariate, and $\\epsilon_i$ is the error term. We assume that the error term is independent and identically distributed (i.i.d.) with mean zero and variance $\\sigma^2$. \n\n\n# Scoring models\n\nIn model selection, the first challenge is to assign a score to each model, where a model is defined by a particular subset of covariates. This section explains how models can be scored.\n\nLet us first discuss the problem of scoring models. Let $S \\subset \\{1, \\ldots, p\\}$ and let $\\mathcal{X}_S = \\{X_j : j \\in S\\}$ denote a subset of the covariates. Let $\\beta_S$ denote the coefficients of the corresponding set of covariates and let $\\hat{\\beta}_S$ denote the least squares estimate of $\\beta_S$. Also, let $X_S$ denote the $X$ matrix for this subset of covariates and define $\\hat{r}_S(x) = \\hat{\\beta}_{0,S} + \\sum_{j \\in S} \\hat{\\beta}_j x_j,$ to be the estimated regression function. The predicted values from model $S$ are denoted by $\\hat{Y}_i(S) = \\hat{r}_S(X_i)$. The $\\textbf{prediction risk}$ is defined to be\n\n$$\n\\begin{equation}\nR(S) = \\sum_{i=1}^{n} \\mathbb{E}\\left(\\hat{Y}_i(S) - Y_i^*\\right)^2\n\\end{equation}\n$$\n\nwhere $Y_i^*$ is the future observation of $Y_i$ at the covariate $X_i$. \nThe goal of model selection is to find the subset $S$ that makes the prediction risk $R(S)$ small.\n\nWith data, we cannot compute the prediction risk $R(S)$ directly. In this situation, we generally use its estimate $\\hat{R}(S)$ based on the available data. The estimation of the prediction risk are used as our scoring criteria. \n\nThe naive estimate of the prediction risk that we can use is : the $\\textbf{training error}$, which is defined as\n\n$$\n\\hat{R_{tr}}(S) = \\sum_{i=1}^{n} \\left(\\hat{Y}_i(S) - Y_i\\right)^2\n$$\n\nwhere $Y_i$ is the observed value of the response variable for the $i$-th observation.\n\nHowever, the training error is very biased as an estimate of the prediction risk. It is always smaller than the prediction risk $R(S)$. In fact,\n\n$$\nbias(\\hat{R_{tr}}(S)) = \\mathbb{E}\\left(\\hat{R_{tr}}(S)\\right) - R(S) = -2\\sum_{i=1}^{n} \\mathbb{Cov}\\left(\\hat{Y}_i(S), Y_i\\right)\n$$\n\nWhat explains this biais is that the data is used twice: once to fit the model and once to compute the training error. When we fit a complex model, with many parameters, the covariance $\\mathbb{Cov}\\left(\\hat{Y}_i(S), Y_i\\right)$ will be large and the bias of the training error will get worse. This is why we need to use a more reliable estimate of the prediction risk. \n\n## Mallow's $C_p$ statistic\n\nThe Mallow's $C_p$ statistic is a popular method for model selection. It is defined as:\n$$\n\\hat{R}(S) = \\hat{R_{tr}}(S) + 2|S| \\hat{\\sigma}^2\n$$\n\nwhere $|S|$ is the number of terms in $S$ and $\\hat{\\sigma}^2$ is the estimated of $\\sigma^2$, the variance of the error term obtained from the full model with all variables($k$). It is a measure of the training error plus a biais correction. The first term measures the fit of the model to the data, while the second term measures the complexity of the model. More the model is complex, more the second term will be large and the Mallow's $C_p$ statistic will be large. The goal is to find the model that minimizes the Mallow's $C_p$ statistic.\nThe Mallow's $C_p$ statistic is seen as a trade-off between the fit of the model and its complexity. Thus find a good model involves trading off fit and complexity.\n\n\n## Likelihood and penalization\n\nThe approach below to estimate the prediction risk is based on the maximum likelihood estimation of the parameters. \nIn the hypothesis that the error term is normally distributed, the likelihood function is given by:\n$$\n\\begin{align*}\n\\mathcal{l}(Y, \\beta, \\sigma^2)\n&= \\log l(Y, \\beta, \\sigma^2) \\\\\n&= -\\frac{n}{2} \\log(2\\pi) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (Y_i - X_i\\beta)^2 - \\frac{n}{2} \\log(\\sigma^2).\n\\end{align*}\n$$\n\nIf you compute the maximum likelihood estimate of the parameters $\\beta$ and $\\sigma^2$, for the model $S$, that have $|S|$ variables, you will get respectively :\n$\\hat{\\beta(S)_{MV}} = \\hat{\\beta(S)_{MCO}}$ and $\\hat{\\sigma(S)^2_{MV}} = \\frac{1}{n}\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i(S))^2$.\n\nThe log-likelihood of the model for the model $S$ which has $|S|$ variables is then given by:\n$$\n\\mathcal{l(S)} = -\\frac{n}{2}(1 + \\log(2\\pi)) - \\frac{n}{2} \\log \\frac{\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i(S))^2}{n}\n$$\n\nChoosing the model that maximizes the log-likelihood is equivalent to choosing the model that have the smallest residual sum of squares (RSS), that is:\n$$\n\\hat{R}(S) = \\frac{1}{n}\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i(S))^2\n$$\n\nIn other to minimize a criterion, we work with the opposite of the log-likelihood and the criteria will be generally defined as:\n$$\n- 2\\mathcal{l}(S) + 2|S| f(n)  \n$$\n\nwhere $f(n)$ is a function of penalization that depends on the sample size $n$. This relation allows us to define the AIC and BIC criteria, which are defined below.\n\n### Akaike Information Criterion (AIC)\n\nAnother method for model selection is the Akaike Information Criterion (AIC). The idea behind the AIC is to find a model that minimizes the information loss.  The idea is to choose S to minimize the AIC criterion, which is defined as:\n$$\n\\text{AIC}(S) =  - 2\\mathbfcal{l}_S + 2|S|\n$$\nwhere $\\mathbfcal{l}_S$ is the log-likelihood of the model $S$ evaluated at the maximum likelihood estimates of the parameters. Here $f(n) = 2$.\n\nThis can be thought of goodness of fit plus a complexity. When we want to choose two models, we will prefer the one with the lower AIC. \n\n\n### Bayesian Information Criterion (BIC)\n\nThe Bayesian Information Criterion (BIC) is another method for model selection. It is similar to the AIC, and BIC is defined as:\n$$\n\\text{BIC}(S) = -2\\mathbfcal{l}_S + 2|S| \\frac{1}{2} \\log(n)\n$$\n\nwhere $\\mathbfcal{l}_S$ is the log-likelihood of the model $S$ evaluated at the maximum likelihood estimates of the parameters. \nWe call it Bayesian Information Criterion because it can be derived from a Bayesian perspective. In fact let $S = \\{S_1, \\ldots, S_m\\}$ denoted a set of models. When we assigns a prior probability to each model $S_i$ as $\\pi(S_i) = \\frac{1}{m}$, the posterior probability of the model $S_i$ given the data is proportional to the likelihood of the model $S_i$ given the data, that is:\n$$\n\\pi(S_i | \\text{data}) \\propto \\frac{e^{-\\frac{1}{2} \\text{BIC}(S_i)}}{\\sum_{j=1}^{m} e^{-\\frac{1}{2} \\text{BIC}(S_j)}}\n$$\n\nHence, choosing the model that minimizes the BIC is equivalent to choosing the model with the highest posterior probability given the data. It also has a interpretation in terms of description length. It puts a more severe penalty for complexity than the AIC, which is why it is often preferred when the sample size is large. In fact, by definition, $f(n) = \\frac{1}{2} \\log(n)$. Ainsi, more the sample size $n$ is large, more the penalty is lower when we compare with the penalty of the AIC. However, this penalty is generally greater than 2 (When $n > 7$), donc the BIC tends to select smaller models than the AIC. The use of this criterion is similar to the use of the AIC, so when we want to choose two models, we will prefer the one with the lower BIC. \n\n## Leave-One-Out Cross-Validation (LOOCV) and k-Fold Cross-Validation\n\nYet another method for model selection is leave-one-out cross-validation (LOOCV). In this case, the risk estimator is given by:\n\n$$\n\\hat{R}_{LOOCV}(S) = \\sum_{i=1}^{n} \\left(\\hat{Y}_{-i}(S) - Y_{(i)}\\right)^2\n$$\n\nWhere \\hat{Y}_{-i}(S) is the prediction for $Y_i$ using the model $S$ fitted on all data except the $i$-th observation, and $Y_{(i)}$ is the $i$-th observation of the response variable. It can be shown that \n$$\n\\hat{R}_{LOOCV}(S) = \\sum_{i=1}^{n} (\\frac{\\hat{Y}_{i}(S) - Y_{i}}{1 - h_{ii}(S)})^2\n$$\nwhere $h_{ii}(S)$ is  the $i$-th diagonal element of the hat matrix $H_S = X_S(X_S^TX_S)^{-1}X_S^T$ for the model $S$.\n\nThus, one need not actually drop each observation and refit the model. A generalization of LOOCV is k-fold cross-validation. \n\n## K-Fold Cross-Validation\n\n\nIn this approach, the data is divided into $k$ groups, or *folds* (commonly $k = 5$ or $k = 10$). One fold is omitted, and the model is fitted using the remaining $k-1$ folds. The fitted model is then used to predict the responses for the omitted fold. The risk is estimated as\n\n$$\n\\sum_i \\left( Y_i - \\hat{Y}_i \\right)^2,\n$$\n\nwhere the sum is taken over the data points in the omitted fold. This process is repeated for each of the $k$ folds, and the average of the $k$ risk estimates is taken as the overall risk estimate.\n\nThis method is particularly appropriate when the primary objective of the regression is **prediction**. In this context, alternative performance measures such as the **Mean Absolute Error (MAE)** or the **Root Mean Squared Error (RMSE)** can also be used to evaluate the model’s predictive performance.\n\n\n## Other criteria\n\n\nIn the literature, in addition to the criteria presented above, there are other measures that can be used for model selection. For example, the adjusted $R^2$ is a widely used criterion, defined as\n\n$$\n\\text{Adjusted } R_a^2(S) = 1 - \\frac{n - 1}{n - |S| - 1} \\left( 1 - R^2(S) \\right).\n$$\n\nAnother option is to use nested model tests, such as the **F-test**. The F-test compares two nested models—specifically, a model $S_1$ whose covariates form a subset of those in a larger model $S_2$. The null hypothesis states that the additional variables in $S_2$ do not improve the fit of the model compared to $S_1$.\n\nThe methods presented above primarily address two key objectives of linear regression: **parameter estimation** and **variable selection**.\n\n\n\n# Selection Procedure\n\n\nOnce models can be scored, the next step is to search either the entire space of possible models or a selected subset to find the one with the best score. With $k$ covariates, there are $2^k - 1$ possible models—a number that quickly becomes prohibitive for large $k$ (for example, more than one million when $k = 20$). In such cases, exhaustive search is impractical, and heuristic methods are preferred. Broadly, model selection strategies fall into two categories: **exhaustive search** and **stepwise search**.\n\n\n\n## Exhaustive Search\n\nThis approach evaluates every possible model and selects the one with the best score. Feasible only for small $k$, as computation becomes prohibitive for large numbers of covariates.\n\n## Stepwise Search\n\nThe methods presented here aim to identify a *local optimum*—that is, a model that performs better than its neighboring models. Such methods are generally recommended only when exhaustive search is not feasible (for example, when both $n$ and $p$ are large).\n\n### Forward Stepwise Selection\n\nIn this approach, we first select a scoring criterion (AIC, BIC, Mallows’ $C_p$, etc.). We start with an empty model and, at each step, add the variable that provides the greatest improvement in the criterion. This process continues until no variable improves the score or all variables are included in the model.\n\n### Backward Stepwise Selection\n\nHere, we also begin by selecting a scoring criterion (AIC, BIC, Mallows’ $C_p$, etc.). We start with the full model containing all variables and, at each step, remove the variable whose removal most improves the criterion. We continue removing variables one at a time until no further improvement is possible or only the essential variables remain.\n\n### Stepwise Selection (Mixed Method)\n\nIn the mixed approach, we again begin by selecting a scoring criterion (AIC, BIC, Mallows’ $C_p$, etc.). We start with an empty model and add variables one at a time, as in forward selection, until no additional variable improves the score. Then, we proceed as in backward selection, removing variables one at a time if doing so improves the criterion. This process stops when no further improvement can be made or all variables are included in the model.\n\n\n\n\n# Application\n\nIn practice, before use the model selection techniques, we need to ensure that the covariates are not highly correlated. To do that, we will use the technique below.\n\n- The first step is to remove the covariates that are not relevant to the response variable using expert approch, treatment of missing values, etc.\n\n- Next, define a threshold for the correlation between covariates and the response variable. For example, we can set the threshold to 0.6. This will help us to remove the covariates that are not correlated with the response variable. We will not use this technique here to let enough covariates to selection techniques.\n\n- Next, define a threshold for the correlation between covariates. For example, we can set the threshold to 0.7. Compute the correlation matrix of the covariates. If two covariates have a correlation greater than the threshold, we will consider them as highly correlated and return the one with the highest correlation with the response variable or the one with has the most interpretation metier.\n\n- Next, we will compute the variance inflation factor (VIF) for all remaining covariates. And if the VIF of a covariate is greater than 5 or 10, we will consider it as highly correlated with the other covariates and remove it from the model. \n\n- Finally, we will use the model selection techniques discussed above to select the best model. We will use the Mallow's $C_p$ to score the models and select the one with the best score and backward stepwise selection to select variables. We will implement a stepwise selection procedure that will allow us to select the best model based on all criteria discussed above and the backward or forward stepwise selection strategy.\n\n## Presentation of the dataset\n\n\nWe use the Communities dataset from the UCI Machine Learning Repository, which contains socio-economic and demographic information about communities in the United States. It includes over 100 variables, with the response variable being the number of violent crimes per population (`violentCrimesPerPop`). We apply the model selection techniques discussed above to identify the variables most strongly associated with the response.\n\n\n\n## Handling Missing Values\n\nIn this analysis, we remove all rows containing missing values. An alternative approach is to drop variables with a high proportion of missing values (e.g., more than 10%) and then determine whether the remaining missing values are Missing At Random (MAR), applying an appropriate imputation method if needed. Here, however, we remove all incomplete rows. After this step, the dataset contains no missing values and includes 103 variables, comprising the response variable `violentCrimesPerPop` and the covariates.\n## Selection of Relevant Variables Using Expert Judgment\n\nWe apply expert knowledge to assess the relevance of each variable and determine whether its correlation with the response variable is meaningful. This involves consultation between the statistician and domain experts to understand the context and importance of each variable. For this dataset, we remove `communityname` for simplicity, as it is a categorical variable with many levels, and `fold`, which is used only for cross-validation. This leaves 101 variables, including the response variable `violentCrimesPerPop` and the covariates.\n\n## Reducing Covariates Using a Correlation Threshold of 0.6\n\nTo further reduce the number of covariates, we compute the correlation matrix for all covariates and the response variable. When multiple covariates are highly correlated with each other (correlation greater than 0.6), we retain only the one with the highest correlation to the response. This approach reduces the number of covariates while mitigating multicollinearity.\n\nAfter applying this and the previous steps, the dataset is reduced to 19 covariates with the VIF below 5. These steps are documented in detail in my article [Feature Selection](https://juniorjumbong.github.io/personal-website/00_tds/feature_selection.html).\n$$\n\\begin{center}\n\\scriptsize\n\\caption{Variance Inflation Factor (VIF) for Selected Variables}\n\\begin{tabular}{lc}\n\\hline\nVariable              & VIF      \\\\\n\\hline\npctWFarmSelf          & 1.329818 \\\\\nindianPerCap          & 1.067939 \\\\\nAsianPerCap           & 1.221415 \\\\\nPctEmplManu           & 1.700146 \\\\\nPctEmplProfServ       & 1.734482 \\\\\nPctKids2Par           & 2.442528 \\\\\nPctWorkMom            & 1.232448 \\\\\nPctImmigRec10         & 1.668404 \\\\\nPctVacantBoarded      & 1.828584 \\\\\nPctVacMore6Mos        & 1.816510 \\\\\nMedYrHousBuilt        & 2.587958 \\\\\nPctWOFullPlumb        & 1.475350 \\\\\nMedRentPctHousInc     & 1.462474 \\\\\nMedOwnCostPctIncNoMtg & 1.452386 \\\\\nPctSameHouse85        & 2.382161 \\\\\nLandArea              & 1.289480 \\\\\nPopDens               & 2.360121 \\\\\nPctUsePubTrans        & 2.127730 \\\\\nLemasPctOfficDrugUn   & 1.308731 \\\\\n\\hline\n\\end{tabular}\n\\end{center}\n$$\n\n\n## Model Selection with Backward Stepwise Selection\n\nWith 19 variables, the total number of possible models is $524,288$, which may be computationally infeasible for some systems. To reduce the number of models to evaluate, we use a stepwise selection procedure. We implement a function, `stepwise_selection`, that selects the most relevant variables based on a chosen selection criterion and method (forward, backward, or mixed). In this example, we use Mallows’ $C_p$ as the selection criterion and apply both forward and backward stepwise selection methods. \n\n::: {#23cdf48b .cell execution_count=1}\n``` {.python .cell-code}\n# Lire les noms de colonnes à partir du fichier .names\nwith open(\"communities.names\", \"r\") as f:\n    lines = f.readlines()\n\n# Extraire les noms à partir des lignes définissant les attributs\ncolumns = []\nstart_extracting = False\nfor line in lines:\n    if line.startswith(\"@attribute\"):\n        parts = line.split()\n        if len(parts) > 1:\n            columns.append(parts[1])\n    elif \"attribute information:\" in line.lower():\n        start_extracting = True\n    elif start_extracting and line.strip() and not line.startswith('@'):\n        # handle lines like: \"1. state: continuous\"\n        if ':' in line:\n            name = line.split(':')[0].strip().split()[-1]\n            columns.append(name)\n\n# Supprimer les doublons tout en conservant l'ordre\nfrom collections import OrderedDict\ncolumns = list(OrderedDict.fromkeys(columns))\n\n# Vérifie que ça correspond au nombre de colonnes du fichier data\nprint(f\"{len(columns)} colonnes uniques\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n135 colonnes uniques\n```\n:::\n:::\n\n\n::: {#9efc1ae8 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Charger le fichier communities.data\ndf = pd.read_csv(\"communities.data\", header=None, names=columns, na_values='?')\n\n# Vérifier la forme\nprint(df.shape)\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(1994, 135)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>county</th>\n      <th>community</th>\n      <th>communityname</th>\n      <th>fold</th>\n      <th>population</th>\n      <th>householdsize</th>\n      <th>racepctblack</th>\n      <th>racePctWhite</th>\n      <th>racePctAsian</th>\n      <th>...</th>\n      <th>LemasPctOfficDrugUn</th>\n      <th>PolicBudgPerPop</th>\n      <th>ViolentCrimesPerPop</th>\n      <th>Statistics</th>\n      <th>Population)</th>\n      <th>Papers</th>\n      <th>Request</th>\n      <th>paper</th>\n      <th>States</th>\n      <th>Baveja</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Lakewoodcity</td>\n      <td>1</td>\n      <td>0.19</td>\n      <td>0.33</td>\n      <td>0.02</td>\n      <td>0.90</td>\n      <td>0.12</td>\n      <td>...</td>\n      <td>0.32</td>\n      <td>0.14</td>\n      <td>0.20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tukwilacity</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.16</td>\n      <td>0.12</td>\n      <td>0.74</td>\n      <td>0.45</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.67</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Aberdeentown</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.49</td>\n      <td>0.56</td>\n      <td>0.17</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.43</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>5.0</td>\n      <td>81440.0</td>\n      <td>Willingborotownship</td>\n      <td>1</td>\n      <td>0.04</td>\n      <td>0.77</td>\n      <td>1.00</td>\n      <td>0.08</td>\n      <td>0.12</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42</td>\n      <td>95.0</td>\n      <td>6096.0</td>\n      <td>Bethlehemtownship</td>\n      <td>1</td>\n      <td>0.01</td>\n      <td>0.55</td>\n      <td>0.02</td>\n      <td>0.95</td>\n      <td>0.09</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 135 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#bcb1e4bd .cell execution_count=3}\n``` {.python .cell-code}\ndf['fold'].value_counts()  # Voir combien de points dans chaque fold\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nfold\n1     200\n2     200\n3     200\n4     200\n5     199\n6     199\n7     199\n8     199\n9     199\n10    199\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {#5a331266 .cell execution_count=4}\n``` {.python .cell-code}\n# Liste des colonnes sans aucune valeur manquante\ncols_without_na = df.columns[df.notna().all()].tolist()\n\nprint(f\"{len(cols_without_na)} colonnes sans NA :\")\n\nprint(cols_without_na)\ndf_clean = df.dropna(axis=1)\nprint(len(df_clean.columns))\ndf_clean.to_csv(\"communities_clean.csv\", index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n103 colonnes sans NA :\n['state', 'communityname', 'fold', 'population', 'householdsize', 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap', 'indianPerCap', 'AsianPerCap', 'HispPerCap', 'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ', 'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85', 'PctSameCity85', 'PctSameState85', 'LandArea', 'PopDens', 'PctUsePubTrans', 'LemasPctOfficDrugUn', 'ViolentCrimesPerPop']\n103\n```\n:::\n:::\n\n\n::: {#834371ac .cell execution_count=5}\n``` {.python .cell-code}\n# Extract response variable and covariates\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndf = pd.read_csv(\"communities_clean.csv\")\nresponse = 'ViolentCrimesPerPop'\ncovariates = [col for col in df.columns if col not in ['fold', response, 'state', 'county', 'community', 'communityname', 'NumStreet']]\n\n\nspearman_corr = df[covariates + [response]].corr(method='spearman')\nplt.figure(figsize=(12, 10))\nsns.heatmap(spearman_corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Correlation Matrix Heatmap\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](model_selection_files/figure-html/cell-6-output-1.png){width=1029 height=942}\n:::\n:::\n\n\n::: {#371b9b45 .cell execution_count=6}\n``` {.python .cell-code}\n# Step 2: Correlation of each variable with response R\nspearman_corr_with_R = spearman_corr[response].drop(response)  # exclude R-R\n\n# Step 3: Identify pairs of covariates with strong inter-correlation (e.g., > 0.9)\nstrong_pairs = []\nthreshold = 0.6\ncovariates = spearman_corr_with_R.index\n\nfor i, var1 in enumerate(covariates):\n    for var2 in covariates[i+1:]:\n        if abs(spearman_corr.loc[var1, var2]) > threshold:\n            strong_pairs.append((var1, var2))\n\n# Step 4: From each correlated pair, keep only the variable most correlated with R\nto_keep = set()\nto_discard = set()\n\nfor var1, var2 in strong_pairs:\n    if abs(spearman_corr_with_R[var1]) >= abs(spearman_corr_with_R[var2]):\n        to_keep.add(var1)\n        to_discard.add(var2)\n    else:\n        to_keep.add(var2)\n        to_discard.add(var1)\n\n# Final selection: all covariates excluding the ones to discard due to redundancy\nfinal_selected_variables = [var for var in covariates if var not in to_discard]\n\nfinal_selected_variables\nprint(f\"Number of selected variables: {len(final_selected_variables)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of selected variables: 19\n```\n:::\n:::\n\n\n::: {#99a9f0f2 .cell execution_count=7}\n``` {.python .cell-code}\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nX = df[final_selected_variables]  \n\nX_with_const = add_constant(X)  \n\nvif_data = pd.DataFrame()\nvif_data[\"variable\"] = X_with_const.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i)\n                   for i in range(X_with_const.shape[1])]\n\nvif_data = vif_data[vif_data[\"variable\"] != \"const\"]\n\nprint(vif_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 variable       VIF\n1            pctWFarmSelf  1.329818\n2            indianPerCap  1.067939\n3             AsianPerCap  1.221415\n4             PctEmplManu  1.700146\n5         PctEmplProfServ  1.734482\n6             PctKids2Par  2.442528\n7              PctWorkMom  1.232448\n8           PctImmigRec10  1.668404\n9        PctVacantBoarded  1.828584\n10         PctVacMore6Mos  1.816510\n11         MedYrHousBuilt  2.587958\n12         PctWOFullPlumb  1.475350\n13      MedRentPctHousInc  1.462474\n14  MedOwnCostPctIncNoMtg  1.452386\n15         PctSameHouse85  2.382161\n16               LandArea  1.289480\n17                PopDens  2.360121\n18         PctUsePubTrans  2.127730\n19    LemasPctOfficDrugUn  1.308731\n```\n:::\n:::\n\n\n::: {#cfb4c490 .cell execution_count=8}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom collections import OrderedDict\n\ndef stepwise_selection(df, target, strategy='forward', metric='AIC', verbose=True):\n    \"\"\"\n    Variable selection using stepwise regression (forward or backward) and AIC/BIC criterion.\n    \n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing the predictors and the target column.\n    target : str\n        Name of the target column.\n    strategy : str\n        'forward' or 'backward'.\n    metric : str\n        'AIC' or 'BIC'.\n    verbose : bool\n        Whether to print the steps.\n    \n    Returns\n    -------\n    selected_vars : list\n        List of variables selected in the final model.\n    best_model : statsmodels.regression.linear_model.RegressionResultsWrapper\n        Fitted OLS model with selected variables.\n    history : list of dict\n        Steps taken (variables, metric).\n    \"\"\"\n    # Vérification des NaN\n    if df.isnull().values.any():\n        raise ValueError(\"Des valeurs manquantes sont présentes dans le DataFrame. Veuillez les gérer avant d'appliquer la sélection.\")\n    \n    X = df.drop(columns=[target])\n    y = df[target]\n    variables = list(X.columns)\n    history = []\n    \n    # Initialisation\n    if strategy == 'forward':\n        selected = []\n        remaining = variables.copy()\n    elif strategy == 'backward':\n        selected = variables.copy()\n        remaining = []\n    else:\n        raise ValueError(\"strategy must be 'forward' or 'backward'\")\n    \n    current_score = np.inf\n    best_new_score = np.inf\n    \n    step = 0\n    while True:\n        step += 1\n        scores_with_candidates = []\n        \n        if strategy == 'forward':\n            # Tester chaque variable qui n'est pas dans 'selected'\n            candidates = [var for var in remaining if var not in selected]\n            for candidate in candidates:\n                vars_to_test = selected + [candidate]\n                X_train = sm.add_constant(X[vars_to_test])\n                model = sm.OLS(y, X_train).fit()\n                if metric == 'AIC':\n                    score = model.aic\n                elif metric == 'BIC':\n                    score = model.bic\n                scores_with_candidates.append((score, candidate, vars_to_test))\n            if not scores_with_candidates:\n                break\n            # Chercher la variable qui améliore le plus la métrique\n            scores_with_candidates.sort()\n            best_new_score, best_candidate, vars_to_test = scores_with_candidates[0]\n            \n            if verbose:\n                print(f\"\\nÉtape {step}:\")\n                print(\"Candidats testés:\", [(v, round(s, 2)) for s, v, _ in scores_with_candidates])\n                print(f\"Meilleure variable à ajouter : {best_candidate} (score={round(best_new_score,2)})\")\n            \n            # Critère d'arrêt\n            if len(selected) == 0 or best_new_score < current_score - 1e-6:\n                selected.append(best_candidate)\n                remaining.remove(best_candidate)\n                current_score = best_new_score\n                history.append({\n                    'step': step,\n                    'selected': selected.copy(),\n                    'score': current_score,\n                    'modified': best_candidate\n                })\n            else:\n                if verbose:\n                    print(\"Plus aucune variable n'améliore le score.\")\n                break\n        \n        elif strategy == 'backward':\n            # Tester la suppression de chaque variable restante\n            if len(selected) == 0:\n                break\n            scores_with_candidates = []\n            for candidate in selected:\n                vars_to_test = [var for var in selected if var != candidate]\n                if len(vars_to_test) == 0:\n                    continue\n                X_train = sm.add_constant(X[vars_to_test])\n                model = sm.OLS(y, X_train).fit()\n                if metric == 'AIC':\n                    score = model.aic\n                elif metric == 'BIC':\n                    score = model.bic\n                scores_with_candidates.append((score, candidate, vars_to_test))\n            if not scores_with_candidates:\n                break\n            # Chercher la variable dont la suppression améliore le plus la métrique\n            scores_with_candidates.sort()\n            best_new_score, worst_candidate, vars_to_test = scores_with_candidates[0]\n            \n            if verbose:\n                print(f\"\\nÉtape {step}:\")\n                print(\"Suppressions testées:\", [(v, round(s, 2)) for s, v, _ in scores_with_candidates])\n                print(f\"Meilleure variable à retirer : {worst_candidate} (score={round(best_new_score,2)})\")\n            \n            # Critère d'arrêt\n            if best_new_score < current_score - 1e-6:\n                selected.remove(worst_candidate)\n                current_score = best_new_score\n                history.append({\n                    'step': step,\n                    'selected': selected.copy(),\n                    'score': current_score,\n                    'modified': worst_candidate\n                })\n            else:\n                if verbose:\n                    print(\"Aucune suppression n'améliore le score.\")\n                break\n    \n    # Fit final model\n    X_final = sm.add_constant(X[selected])\n    best_model = sm.OLS(y, X_final).fit()\n    if verbose:\n        print(\"\\nVariables sélectionnées :\", selected)\n        print(f\"Score final ({metric}): {round(best_model.aic if metric=='AIC' else best_model.bic,2)}\")\n    \n    \n    return selected, best_model, history\n\n# Graphique de l'historique des scores\n```\n:::\n\n\n::: {#9cb9bb60 .cell execution_count=9}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nimport matplotlib.pyplot as plt\n\ndef plot_stepwise_crosses(history, all_vars, metric=\"AIC\", title=None):\n    \"\"\"\n    Affiche le graphique stepwise type heatmap à croix :\n    - X : variables explicatives modifiées à au moins une étape (ordre d'apparition)\n    - Y : score (AIC/BIC) à chaque étape (de l'historique)\n    - Croix noire : variable modifiée à chaque étape\n    - Vide ailleurs\n    - Courbe du score\n    \"\"\"\n    n_steps = len(history)\n    scores = [h['score'] for h in history]\n    \n    # Extraire la liste ordonnée des variables effectivement modifiées\n    modified_vars = []\n    for h in history:\n        var = h['modified']\n        if var not in modified_vars and var is not None:\n            modified_vars.append(var)\n    \n    n_mod_vars = len(modified_vars)\n    \n    # Construction des positions X pour les croix (selon modified_vars)\n    mod_pos = [modified_vars.index(h['modified']) if h['modified'] in modified_vars else None for h in history]\n\n    fig, ax = plt.subplots(figsize=(min(1.3 * n_mod_vars, 14), 6))\n    # Placer la croix noire à chaque étape\n    for i, x in enumerate(mod_pos):\n        if x is not None:\n            ax.scatter(x, scores[i], color='black', marker='x', s=100, zorder=3)\n    # Tracer la courbe du score\n    ax.plot(range(n_steps), scores, color='gray', alpha=0.7, linewidth=2, zorder=1)\n    # Axe X : labels verticaux, police réduite (uniquement variables modifiées)\n    ax.set_xticks(range(n_mod_vars))\n    ax.set_xticklabels(modified_vars, rotation=90, fontsize=10)\n    ax.set_xlabel(\"Variables modifiées\")\n    ax.set_ylabel(metric)\n    ax.set_title(title or f\"Stepwise ({metric}) – Variables modifiées à chaque étape\")\n    ax.grid(True, axis='y', alpha=0.2)\n    plt.tight_layout()\n    plt.show()\n\n```\n:::\n\n\n::: {#3d2ff1ae .cell execution_count=10}\n``` {.python .cell-code}\ndf_for_stepwise = df[final_selected_variables + [response]].dropna()\n\n```\n:::\n\n\n::: {#52e404b4 .cell execution_count=11}\n``` {.python .cell-code}\nselected_vars, best_model, history = stepwise_selection(\n    df=df_for_stepwise,\n    target='ViolentCrimesPerPop',\n    strategy='backward',    # Ou 'backward'\n    metric='AIC',          # Ou 'BIC'\n    verbose=True\n)\nprint(best_model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nÉtape 1:\nSuppressions testées: [('pctWFarmSelf', np.float64(-2050.99)), ('PctWOFullPlumb', np.float64(-2050.95)), ('indianPerCap', np.float64(-2050.84)), ('MedRentPctHousInc', np.float64(-2048.38)), ('PctVacMore6Mos', np.float64(-2047.19)), ('PctEmplManu', np.float64(-2045.67)), ('PctImmigRec10', np.float64(-2045.63)), ('PctUsePubTrans', np.float64(-2042.0)), ('PctEmplProfServ', np.float64(-2040.42)), ('MedOwnCostPctIncNoMtg', np.float64(-2039.47)), ('AsianPerCap', np.float64(-2039.39)), ('PctSameHouse85', np.float64(-2037.29)), ('LemasPctOfficDrugUn', np.float64(-2035.93)), ('PopDens', np.float64(-2034.44)), ('PctWorkMom', np.float64(-2031.19)), ('PctVacantBoarded', np.float64(-2021.95)), ('LandArea', np.float64(-2020.45)), ('MedYrHousBuilt', np.float64(-2016.35)), ('PctKids2Par', np.float64(-1246.96))]\nMeilleure variable à retirer : pctWFarmSelf (score=-2050.99)\n\nÉtape 2:\nSuppressions testées: [('PctWOFullPlumb', np.float64(-2052.95)), ('indianPerCap', np.float64(-2052.83)), ('MedRentPctHousInc', np.float64(-2050.35)), ('PctVacMore6Mos', np.float64(-2049.07)), ('PctEmplManu', np.float64(-2047.65)), ('PctImmigRec10', np.float64(-2047.54)), ('PctUsePubTrans', np.float64(-2043.85)), ('PctEmplProfServ', np.float64(-2042.15)), ('MedOwnCostPctIncNoMtg', np.float64(-2041.43)), ('AsianPerCap', np.float64(-2041.35)), ('PctSameHouse85', np.float64(-2039.27)), ('LemasPctOfficDrugUn', np.float64(-2037.86)), ('PopDens', np.float64(-2036.4)), ('PctWorkMom', np.float64(-2033.17)), ('PctVacantBoarded', np.float64(-2023.94)), ('LandArea', np.float64(-2022.31)), ('MedYrHousBuilt', np.float64(-2017.9)), ('PctKids2Par', np.float64(-1227.34))]\nMeilleure variable à retirer : PctWOFullPlumb (score=-2052.95)\n\nÉtape 3:\nSuppressions testées: [('indianPerCap', np.float64(-2054.79)), ('MedRentPctHousInc', np.float64(-2052.31)), ('PctVacMore6Mos', np.float64(-2051.07)), ('PctEmplManu', np.float64(-2049.64)), ('PctImmigRec10', np.float64(-2049.39)), ('PctUsePubTrans', np.float64(-2045.84)), ('PctEmplProfServ', np.float64(-2044.03)), ('MedOwnCostPctIncNoMtg', np.float64(-2043.43)), ('AsianPerCap', np.float64(-2043.35)), ('PctSameHouse85', np.float64(-2041.14)), ('LemasPctOfficDrugUn', np.float64(-2039.86)), ('PopDens', np.float64(-2038.15)), ('PctWorkMom', np.float64(-2034.37)), ('PctVacantBoarded', np.float64(-2025.71)), ('LandArea', np.float64(-2024.0)), ('MedYrHousBuilt', np.float64(-2019.8)), ('PctKids2Par', np.float64(-1169.01))]\nMeilleure variable à retirer : indianPerCap (score=-2054.79)\n\nÉtape 4:\nSuppressions testées: [('MedRentPctHousInc', np.float64(-2054.16)), ('PctVacMore6Mos', np.float64(-2053.0)), ('PctEmplManu', np.float64(-2051.47)), ('PctImmigRec10', np.float64(-2051.2)), ('PctUsePubTrans', np.float64(-2047.79)), ('PctEmplProfServ', np.float64(-2045.85)), ('AsianPerCap', np.float64(-2045.34)), ('MedOwnCostPctIncNoMtg', np.float64(-2045.21)), ('PctSameHouse85', np.float64(-2043.08)), ('LemasPctOfficDrugUn', np.float64(-2041.75)), ('PopDens', np.float64(-2040.09)), ('PctWorkMom', np.float64(-2036.16)), ('PctVacantBoarded', np.float64(-2027.57)), ('LandArea', np.float64(-2025.81)), ('MedYrHousBuilt', np.float64(-2021.8)), ('PctKids2Par', np.float64(-1165.99))]\nMeilleure variable à retirer : MedRentPctHousInc (score=-2054.16)\nAucune suppression n'améliore le score.\n\nVariables sélectionnées : ['AsianPerCap', 'PctEmplManu', 'PctEmplProfServ', 'PctKids2Par', 'PctWorkMom', 'PctImmigRec10', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'MedRentPctHousInc', 'MedOwnCostPctIncNoMtg', 'PctSameHouse85', 'LandArea', 'PopDens', 'PctUsePubTrans', 'LemasPctOfficDrugUn']\nScore final (AIC): -2054.79\n                             OLS Regression Results                            \n===============================================================================\nDep. Variable:     ViolentCrimesPerPop   R-squared:                       0.621\nModel:                             OLS   Adj. R-squared:                  0.618\nMethod:                  Least Squares   F-statistic:                     202.8\nDate:                 Sun, 10 Aug 2025   Prob (F-statistic):               0.00\nTime:                         15:32:22   Log-Likelihood:                 1044.4\nNo. Observations:                 1994   AIC:                            -2055.\nDf Residuals:                     1977   BIC:                            -1960.\nDf Model:                           16                                         \nCovariance Type:             nonrobust                                         \n=========================================================================================\n                            coef    std err          t      P>|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nconst                     0.6121      0.041     14.766      0.000       0.531       0.693\nAsianPerCap               0.0611      0.018      3.374      0.001       0.026       0.097\nPctEmplManu              -0.0475      0.021     -2.298      0.022      -0.088      -0.007\nPctEmplProfServ          -0.0789      0.024     -3.297      0.001      -0.126      -0.032\nPctKids2Par              -0.7673      0.023    -33.369      0.000      -0.812      -0.722\nPctWorkMom               -0.0915      0.020     -4.534      0.000      -0.131      -0.052\nPctImmigRec10             0.0496      0.021      2.356      0.019       0.008       0.091\nPctVacantBoarded          0.1080      0.020      5.402      0.000       0.069       0.147\nPctVacMore6Mos           -0.0437      0.023     -1.941      0.052      -0.088       0.000\nMedYrHousBuilt            0.1306      0.022      5.916      0.000       0.087       0.174\nMedRentPctHousInc         0.0370      0.023      1.615      0.107      -0.008       0.082\nMedOwnCostPctIncNoMtg    -0.0681      0.020     -3.393      0.001      -0.108      -0.029\nPctSameHouse85            0.1011      0.027      3.693      0.000       0.047       0.155\nLandArea                  0.1854      0.033      5.564      0.000       0.120       0.251\nPopDens                   0.0991      0.024      4.078      0.000       0.051       0.147\nPctUsePubTrans            0.0609      0.020      2.990      0.003       0.021       0.101\nLemasPctOfficDrugUn       0.0591      0.015      3.868      0.000       0.029       0.089\n==============================================================================\nOmnibus:                      389.964   Durbin-Watson:                   2.035\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1040.967\nSkew:                           1.034   Prob(JB):                    9.06e-227\nKurtosis:                       5.873   Cond. No.                         29.4\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n::: {#fa50ed13 .cell execution_count=12}\n``` {.python .cell-code}\nall_vars = [col for col in df.columns if col != 'target']\nplot_stepwise_crosses(history, all_vars, metric=\"AIC\", title=\"Sélection de variables – Stepwise\")\n```\n\n::: {.cell-output .cell-output-display}\n![](model_selection_files/figure-html/cell-13-output-1.png){width=368 height=566}\n:::\n:::\n\n\n::: {#34415aed .cell execution_count=13}\n``` {.python .cell-code}\nimport numpy as np\nimport statsmodels.api as sm\n\ndef compute_score(y, X, vars_to_test, metric, full_model_mse=None):\n    X_train = sm.add_constant(X[vars_to_test])\n    model = sm.OLS(y, X_train).fit()\n    n = len(y)\n    p = len(vars_to_test) + 1  # +1 pour la constante\n\n    if metric == 'AIC':\n        return model.aic\n\n    elif metric == 'BIC':\n        return model.bic\n\n    elif metric == 'Cp':\n        if full_model_mse is None:\n            raise ValueError(\"full_model_mse doit être fourni pour calculer Cp Mallows.\")\n        rss = sum(model.resid ** 2)\n        return rss + 2 * p * full_model_mse\n\n    elif metric == 'R2_adj':\n        return -model.rsquared_adj  # négatif pour maximiser\n\n    else:\n        raise ValueError(\"Métrique inconnue. Utilisez 'AIC', 'BIC', 'Cp' ou 'R2_adj'.\")\n\ndef get_best_candidate(y, X, selected, candidates, metric, strategy, full_model_mse=None):\n    scores_with_candidates = []\n    for candidate in candidates:\n        vars_to_test = selected + [candidate] if strategy == 'forward' else [var for var in selected if var != candidate]\n        score = compute_score(y, X, vars_to_test, metric, full_model_mse)\n        scores_with_candidates.append((score, candidate, vars_to_test))\n\n    scores_with_candidates.sort()\n    print(\"Suppressions testées:\", [(v, round(s, 2)) for s, v, _ in scores_with_candidates])\n    return scores_with_candidates[0] if scores_with_candidates else (None, None, None)\n\ndef stepwise_selection(df, target, strategy='forward', metric='AIC', verbose=True):\n    if df.isnull().values.any():\n        raise ValueError(\"Des valeurs manquantes sont présentes dans le DataFrame.\")\n\n    X = df.drop(columns=[target])\n    y = df[target]\n    variables = list(X.columns)\n\n    selected = [] if strategy == 'forward' else variables.copy()\n    remaining = variables.copy() if strategy == 'forward' else []\n\n    # Calcul préalable du MSE du modèle complet pour Cp Mallows\n    if metric == 'Cp':\n        X_full = sm.add_constant(X)\n        full_model = sm.OLS(y, X_full).fit()\n        full_model_mse = sum(full_model.resid ** 2) / (len(y) - len(variables) - 1)\n    else:\n        full_model_mse = None\n\n    current_score = np.inf\n    history = []\n    step = 0\n\n    while True:\n        step += 1\n        candidates = remaining if strategy == 'forward' else selected\n        best_score, best_candidate, vars_to_test = get_best_candidate(y, X, selected, candidates, metric, strategy, full_model_mse)\n\n        if best_candidate is None:\n            if verbose:\n                print(\"Aucun candidat disponible.\")\n            break\n\n        if verbose:\n            action = \"ajouter\" if strategy == 'forward' else \"retirer\"\n            print(f\"\\nÉtape {step}: Meilleure variable à {action} : {best_candidate} (score={round(best_score,5)})\")\n\n\n        improvement = best_score < current_score - 1e-6\n\n        if improvement:\n            if strategy == 'forward':\n                selected.append(best_candidate)\n                remaining.remove(best_candidate)\n            else:\n                selected.remove(best_candidate)\n\n            current_score = best_score\n            history.append({\n                'step': step,\n                'selected': selected.copy(),\n                'score': current_score,\n                'modified': best_candidate\n            })\n        else:\n            if verbose:\n                print(\"Aucune amélioration supplémentaire du score.\")\n            break\n\n    X_final = sm.add_constant(X[selected])\n    best_model = sm.OLS(y, X_final).fit()\n\n    if verbose:\n        print(\"\\nVariables sélectionnées :\", selected)\n        final_score = best_model.aic if metric == 'AIC' else best_model.bic\n        if metric == 'Cp':\n            final_score = compute_score(y, X, selected, metric, full_model_mse)\n        elif metric == 'R2_adj':\n            final_score = -compute_score(y, X, selected, metric)\n        print(f\"Score final ({metric}): {round(final_score,5)}\")\n\n    return selected, best_model, history\n```\n:::\n\n\n::: {#039563f7 .cell execution_count=14}\n``` {.python .cell-code}\nselected_vars, best_model, history = stepwise_selection(\n    df=df_for_stepwise,\n    target='ViolentCrimesPerPop',\n    strategy='backward',    # Ou 'backward'\n    metric='Cp',           # Ou 'AIC', 'BIC', 'R2_adj'\n    verbose=True\n)\nprint(best_model.summary())\nplot_stepwise_crosses(history, df_for_stepwise.columns.tolist(), metric=\"Cp\", title=\"Sélection de variables – Stepwise avec Cp Mallows\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSuppressions testées: [('pctWFarmSelf', 41.74), ('PctWOFullPlumb', 41.74), ('indianPerCap', 41.74), ('MedRentPctHousInc', 41.79), ('PctVacMore6Mos', 41.82), ('PctEmplManu', 41.85), ('PctImmigRec10', 41.85), ('PctUsePubTrans', 41.92), ('PctEmplProfServ', 41.96), ('MedOwnCostPctIncNoMtg', 41.98), ('AsianPerCap', 41.98), ('PctSameHouse85', 42.02), ('LemasPctOfficDrugUn', 42.05), ('PopDens', 42.08), ('PctWorkMom', 42.15), ('PctVacantBoarded', 42.34), ('LandArea', 42.37), ('MedYrHousBuilt', 42.46), ('PctKids2Par', 62.08)]\n\nÉtape 1: Meilleure variable à retirer : pctWFarmSelf (score=41.73966)\nSuppressions testées: [('PctWOFullPlumb', 41.7), ('indianPerCap', 41.7), ('MedRentPctHousInc', 41.75), ('PctVacMore6Mos', 41.78), ('PctEmplManu', 41.81), ('PctImmigRec10', 41.81), ('PctUsePubTrans', 41.89), ('PctEmplProfServ', 41.92), ('MedOwnCostPctIncNoMtg', 41.94), ('AsianPerCap', 41.94), ('PctSameHouse85', 41.98), ('LemasPctOfficDrugUn', 42.01), ('PopDens', 42.04), ('PctWorkMom', 42.11), ('PctVacantBoarded', 42.3), ('LandArea', 42.33), ('MedYrHousBuilt', 42.43), ('PctKids2Par', 62.7)]\n\nÉtape 2: Meilleure variable à retirer : PctWOFullPlumb (score=41.69895)\nSuppressions testées: [('indianPerCap', 41.66), ('MedRentPctHousInc', 41.71), ('PctVacMore6Mos', 41.74), ('PctEmplManu', 41.77), ('PctImmigRec10', 41.77), ('PctUsePubTrans', 41.84), ('PctEmplProfServ', 41.88), ('MedOwnCostPctIncNoMtg', 41.89), ('AsianPerCap', 41.9), ('PctSameHouse85', 41.94), ('LemasPctOfficDrugUn', 41.97), ('PopDens', 42.0), ('PctWorkMom', 42.08), ('PctVacantBoarded', 42.26), ('LandArea', 42.3), ('MedYrHousBuilt', 42.39), ('PctKids2Par', 64.57)]\n\nÉtape 3: Meilleure variable à retirer : indianPerCap (score=41.66073)\nSuppressions testées: [('MedRentPctHousInc', 41.67), ('PctVacMore6Mos', 41.7), ('PctEmplManu', 41.73), ('PctImmigRec10', 41.73), ('PctUsePubTrans', 41.8), ('PctEmplProfServ', 41.84), ('AsianPerCap', 41.86), ('MedOwnCostPctIncNoMtg', 41.86), ('PctSameHouse85', 41.9), ('LemasPctOfficDrugUn', 41.93), ('PopDens', 41.96), ('PctWorkMom', 42.05), ('PctVacantBoarded', 42.22), ('LandArea', 42.26), ('MedYrHousBuilt', 42.34), ('PctKids2Par', 64.69)]\n\nÉtape 4: Meilleure variable à retirer : MedRentPctHousInc (score=41.67325)\nAucune amélioration supplémentaire du score.\n\nVariables sélectionnées : ['AsianPerCap', 'PctEmplManu', 'PctEmplProfServ', 'PctKids2Par', 'PctWorkMom', 'PctImmigRec10', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'MedRentPctHousInc', 'MedOwnCostPctIncNoMtg', 'PctSameHouse85', 'LandArea', 'PopDens', 'PctUsePubTrans', 'LemasPctOfficDrugUn']\nScore final (Cp): 41.66073\n                             OLS Regression Results                            \n===============================================================================\nDep. Variable:     ViolentCrimesPerPop   R-squared:                       0.621\nModel:                             OLS   Adj. R-squared:                  0.618\nMethod:                  Least Squares   F-statistic:                     202.8\nDate:                 Sun, 10 Aug 2025   Prob (F-statistic):               0.00\nTime:                         15:32:22   Log-Likelihood:                 1044.4\nNo. Observations:                 1994   AIC:                            -2055.\nDf Residuals:                     1977   BIC:                            -1960.\nDf Model:                           16                                         \nCovariance Type:             nonrobust                                         \n=========================================================================================\n                            coef    std err          t      P>|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nconst                     0.6121      0.041     14.766      0.000       0.531       0.693\nAsianPerCap               0.0611      0.018      3.374      0.001       0.026       0.097\nPctEmplManu              -0.0475      0.021     -2.298      0.022      -0.088      -0.007\nPctEmplProfServ          -0.0789      0.024     -3.297      0.001      -0.126      -0.032\nPctKids2Par              -0.7673      0.023    -33.369      0.000      -0.812      -0.722\nPctWorkMom               -0.0915      0.020     -4.534      0.000      -0.131      -0.052\nPctImmigRec10             0.0496      0.021      2.356      0.019       0.008       0.091\nPctVacantBoarded          0.1080      0.020      5.402      0.000       0.069       0.147\nPctVacMore6Mos           -0.0437      0.023     -1.941      0.052      -0.088       0.000\nMedYrHousBuilt            0.1306      0.022      5.916      0.000       0.087       0.174\nMedRentPctHousInc         0.0370      0.023      1.615      0.107      -0.008       0.082\nMedOwnCostPctIncNoMtg    -0.0681      0.020     -3.393      0.001      -0.108      -0.029\nPctSameHouse85            0.1011      0.027      3.693      0.000       0.047       0.155\nLandArea                  0.1854      0.033      5.564      0.000       0.120       0.251\nPopDens                   0.0991      0.024      4.078      0.000       0.051       0.147\nPctUsePubTrans            0.0609      0.020      2.990      0.003       0.021       0.101\nLemasPctOfficDrugUn       0.0591      0.015      3.868      0.000       0.029       0.089\n==============================================================================\nOmnibus:                      389.964   Durbin-Watson:                   2.035\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1040.967\nSkew:                           1.034   Prob(JB):                    9.06e-227\nKurtosis:                       5.873   Cond. No.                         29.4\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](model_selection_files/figure-html/cell-15-output-2.png){width=427 height=566}\n:::\n:::\n\n\n::: {#7af97b21 .cell execution_count=15}\n``` {.python .cell-code}\n# R2_adj\nselected_vars, best_model, history = stepwise_selection(\n    df=df_for_stepwise,\n    target='ViolentCrimesPerPop',\n    strategy='backward',    # Ou 'backward'\n    metric='AIC',      # Ou 'AIC', 'BIC', 'Cp'\n    verbose=True\n)\nprint(best_model.summary())\nplot_stepwise_crosses(history, df_for_stepwise.columns.tolist(), metric=\"AIC\", title=\"Sélection de variables – Stepwise avec R2 ajusté\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSuppressions testées: [('pctWFarmSelf', np.float64(-2050.99)), ('PctWOFullPlumb', np.float64(-2050.95)), ('indianPerCap', np.float64(-2050.84)), ('MedRentPctHousInc', np.float64(-2048.38)), ('PctVacMore6Mos', np.float64(-2047.19)), ('PctEmplManu', np.float64(-2045.67)), ('PctImmigRec10', np.float64(-2045.63)), ('PctUsePubTrans', np.float64(-2042.0)), ('PctEmplProfServ', np.float64(-2040.42)), ('MedOwnCostPctIncNoMtg', np.float64(-2039.47)), ('AsianPerCap', np.float64(-2039.39)), ('PctSameHouse85', np.float64(-2037.29)), ('LemasPctOfficDrugUn', np.float64(-2035.93)), ('PopDens', np.float64(-2034.44)), ('PctWorkMom', np.float64(-2031.19)), ('PctVacantBoarded', np.float64(-2021.95)), ('LandArea', np.float64(-2020.45)), ('MedYrHousBuilt', np.float64(-2016.35)), ('PctKids2Par', np.float64(-1246.96))]\n\nÉtape 1: Meilleure variable à retirer : pctWFarmSelf (score=-2050.98706)\nSuppressions testées: [('PctWOFullPlumb', np.float64(-2052.95)), ('indianPerCap', np.float64(-2052.83)), ('MedRentPctHousInc', np.float64(-2050.35)), ('PctVacMore6Mos', np.float64(-2049.07)), ('PctEmplManu', np.float64(-2047.65)), ('PctImmigRec10', np.float64(-2047.54)), ('PctUsePubTrans', np.float64(-2043.85)), ('PctEmplProfServ', np.float64(-2042.15)), ('MedOwnCostPctIncNoMtg', np.float64(-2041.43)), ('AsianPerCap', np.float64(-2041.35)), ('PctSameHouse85', np.float64(-2039.27)), ('LemasPctOfficDrugUn', np.float64(-2037.86)), ('PopDens', np.float64(-2036.4)), ('PctWorkMom', np.float64(-2033.17)), ('PctVacantBoarded', np.float64(-2023.94)), ('LandArea', np.float64(-2022.31)), ('MedYrHousBuilt', np.float64(-2017.9)), ('PctKids2Par', np.float64(-1227.34))]\n\nÉtape 2: Meilleure variable à retirer : PctWOFullPlumb (score=-2052.94899)\nSuppressions testées: [('indianPerCap', np.float64(-2054.79)), ('MedRentPctHousInc', np.float64(-2052.31)), ('PctVacMore6Mos', np.float64(-2051.07)), ('PctEmplManu', np.float64(-2049.64)), ('PctImmigRec10', np.float64(-2049.39)), ('PctUsePubTrans', np.float64(-2045.84)), ('PctEmplProfServ', np.float64(-2044.03)), ('MedOwnCostPctIncNoMtg', np.float64(-2043.43)), ('AsianPerCap', np.float64(-2043.35)), ('PctSameHouse85', np.float64(-2041.14)), ('LemasPctOfficDrugUn', np.float64(-2039.86)), ('PopDens', np.float64(-2038.15)), ('PctWorkMom', np.float64(-2034.37)), ('PctVacantBoarded', np.float64(-2025.71)), ('LandArea', np.float64(-2024.0)), ('MedYrHousBuilt', np.float64(-2019.8)), ('PctKids2Par', np.float64(-1169.01))]\n\nÉtape 3: Meilleure variable à retirer : indianPerCap (score=-2054.78992)\nSuppressions testées: [('MedRentPctHousInc', np.float64(-2054.16)), ('PctVacMore6Mos', np.float64(-2053.0)), ('PctEmplManu', np.float64(-2051.47)), ('PctImmigRec10', np.float64(-2051.2)), ('PctUsePubTrans', np.float64(-2047.79)), ('PctEmplProfServ', np.float64(-2045.85)), ('AsianPerCap', np.float64(-2045.34)), ('MedOwnCostPctIncNoMtg', np.float64(-2045.21)), ('PctSameHouse85', np.float64(-2043.08)), ('LemasPctOfficDrugUn', np.float64(-2041.75)), ('PopDens', np.float64(-2040.09)), ('PctWorkMom', np.float64(-2036.16)), ('PctVacantBoarded', np.float64(-2027.57)), ('LandArea', np.float64(-2025.81)), ('MedYrHousBuilt', np.float64(-2021.8)), ('PctKids2Par', np.float64(-1165.99))]\n\nÉtape 4: Meilleure variable à retirer : MedRentPctHousInc (score=-2054.16175)\nAucune amélioration supplémentaire du score.\n\nVariables sélectionnées : ['AsianPerCap', 'PctEmplManu', 'PctEmplProfServ', 'PctKids2Par', 'PctWorkMom', 'PctImmigRec10', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'MedRentPctHousInc', 'MedOwnCostPctIncNoMtg', 'PctSameHouse85', 'LandArea', 'PopDens', 'PctUsePubTrans', 'LemasPctOfficDrugUn']\nScore final (AIC): -2054.78992\n                             OLS Regression Results                            \n===============================================================================\nDep. Variable:     ViolentCrimesPerPop   R-squared:                       0.621\nModel:                             OLS   Adj. R-squared:                  0.618\nMethod:                  Least Squares   F-statistic:                     202.8\nDate:                 Sun, 10 Aug 2025   Prob (F-statistic):               0.00\nTime:                         15:32:30   Log-Likelihood:                 1044.4\nNo. Observations:                 1994   AIC:                            -2055.\nDf Residuals:                     1977   BIC:                            -1960.\nDf Model:                           16                                         \nCovariance Type:             nonrobust                                         \n=========================================================================================\n                            coef    std err          t      P>|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nconst                     0.6121      0.041     14.766      0.000       0.531       0.693\nAsianPerCap               0.0611      0.018      3.374      0.001       0.026       0.097\nPctEmplManu              -0.0475      0.021     -2.298      0.022      -0.088      -0.007\nPctEmplProfServ          -0.0789      0.024     -3.297      0.001      -0.126      -0.032\nPctKids2Par              -0.7673      0.023    -33.369      0.000      -0.812      -0.722\nPctWorkMom               -0.0915      0.020     -4.534      0.000      -0.131      -0.052\nPctImmigRec10             0.0496      0.021      2.356      0.019       0.008       0.091\nPctVacantBoarded          0.1080      0.020      5.402      0.000       0.069       0.147\nPctVacMore6Mos           -0.0437      0.023     -1.941      0.052      -0.088       0.000\nMedYrHousBuilt            0.1306      0.022      5.916      0.000       0.087       0.174\nMedRentPctHousInc         0.0370      0.023      1.615      0.107      -0.008       0.082\nMedOwnCostPctIncNoMtg    -0.0681      0.020     -3.393      0.001      -0.108      -0.029\nPctSameHouse85            0.1011      0.027      3.693      0.000       0.047       0.155\nLandArea                  0.1854      0.033      5.564      0.000       0.120       0.251\nPopDens                   0.0991      0.024      4.078      0.000       0.051       0.147\nPctUsePubTrans            0.0609      0.020      2.990      0.003       0.021       0.101\nLemasPctOfficDrugUn       0.0591      0.015      3.868      0.000       0.029       0.089\n==============================================================================\nOmnibus:                      389.964   Durbin-Watson:                   2.035\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1040.967\nSkew:                           1.034   Prob(JB):                    9.06e-227\nKurtosis:                       5.873   Cond. No.                         29.4\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](model_selection_files/figure-html/cell-16-output-2.png){width=430 height=566}\n:::\n:::\n\n\n",
    "supporting": [
      "model_selection_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}