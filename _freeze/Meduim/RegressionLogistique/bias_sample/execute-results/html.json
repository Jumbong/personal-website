{
  "hash": "72dbe70fa312323d8cb65452ecc55729",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \" Sampling Bias and Class Imbalance (Oversampling and Undersampling) in Maximum-likelihood Logistic Regression\"\nsidebar: auto\nauthor:\n  - Jumbong Junior \ncategories: []\ntags: []\ntitle-block-banner: false\nhtml:\n    code-fold : true\njupyter: python3\n\n---\n\n\n# Introduction \n\nIn this article, the impact of sampling bias and class imbalance on logistic regression models is explored. The article covers two topics :\n\n- First, we hypothesize that the predictive performance of a logistic regression model is related to the sampling bias associated with the data and it has a perrformance advantage when the data is balanced. The hypothesis is testing with two simulated datasets : a balanced dataset (50:50) and an imbalanced dataset (80:20).  Each dataset will be sampled to produce samples with the following distribution : 50:50, 60:40, 70:30, 80:20, 90:10, 95:5, 99:1. \n\n- Second, in the case of class imbalance data, if the oversampling technique is used the intercept of the logistic regression model after oversampling need to be adjusted. In other words, let denote $\\hat{\\beta_0}$ the intercept of the logistic regression model after oversampling, then the following correction needs to be performed on it : \n\nbeta_hat - log[((1 - tau)/tau)(bar(y)/(1 - bar(y)))] \nIn latex ,the formular is given by :\n$$\n\\hat{\\beta}_0 - \\ln\\left[\\left(\\frac{1-\\tau}{\\tau}\\right)\\left(\\frac{\\bar{y}}{1-\\bar{y}}\\right)\\right]\n\n$$\n\nwhere $\\hat{\\beta_0}$ is the intercept of the logistic regression model after oversampling, $\\tau$ is the proportion of the minority class in the original dataset (or in population), and $\\bar{y}$ is the proportion of the minority class in the oversampled dataset (or in sample).\n\n1. Simulated Data Generation\n\nMany authors document that, for logistic regressionthe , the probability distribution of the dependent variable is assumed to be Bernoulli and the mass function f is given by :\n\n$$\nf(y, x, \\alpha, \\beta) = p(x, \\alpha, \\beta)^y(1-p(x, \\alpha, \\beta))^{1-y}\n$$\n\nwhere \n$$\np(x, $\\alpha$, $\\beta$) = \\frac{\\exp(\\alpha + \\beta x)}{1 + \\exp(\\alpha + \\beta x)} \n$$\n\nand where y is the dependent variable, x is the independent variable, $\\alpha$ and $\\beta$ are the parameters to be estimated using the maximum likelihood method (MLE).\n\nFor generating the the bernouilli trial y using for a fixed parameter P, we use the following equation :\n\n$$\n\ny(p) = \n\\begin{cases}\n\\text{dummy} \\leftarrow \\mathrm{rnd}(1), \\\\\n0, & \\text{if dummy} < p, \\\\\n1, & \\text{otherwise}.\n\\end{cases}\n$$\n\nwhere rnd(1) is a random number generator that generates a random number between 0 and 1.\n\nThe conditional bernouilli trials y are then generated by substituting of $p(x, \\alpha, \\beta)$ :\n\n$$\ny(x, \\alpha, \\beta) =\n\\begin{cases}\n0, & \\text{if rnd(1)} < p(x, \\alpha, \\beta), \\\\\n1, & \\text{otherwise}.\n\\end{cases}\n\n",
    "supporting": [
      "bias_sample_files"
    ],
    "filters": [],
    "includes": {}
  }
}