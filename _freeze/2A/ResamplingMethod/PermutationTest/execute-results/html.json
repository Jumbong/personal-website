{
  "hash": "7a97fb0ca5d5446ac5112a55436457f7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \" Resampling methods : Permutation Test\"\nsidebar: auto\nauthor:\n  - Jumbong Junior \ncategories: []\ntags: [Resampling methods, Permutation test, wilcoxon test,Monte Carlo ]\n\ntitle-block-banner: false\nformat: \n  html: \n    mainfont: Times New Roman\n    fontsize: 16pt\n\njupyter: python3\n        \n---\n\n\n# Introduction\n\nResampling methods are a key part of statistical inference. It is important to understand them in order to have accurate estimates, validate models, and dealt with the uncertainty of the data. Indeed, **the resampling methods mesure the variability of statistics by using subsamples from the original data**. There are least four resampling methods: **bootstrap, jackknife, permutation test, and cross-validation** :\n\n| Resampling method | Applications | Type of resampling |\n|-------------------|--------------|--------------------|\n| Efron's bootstrap | Bias, variance, confidence intervals, hypothesis testing | With replacement |\n| Permutation test | Hypothesis testing | Without replacement |\n| Jackknife | Bias, variance, confidence intervals | Leave-one-out |\n| Cross-validation | Model selection, validation | Leave-p-out |\n\nThis document will focus on the permutation test. \n\n# General framework of the hypothesis test\n\nThe goal of statistics is to learn about a population by studying a sample. Often, we don't know the process that produced the sample. Mathematically, the sample is a random variable. \n\nLet $X = (X_1, X_2, \\ldots, X_n)$ be a sample of size $n$ drawn from a population or a probability distribution $P$. \n\nA hypothesis is a declarative statement about the population or the probability distribution. A hypothesis test involves two complementary hypotheses :\n\n- The null hypothesis $H_0$ : \"$P \\in \\mathcal{P}_0$\" where $\\mathcal{P}_0$ is a set of probability distributions.\n- The alternative hypothesis $H_1$ : \"$P \\notin \\mathcal{P}_0$\". \n\nA test $\\phi$ is a decision procedure between $H_0$ and $H_1$, given the sample $X$. \n$$\n\\phi(x) =\n\\begin{cases}\n    1 & \\text{reject} H_0 \\\\\n    0 & \\text{It is not reject} H_0\n\\end{cases}\n$$\n\n\nA test $\\phi$ is defined using a real-valued test statistic $T(X)$ :\n\n- $\\phi(x) = \\mathbb{1}_{\\{T(x) > t_{\\alpha}\\}}$ where $t_{\\alpha}$ is the critical value of the test at level $\\alpha$. $H_0$ is rejected when $T(x) > t_{\\alpha}$.\n- $\\sup_{P \\in \\mathcal{P}_0} \\mathbb{E}_P \\{\\phi\\} \\leq \\alpha : \\text{ The law of } T \\text{ under } H_0 \\text{ is known}$.\n\nThe p-value of a test is the smallest level $\\alpha$ at which the null hypothesis is rejected :\n$$\np(x) = \\inf \\{ \\alpha : T(x) > t_{\\alpha} \\}\n$$\n\nTo construct a test, it is necessary to know the distribution or the law of the test statistic under the null hypothesis in other to compute :\n\n- The critical value $t_{\\alpha}$.\n- The p-value $p(x)$.\n\n# Motivation of the permutation test\n\nIn pratice, the law of the test statistic T is often approximated asymptotically, or requires verifying parametric assumptions that are hard to justify (eg. normality, homoscedasticity, etc.).\n\nThe permutation test is a non-parametric test. It can be used :\n\n- When the size of the sample is small to approximate the law of the test statistic.\n\n- When parametric test is not valid.\n\n# General framework of the permutation test\n\n**Principle** : Working on the observed data to avoid having to assume a specific distribution for the observed sample.\n\n## General Principle \n\n**The statistical Model** : $X \\sim P, P \\in \\mathcal{P}$.\n$P$ is a probability defined on $\\mathbb{R}^N$ and $\\mathcal{P}$ is a set of probability distributions on $\\mathbb{R}^N$.\n\n**The hypothesis test** : $H_0 : P \\in \\mathcal{P}_0$ vs $H_1 : P \\notin \\mathcal{P}_0$. $\\mathcal{P}_0$ is a subset of $\\mathcal{P}$.\n\n**Group of Transformations** : $G$ has the size $|G| = M$.\n$G$ has an idendity element $e$.\nThe operation inside $G$ is associative : $g_1, g_2 \\in G \\Rightarrow g_1 \\cdot g_2 \\in G$.\nFor each $g \\in G$, there is an inverse element $g^{-1}$ such that $g \\cdot g^{-1} = g^{-1} \\cdot g = e$.\n\n$G$ acts on $\\mathbb{R}^N$ : $g \\in G, x \\in \\mathbb{R}^N \\Rightarrow g \\cdot x \\in \\mathbb{R}^N$.\nwhere $e \\cdot x = x$ and $g_1 \\cdot (g_2 \\cdot x) = (g_1 g_2) \\cdot x$\n\n::: {.callout-note icon=false}\n\n## Echangeability Assumption\n\nUnder $H_0$ ($P \\in \\mathcal{P}_0$): for every $g \\in G$, $\\mathcal{L}_P(g \\cdot X) = \\mathcal{L}_P(X)$.\n:::\n\n**Permutation Test** : The permutation test is a test that uses the exchangeability assumption to construct a test.\n\nLet's define the decision function $\\phi$  and the p-value $p$ of the permutation test :\n\n::: {.callout-note icon=false}\n\n## Permutation Test with Level $\\leq \\alpha$\n\n$$\n\\phi(X) = \\mathbb{1}_{\\{T(X) >T^{(\\lceil M(1-\\alpha) \\rceil)}\\}}\n$$\nwhere $T^{(\\lceil M(1-\\alpha) \\rceil)}$ is the $\\lceil M(1-\\alpha) \\rceil$-th order statistic of the test statistic $T(g \\cdot X)$ for $g \\in G$.\n\nThe p-value of the permutation test is :\n$$\np(X) = \\frac{1}{M} \\sum_{g \\in G} \\mathbb{1}_{\\{T(g \\cdot X) > T(X)\\}}\n$$\n\n:::\n\n# Application of the permutation test\n\nThe permutation test has many applications in statistics :\n\n- **Symmetry test** : The permutation test can be used to test the symmetry of a distribution. An example is the Wilcoxon sign-rank test for paired samples.\n\n- **Independence test** : which help assess the effect of one variable on another. An example is the Spearman test.\n\n- **Comparison of two samples** : The permutation test can be used to compare the distribution of two samples. For example to assess if two samples have the same law.\n\n## Symmetry test \n\n**Statistical Model** : $X = (X_1, X_2, \\ldots, X_n)\\overset{i.i.d}{\\sim} F$ where $F$ is a Cumulative Distribution Function (CDF) defined on $\\mathbb{R}$.\n$X = (X_1, \\dots, X_n) \\in \\mathbb{R}^n$\n\n**The hypothesis test** : $H_0 : F \\text{ is symmetric around } 0$ vs $H_1 : F \\text{ is not symmetric around } 0$.\n\n**The transformation group** : $G = \\{-1, 1\\}^n$. with cardinality $|G| = 2^n$.\n\n::: {.callout-note icon=false}\n\n## Exchangeability Assumption\n\nUnder $H_0$ ($F$ is symmetric around 0) : for every $g \\in G$, $\\mathcal{L}_F(g \\cdot X) = \\mathcal{L}_F(X)$.\n:::\n\n**Test statistic** :  The test statistic can be defined by :\n\n- T(X) = |$\\overline{X}$| where $\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i$.\n\n- $T(X) = \\sum_{i=1}^n R_i sign(X_i)$ where $R_i$ is the rank of $|X_i|$ in $|X_1|, |X_2|, \\ldots, |X_n|$.\n\n::: {.callout-tip icon=false}\n\n## Algo : Symmetry test by permutation test (Monte Carlo)\n\n**Variable** : \n\n   - B : 999,999 such that (B+1)$\\alpha$ is an integer.\n\n**Begin** :\n\nfor b = 1 to B do:\n\n   - Generate $g^b \\sim \\mathcal{U}(G)$\n\n   - Compute $T^b = T(g^b \\cdot X)$.  \n   \n**end for.**\n\nReturn the p-value $p(X) = \\frac{1}{B} \\sum_{b=1}^B \\mathbb{1}_{\\{T^b > T(X)\\}}$\n\nend\n\n:::\n\nThe code below is an implementation of the permutation test for the symmetry test.\n\n::: {#26622618 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\n\n\n# Inputs : x (array) or (list) : sample.\n#func : function : statistic function.\n#nsamp : int : number of samples.\n# Outputs : dictionnary : statistic, sample_perm, p-value.\n\ndef symmetry_perm(x, func=np.mean, nsamp =9999):\n    x = np.asarray(x)\n    n = x.shape[0]\n\n    tobs = func(x)\n    # Generate nsamp samples sign permutation\n    eps = np.random.choice([-1, 1], size=(nsamp, n), replace=True)\n    # Compute the test statistic for each sample\n    permuted = eps * x\n\n    try:\n        tperm = func(permuted, axis=1)\n    except TypeError:\n        tperm = np.apply_along_axis(func, 1, permuted)\n    # Compute the p-value\n\n    count = np.sum(np.abs(tperm) >= np.abs(tobs))\n    p = (count + 1) / (nsamp + 1)\n    return {\"statistic\": tobs, \"sample_perm\": tperm, \"p-value\": p}\n```\n:::\n\n\nLet's apply the symmetry test to a central normal distribution.\n\n::: {#b10e54a9 .cell execution_count=2}\n``` {.python .cell-code}\n#np.random.seed(42)\n\nn = 100\nx = np.random.normal(0, 1, n)\n\nres = symmetry_perm(x, func=np.mean, nsamp=9999)\n\nprint(f\"Statistic : {res['statistic']},\" \n      f\" p-value : {res['p-value']}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStatistic : -0.06308259014379482, p-value : 0.5059\n```\n:::\n:::\n\n\n**Distribution of the mean and the ergodic mean p-values.**\n\n::: {#e8de244d .cell execution_count=3}\n``` {.python .cell-code}\nB = 6000\n# P value for a range of nsamp from 1 to B\np_values = [symmetry_perm(x, func=np.mean, nsamp=i)[\"p-value\"] for i in np.arange(1, B)]\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns   \n\nfig, axes = plt.subplots(1, 2, figsize=(8, 3))\n\n## ðŸŸ¢ Histogram: Distribution of Test Statistic\nsns.histplot(res['sample_perm'], ax=axes[0], kde=True, color='#1f77b4', alpha=0.7)\naxes[0].axvline(res['statistic'], color='red', linestyle='--', linewidth=2, label='Observed Statistic')\naxes[0].set_title('Distribution of the Test Statistic', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Test Statistic', fontsize=12)\naxes[0].set_ylabel('Frequency', fontsize=12)\naxes[0].legend(fontsize=12)\n# No grid for better readability\naxes[0].grid(False)\n\n## ðŸ”µ Line Plot: Ergodic Mean of the P-value\naxes[1].plot(np.arange(1, B), p_values, color='#ff7f0e', linewidth=2)\naxes[1].axhline(np.mean(p_values), color='black', linestyle='--', linewidth=2, label='Mean p-value')\naxes[1].set_title('Ergodic Mean of the P-value', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Iterations', fontsize=12)\naxes[1].set_ylabel('P-value', fontsize=12)\naxes[1].legend(fontsize=12)\naxes[1].grid(False)\n# Annotation for Mean P-value\naxes[1].text(0.6 * B, np.mean(p_values), f\"Mean p-value: {np.mean(p_values):.4f}\",\n             fontsize=12, color='black', fontweight='bold')\n\n# Improve layout\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](PermutationTest_files/figure-html/cell-4-output-1.png){width=762 height=278}\n:::\n:::\n\n\n## Symmetry test : Wilcoxon sign-rank test\n\nOne of the most popular permutation tests is the Wilcoxon sign-rank test. It allows to test for example if two paired samples come from the same distribution. To accomplish this, the Wilcoxon sign-rank test assess if the difference between the two samples is symmetric around 0.\n\nThe test statistic is defined by :\n\n$$\nT(X) = \\sum_{i=1}^n R_i sign(X_i)\n$$\n\nwhere $R_i$ is the rank of $|X_i|$ in $|X_1|, |X_2|, \\ldots, |X_n|$.\n\nFor the application of the Wilcoxon sign-rank test, for 10 patients, we have data on the number of hours of sleep after taking a drug and after taking a placebo. The goal is to test if the number of hours of sleep is the same after taking the drug and the placebo.\n\n::: {#fb429a6d .cell execution_count=4}\n``` {.python .cell-code}\nfrom scipy.stats import wilcoxon, PermutationMethod\nimport pandas as pd\n\ntreatment = np.array([6.1,7.0,8.2,7.6,6.5,8.4,6.9,6.7,7.4,5.8])\nplacebo  = np.array([5.2,7.9,3.9,4.7,5.3,5.4,4.2,6.1,3.8,6.3])\nz = treatment - placebo\n# Stat test \nstatW = lambda z: (pd.Series(np.abs(z)).rank() * np.sign(z)).sum()\n\n# Test per permutation\nres = symmetry_perm(z, func=statW, nsamp=59999)\n\nprint(f\"Statistic : {res['statistic']},\" \n      f\" p-value : {res['p-value']}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStatistic : 45.0, p-value : 0.01965\n```\n:::\n:::\n\n\nThe p-value is 0.01985 less than 0.05, we reject the null hypothesis. The number of hours of sleep is not the same after taking the drug and the placebo.\n\nConclusion\n\nThe permutation test is a powerful tool for hypothesis testing and up-to-date. In this article, we have seen how to apply the permutation test to test the symmetry of a distribution and the Wilcoxon sign-rank test.  \n\n",
    "supporting": [
      "PermutationTest_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}