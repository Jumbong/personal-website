{
  "hash": "745d843947359800577314e2640b36a4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \" Optimal Number of default for constructing a model\"\nsubtitle: \"Normality and heterogeneity of grades scale\"\ndate: last-modified\nsidebar: auto\nnumber-sections: false\ntoc: true\nauthor:\n  - Jumbong Junior \ncategories: []\ntags: []\ntitle-block-banner: false\nbibliography: references.bib\nformat: \n  html: \n    fontsize: 1.1em\n\njupyter: python3\n\n    \n---\n\n\n## Introduction\n\nA common step before building a model is to determine the optimal number of observations required. In credit scoring, it's not only essential to know the total number of observations, but also the optimal number of defaults needed to develop a meaningful and reliable model.\n\nIn the case of a low-default portfolio (LDP), defaults are rare, making it difficult to assess whether constructing a model is even possible. Rather than building a model blindly and relying on luck for acceptable performance, it is crucial to first determine the minimum number of defaults required to justify model development.\n\nThis determination must satisfy both statistical and regulatory constraints. From a statistical perspective, the sample must be representative, with a distribution that reflects the underlying population. On the regulatory side, authorities typically require that a rating model include at least seven distinct grades (e.g., AAA, AA, A, BBB, BB, B, C).\n\nFailing to meet these conditions can lead to regulatory sanctions, delays due to corrective actions, and financial costs for the institution.\n\nThis brings us to the  question, What is the optimal number of defaults required to build a seven-grade rating model for a low-default portfolio that satisfies both statistical rigor and regulatory expectations, while ensuring heterogeneity between rating grades?\n\n\n\n## 1. Which data should be used ?\n\nIt is important to define the perimeter over which data will be collected. This is done by considering several criteria. If we consider a portfolio made up of large corporations, we can define the perimeter based on company size—for example, a turnover above a certain threshold (100 million euros), the region (Europe, North America, etc.), or the sector (agriculture, industry, services, etc.).\n\nWhat characterizes large companies is that they rarely default—that is, they generally meet their financial obligations to creditors. As a result, if we assign them ratings on a seven-grade scale (AAA, AA, A, BBB, BB, B, C), very few companies would receive a C rating. Most companies would fall within the intermediate grades (A, BBB, BB), and only a few would receive the highest rating (AAA). Therefore, the distribution of ratings tends to resemble a normal distribution.\n\nGoing forward, we will assume that our portfolio consists of large corporations and that the rating scale follows a normal distribution.\n\nIf you’re interested in reproducing this work, you can use a portfolio of your choice and define your own distribution of ratings across the grades.\n\n\n\n## 2. Statistical contraints : heterogeneity between grades.\n\n\nTo effectively assess the credit risk of counterparties, it's important that the rating scale is both homogeneous within each category and heterogeneous across categories. In other words, observations within the same rating grade should share similar characteristics — meaning they represent the same level of risk — while observations in different rating grades should reflect distinct risk profiles.\n\nWe won’t address within-grade homogeneity in this post.\n\nTo ensure heterogeneity across rating categories, we’ll use the binomial test to compare the proportions of observations assigned to each grade. The difference in proportions will be evaluated under the assumption that it follows a normal distribution with a mean of zero — which serves as the null hypothesis.\n\nBy dividing the difference by its standard deviation, we obtain a standardized value that follows the standard normal distribution.\n$$\nZ = \\frac{p_1 - p_2}{\\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}}.\n$$\nWhere $p_1$ and $p_2$ are the proportions of observations in the two rating categories being compared, and $n_1$ and $n_2$ are the number of observations in each category. \n\n\n---\n\n## Methodology\n\nThis section outlines the procedure used to determine the optimal number of defaults when constructing a default model with seven rating grades.\n\n### Step 1: Estimating the Number of Observations per Grade\n\nFirst, we need to determine how many observations fall into each rating grade. Given a total number of observations $N$ and assuming a seven-grade scale (AAAA, AA, A, BBB, BB, B, C), we compute the number of observations per grade using the normal distribution. That means calculating the probability associated with each grade and multiplying it by $N$.\n\nThere are many ways to assign probabilities across grades, but we choose this method because it is deterministic and replicable. Other approaches, including random sampling techniques, could be used as well. In our case, the number of observations for each grade is generated based on the following methodology:\n\n- Computing the probability density function (PDF) of the normal distribution for each grade.\n    - For the first grade (AAAA), the probability is:\n\n  $$\n  P(\\text{AAAA}) = \\frac{F(\\text{AAAA} + \\epsilon)}{2\\epsilon},\n  $$\n\n  where $F$ is the cumulative distribution function (CDF) of the normal distribution and $\\epsilon \\to 0$. We assume $F(\\text{AAAA} - \\epsilon) = 0$.\n\n    - For middle grades (AA, A, BBB, BB, B), the probability is calculated as:\n\n  $$\n  P(\\text{Grade}) = \\frac{F(\\text{Grade} + \\epsilon) - F(\\text{Grade} - \\epsilon)}{2\\epsilon},\n  $$\n\n    - For the last grade (C), since $F(\\text{C} + \\epsilon) = 1$, the probability becomes:\n\n  $$\n  P(\\text{C}) = \\frac{1 - F(\\text{C} - \\epsilon)}{2\\epsilon}.\n  $$\n\n- The number of observations in each grade is then computed as:\n\n$$\nN_{\\text{grade}} = N \\cdot P(\\text{grade}).\n$$\n\n### Step 2: Estimating the Number of Defaults per Grade\n\nNext, we determine the number of defaults for each grade while ensuring heterogeneity between them. In the context of low-default portfolios (LDP), the highest rating (AAAA) is expected to have very few defaults. So, we begin by fixing the number of defaults for grade AAAA at 1.\n\nTo compute the number of defaults for grade $i+1$ based on grade $i$, we follow this approach:\n\n#### 1. Ensuring Heterogeneity Between Grades\n\nThe two grades must be heterogeneous, meaning the null hypothesis of the binomial test (that the default rates are equal) must be rejected at a significance level $\\alpha$. This leads to the following statistical condition:\n\n$$\nP(Z = \\frac{|p_i - p_{i+1}|}{\\sqrt{\\frac{p_i(1 - p_i)}{N_i} + \\frac{p_{i+1}(1 - p_{i+1})}{N_{i+1}}}} \\geq Z_\\alpha) = \\alpha,\n$$\n\nwhere $p_i$ and $p_{i+1}$ are the default rates for grades $i$ and $i+1$, and $N_i$, $N_{i+1}$ are the respective numbers of observations. $Z_\\alpha = \\Phi^{-1}(1 - \\alpha/2)$, where $\\Phi^{-1}$ is the inverse of the cumulative distribution function of the standard normal distribution. \n\nis the critical value of the standard normal distribution for the chosen confidence level.\n\nWe can rewrite this condition using the pooled default rate:\n\n$$\np = \\frac{N_i p_i + N_{i+1} p_{i+1}}{N_i + N_{i+1}}.\n$$\n\nThen the $Z$-statistic becomes:\n\n$$\nP(Z = \\frac{|p_i - p_{i+1}|}{\\sqrt{p(1 - p)\\left(\\frac{1}{N_i} + \\frac{1}{N_{i+1}}\\right)}} \\geq Z_\\alpha ) = \\alpha,\n$$\n\nNow, let $e = p_{i+1} - p_i$. Then:\n\n$$\np_{i+1} = p_i + e.\n$$\n\n#### 2. Computing the Number of Defaults for Grade $i+1$\n\nOnce $p_{i+1}$ is known, the number of defaults for grade $i+1$ is:\n\n$$\nn_{i+1} = p_{i+1} \\cdot N_{i+1}.\n$$\n\nTo find the value of the optimal $e$ that satisfies the heterogeneity condition, we solve the equation:\n\n$$\nZ = \\frac{e}{\\sqrt{p(1 - p)\\left(\\frac{1}{N_i} + \\frac{1}{N_{i+1}}\\right)}} = Z_\\alpha,\n$$\n\nThis leads to a second-degree equation of the form:\n\n$$\nae^2 + be + c = 0.\n$$\n\nwith coefficients:\n\n$$\na = -\\left[\\left(\\frac{N_{i+1}}{N_i + N_{i+1}}\\right)^2 + \\frac{1}{Z_\\alpha^2\\left(\\frac{1}{N_i} + \\frac{1}{N_{i+1}}\\right)}\\right],\n$$\n\n$$\nb = (1 - 2p_i)\\left(\\frac{N_{i+1}}{N_i + N_{i+1}}\\right),\n$$\n\n$$\nc = p_i(1 - p_i),\n$$\n\nSince $a < 0$ and $c > 0$, the quadratic equation has two real roots — one negative and one positive. We select the positive solution:\n\n$$\ne = \\frac{-b - \\sqrt{b^2 - 4ac}}{2a}.\n$$\n\n---\n\n::: {#0c5d89c5 .cell execution_count=1}\n``` {.python .cell-code}\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import norm\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## Results\n\nTo implement the method, we use Python. The number of defaults for the highest grade (AAAA) is fixed at 1. A simulation is then conducted by varying the total number of observations from 1,000 to 10,000 in steps of 1,000. The optimal number of defaults is defined as the average number of defaults across all simulations.\n\n\n### Simulating the Distribution of Observations per Grade\n\nThe code below simulates how observations are distributed across rating grades based on the normal distribution. We assume a mean of 4 (corresponding to grade BBB) and a standard deviation of 1. The number of observations in each grade is determined by multiplying the total number of observations by the probability density function (PDF) of the normal distribution centered at each grade (see @fig-generate_obs_pdf).\n\n::: {#cell-fig-generate_obs_pdf .cell execution_count=2}\n``` {.python .cell-code}\ndef generate_obs_pdf(N, mu, sigma,espilon=0.5):\n    grades = ['AAAA', 'AA', 'A', 'BBB', 'BB', 'B', 'C']\n    grades_positions = np.arange(1,len(grades)+1)\n    prob = np.zeros(len(grades))\n    prob[0] = norm.cdf(grades_positions[0] + espilon, mu, sigma) \n    prob[6] = 1 - norm.cdf(grades_positions[6] - espilon, mu, sigma)\n    for i in range(1, len(grades)-1):\n        prob[i] = norm.cdf(grades_positions[i] + espilon, mu, sigma) - norm.cdf(grades_positions[i] - espilon, mu, sigma)\n\n    obs_count = (prob * N).round().astype(int)\n    count_int = np.floor(obs_count).astype(int)\n    remainder = N - count_int.sum()\n    fractional_part = obs_count - count_int\n    sorted_indices = np.argsort(-fractional_part)\n    for i in range(remainder):\n        count_int[sorted_indices[i]] += 1\n\n    obs_count = pd.Series(obs_count, index=grades)\n    return obs_count\n# Define the parameters\nN = 5001\nmu = 4\nsigma = 1\n# Generate the number of observations per grade\nobs_count = generate_obs_pdf(N, mu, sigma)\n\n\n# Plot the results and add the number of observations in each grade\nplt.figure(figsize=(8, 5))\nsns.barplot(x=obs_count.index, y=obs_count.values)\nplt.title(f'Number of Observations per Grade (N={N}, mu={mu}, sigma={sigma})')\nfor i, v in enumerate(obs_count.values):\n    plt.text(i, v + 0.5, str(v), ha='center', va='bottom')\nplt.xlabel('Grade')\nplt.ylabel('Number of Observations')\nplt.xticks(rotation=45)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Distribution of Observations per Grade](number_obs_for_model_files/figure-html/fig-generate_obs_pdf-output-1.png){#fig-generate_obs_pdf width=676 height=472}\n:::\n:::\n\n\n### Estimating the Number of Defaults per Grade\n\nThe following code estimates the number of defaults for each grade, given the total number of observations, while ensuring heterogeneity between consecutive grades. This is done using the binomial test at a significance level $\\alpha = 0.05$ (see @tbl-generate_defaut_per_grade).\n\n::: {#tbl-generate_defaut_per_grade .cell tbl-cap='Number of Defaults per Grade' execution_count=3}\n``` {.python .cell-code}\ndef generate_defaut_per_grade(N, mu, sigma, alpha):\n    df_obs = generate_obs_pdf(N, mu, sigma)\n    grades = df_obs.index\n    n = df_obs.values\n\n    # Initialisation des vecteurs\n    z_alpha = norm.ppf(alpha/2)\n    k = len(n)\n    d_rate = np.zeros(k)\n    ecart = np.zeros(k)\n    p_moy = np.zeros(k)\n    stats = np.zeros(k)\n    p_vals = np.zeros(k)\n    n_def = np.zeros(k, dtype=int)\n\n    # Conditions initiales\n    n_def[0] = 1\n    d_rate[0] = 1 / n[0]\n\n    for i in range(1, k):\n        n1, n2 = n[i-1], n[i]\n        prev_rate = d_rate[i-1]\n        frac = n2 / (n1 + n2)\n\n        # Coefficients quadratiques\n        a = - (frac**2 + 1 / (z_alpha**2 * (1/n1 + 1/n2)))\n        b = (1 - 2 * prev_rate) * frac\n        c = prev_rate * (1 - prev_rate)\n        delta = b**2 - 4*a*c\n\n        if delta < 0:\n            raise ValueError(f\"No real solution at i={i} (delta < 0)\")\n\n        ecart[i] = (-b - np.sqrt(delta)) / (2 * a)\n        d_rate[i] = prev_rate + ecart[i]\n        n_def[i] = int(round(d_rate[i] * n[i]))\n        p_moy[i] = prev_rate + ecart[i] * frac\n\n        var = p_moy[i] * (1 - p_moy[i]) * (1/n1 + 1/n2)\n        stats[i] = ecart[i] / np.sqrt(var)\n        p_vals[i] = 2 * (1 - norm.cdf(abs(stats[i])))\n\n    return pd.DataFrame({\n        'Grade': grades,\n        'nb obs': n,\n        '#defaut': n_def,\n        'pct defaut': d_rate,\n        'écart pct defaut': ecart,\n        'proba moyenne': p_moy,\n        'statistic': stats,\n        'p-value': p_vals\n    })\n\n# Exemple d'appel\nN = 5001\nmu = 4\nsigma = 1\nalpha = 0.05\ndf_defaut = generate_defaut_per_grade(N, mu, sigma, alpha)\n# Display the results\nprint(tabulate(df_defaut, headers='keys', tablefmt='psql', showindex=False))\ndf_defaut.to_excel('df_defaut.xlsx', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n+---------+----------+-----------+--------------+--------------------+-----------------+-------------+-----------+\n| Grade   |   nb obs |   #defaut |   pct defaut |   écart pct defaut |   proba moyenne |   statistic |   p-value |\n|---------+----------+-----------+--------------+--------------------+-----------------+-------------+-----------|\n| AAAA    |       31 |         1 |    0.0322581 |          0         |        0        |     0       |      0    |\n| AA      |      303 |        50 |    0.165283  |          0.133025  |        0.152936 |     1.95996 |      0.05 |\n| A       |     1209 |       261 |    0.216208  |          0.0509256 |        0.206003 |     1.95996 |      0.05 |\n| BBB     |     1915 |       472 |    0.246731  |          0.0305224 |        0.234918 |     1.95996 |      0.05 |\n| BB      |     1209 |       336 |    0.278268  |          0.0315377 |        0.258936 |     1.95996 |      0.05 |\n| B       |      303 |       102 |    0.335389  |          0.0571204 |        0.289715 |     1.95996 |      0.05 |\n| C       |       31 |        16 |    0.511876  |          0.176487  |        0.351769 |     1.95996 |      0.05 |\n+---------+----------+-----------+--------------+--------------------+-----------------+-------------+-----------+\n```\n:::\n:::\n\n\n## Simulating the Optimal Number of Defaults\n\nThis final simulation estimates the optimal number of defaults by computing the average number of defaults over multiple runs. The number of observations varies from 5,000 to 1,000,000 in increments of 5,000(see @fig-optimal_number_defaults).\n\n::: {#cell-fig-optimal_number_defaults .cell execution_count=4}\n``` {.python .cell-code}\nplt.figure(figsize=(8, 5))\n\nN_values = np.arange(5000, 1000000, 5000)\noptimal_defaults = [generate_defaut_per_grade(N, mu, sigma, alpha)['#defaut'].sum() for N in N_values]\nmean_defaults = np.mean(optimal_defaults)\nplt.plot(N_values, optimal_defaults, marker='o')\nplt.axhline(mean_defaults, color='r', linestyle='--', label=f'Mean Defaults: {mean_defaults:.2f}')\n\n########################################\n# Ajout de texte pour afficher la valeur de la moyenne\n##########################################\nplt.text(N_values[-1], mean_defaults, f'Mean: {mean_defaults:.2f}', color='red', fontsize=10, ha='left', va='center')\nplt.title('Optimal Number of Defaults vs. Number of Observations')\nplt.xlabel('Number of Observations')\nplt.ylabel('Optimal Number of Defaults')\nplt.xticks(rotation=45)\nplt.legend()\nplt.grid(False)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Optimal Number of Defaults vs. Number of Observations](number_obs_for_model_files/figure-html/fig-optimal_number_defaults-output-1.png){#fig-optimal_number_defaults width=749 height=461}\n:::\n:::\n\n\n### Conclusion\n\nThis study addressed a fundamental challenge in credit risk modeling: determining the optimal number of defaults required to develop a reliable and regulatory-compliant rating model, particularly for low-default portfolios (LDPs). Building such models without sufficient defaults not only compromises statistical robustness but also risks non-compliance with regulatory expectations, especially the requirement of a seven-grade rating scale.\nThrough a structured and reproducible methodology based on the normal distribution of credit grades and binomial statistical tests, the research demonstrated how one can estimate the number of observations and defaults per grade necessary to ensure heterogeneity between rating categories. A key insight from the simulation was that, even with increasing total observations, the number of defaults required stabilizes - highlighting that data quantity alone does not compensate for data quality or risk signal strength.\nThe implications of these findings are significant for risk managers and model validators. Institutions should not only focus on collecting more data but also ensure they meet a minimum threshold of defaults (estimated at 1,419) to build a statistically valid model. This threshold acts as a benchmark for initiating model development, validating its structure, and anticipating regulatory scrutiny.\nNevertheless, the approach is not without limitations. The model assumes a normal distribution of credit grades and does not explore within-grade homogeneity or other sources of model uncertainty such as macroeconomic shocks, structural breaks, or portfolio shifts. Additionally, the focus on large corporate portfolios may limit generalizability to other segments like SMEs or retail.\nFuture research could refine the simulation under alternative rating distributions.In conclusion, this research provides a quantitative foundation for institutions managing low-default portfolios to assess their readiness for model development. It encourages a shift from ad hoc modeling toward data-driven thresholds, reinforcing both statistical credibility and regulatory alignment in credit risk modeling.\n\n",
    "supporting": [
      "number_obs_for_model_files"
    ],
    "filters": [],
    "includes": {}
  }
}