<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jumbong Junior">
<meta name="dcterms.date" content="2025-04-29">

<title>Linear Regression in Time Series: Sources of Spurious Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../flavicon.jpeg" rel="icon" type="image/jpeg">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Accueil</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../index_gdr.html"> 
<span class="menu-text">Daily Story</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Summary</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#contribution" id="toc-contribution" class="nav-link" data-scroll-target="#contribution">Contribution</a></li>
  <li><a href="#objectives" id="toc-objectives" class="nav-link" data-scroll-target="#objectives">Objectives</a></li>
  </ul></li>
  <li><a href="#random-walk-and-arima011-process" id="toc-random-walk-and-arima011-process" class="nav-link" data-scroll-target="#random-walk-and-arima011-process">Random Walk and ARIMA(0,1,1) Process</a>
  <ul class="collapse">
  <li><a href="#random-walk" id="toc-random-walk" class="nav-link" data-scroll-target="#random-walk">Random Walk</a></li>
  <li><a href="#arima011-process" id="toc-arima011-process" class="nav-link" data-scroll-target="#arima011-process">ARIMA(0,1,1) Process</a></li>
  </ul></li>
  <li><a href="#random-walk-can-lead-to-nonsense-regression" id="toc-random-walk-can-lead-to-nonsense-regression" class="nav-link" data-scroll-target="#random-walk-can-lead-to-nonsense-regression">Random walk can lead to Nonsense Regression</a></li>
  <li><a href="#simulation-results-using-python." id="toc-simulation-results-using-python." class="nav-link" data-scroll-target="#simulation-results-using-python.">Simulation results using python.</a></li>
  <li><a href="#how-to-avoid-spurious-regression-in-time-series" id="toc-how-to-avoid-spurious-regression-in-time-series" class="nav-link" data-scroll-target="#how-to-avoid-spurious-regression-in-time-series">How to avoid spurious regression in time series</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Linear Regression in Time Series: Sources of Spurious Regression</h1>
<p class="subtitle lead">A simulation of the results presented in the article by Granger and Newbold (1974)</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jumbong Junior </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 29, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p>It is common when analyzing the relationship between a dependent time series and several independent time series, to use the regression model. In their well know paper, <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> found several articles in the literature, presenting regression models with apparently high goodness of fit, measured by the coefficient of determination, <span class="math inline">\(R^2\)</span>, but with very low durbin-watson statistics.</p>
<p>What is particularly surprising is that almost all econometric textbook warns about the danger of autocorrelated errors, yet this issue persist in many published papers. <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> identified several examples. For instance, they found published equations with <span class="math inline">\(R^2 = 0.997\)</span> and the the Durbin-Watson statistic (d) equal to 0.53. The most extreme, the found is an equation with <span class="math inline">\(R^2 = 0.999\)</span> and <span class="math inline">\(d = 0.093\)</span>.</p>
<p>These clear examples of what is called spurious regression, where the results look statistically impressive but are in fact misleading, falsely suggesting a strong relationship between the variables when no such relationship exists.</p>
<p>This honestly made me laugh because, during my internships, I saw many colleagues using regression models for time series data, evaluating performance purely based on the <span class="math inline">\(R^2\)</span>, especially when it was high (close to 1), along with metrics like the Mean Squared Error (MSE) or the Mean Absolute Error (MAE), without taking into account the autocorrelation of the residuals.</p>
<p>When I came across this article, I realized how common this issue is. That is why I wanted to show you how crucial to always check the autocorrelation of the residuals when performing a regression analysis with time series data.</p>
</section>
<section id="contribution" class="level2">
<h2 class="anchored" data-anchor-id="contribution">Contribution</h2>
<p>Our post provides :</p>
<ul>
<li>A detailed explanation of the results from <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span>.</li>
<li>A Python simulation replicating the key results presented in their article.</li>
</ul>
</section>
<section id="objectives" class="level2">
<h2 class="anchored" data-anchor-id="objectives">Objectives</h2>
<p>The classic regression model tests assume independent data. However, in the case of time series, observations are not independent — they are autocorrelated, and sometimes we even observe what’s called serial correlation, which is the correlation between successive values of the series. For example, today’s GDP is strongly correlated with the GDP of the previous quarter. This autocorrelation of the data can lead to correlation in the errors, which influence the results of the regression analysis.</p>
<p>There are three main consequences of autocorrelated errors in regression analysis:</p>
<ul>
<li>Estimation of the coefficients of the model is inefficient.</li>
<li>Forecasts based on the regression equation are sub-optimal.</li>
<li>The hypothesis tests of the coefficients are invalid.</li>
</ul>
<p>The first two points are well documented in the literature. However, <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> focused specifically on the third point, showing that it’s possible to obtain very high <span class="math inline">\(R^2\)</span> values, even though the models have no real economic meaning — what we call spurious regressions.</p>
<p>To support their analysis, the authors first present some key results from time series analysis. Then, they explain how nonsense regressions can occur, and finally, they run simulations to demonstrate that if the variables follow a random walk (or close to it), and if you include variables in the regression that shouldn’t be there, then it becomes the rule rather than the exception to obtain misleading results</p>
<p>To walk you through this paper, the next section will introduce the random walk and the ARIMA(0,1,1) process. In section 3, we will explain how <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> describe the emergence of nonsense regressions, with examples illustrated in section 4. Finally, we’ll show how to avoid spurious regressions when working with time series data.</p>
</section>
</section>
<section id="random-walk-and-arima011-process" class="level1">
<h1>Random Walk and ARIMA(0,1,1) Process</h1>
<section id="random-walk" class="level2">
<h2 class="anchored" data-anchor-id="random-walk">Random Walk</h2>
<p>Let <span class="math inline">\(X_t\)</span> be a time series. We say that <span class="math inline">\(X_t\)</span> follows a random walk if its representation is given by:</p>
<p><span id="eq-random_walk"><span class="math display">\[
X_t = X_{t-1} + \epsilon_t
\tag{1}\]</span></span></p>
<p>where <span class="math inline">\(\epsilon_t\)</span> is a white noise. It can be writen as a sum of white noise :</p>
<p><span id="eq-random_walk2"><span class="math display">\[
X_t =  X_0 + \sum_{i=1}^{t} \epsilon_i
\tag{2}\]</span></span></p>
<p>where <span class="math inline">\(X_0\)</span> is the initial value of the series.</p>
<p>The random walk is a non-stationary time series. In fact, if we take the Variance of <span class="math inline">\(X_t\)</span>, we have:</p>
<p><span id="eq-variance_random_walk"><span class="math display">\[
V(X_t) = t\sigma^2
\tag{3}\]</span></span></p>
<p>which is increasing with time.</p>
<p>This model have been found to represent well certain price series, particularly in speculative markets.</p>
<p>For many others series,</p>
<p><span id="eq-random_walk_ar"><span class="math display">\[
X_t - X_{t-1} = \epsilon_t - \theta \epsilon_{t-1}
\tag{4}\]</span></span></p>
<p>has been found to provide a good representation.</p>
<p>Those non-stationary series are often employed as bench-marks against which the forecasting performance of other models is judged.</p>
</section>
<section id="arima011-process" class="level2">
<h2 class="anchored" data-anchor-id="arima011-process">ARIMA(0,1,1) Process</h2>
<p>The ARIMA(0,1,1) process is given by:</p>
<p><span id="eq-arima_0_1_1"><span class="math display">\[
X_t = X_{t-1} + \epsilon_t - \theta \epsilon_{t-1}
\tag{5}\]</span></span></p>
<p>where <span class="math inline">\(\epsilon_t\)</span> is a white noise. The ARIMA(0,1,1) process is non-stationary. It can be written as a sum of independent random walk and white noise :</p>
<p><span id="eq-arima_0_1_1_2"><span class="math display">\[
X_t =  X_0 + random walk + white noise
\tag{6}\]</span></span></p>
<p>In the next section, we will see how Nonsense Regression can arise when we regress a dependent series on independent series that follow a random walk.</p>
</section>
</section>
<section id="random-walk-can-lead-to-nonsense-regression" class="level1">
<h1>Random walk can lead to Nonsense Regression</h1>
<p>First, let’s recall the linear regression model. The linear regression model is given by:</p>
<p><span id="eq-regression"><span class="math display">\[
Y = X\beta + \epsilon
\tag{7}\]</span></span></p>
<p>where <span class="math inline">\(Y\)</span> is a T x 1 vector of the dependent variable, <span class="math inline">\(\beta\)</span> is a K x 1 vector of the coefficients, <span class="math inline">\(X\)</span> is a T x K matrix of the independent containing a column of ones and (K-1) columns and T observations on each of (K-1) independent variables which are stochastic, but distributed independently of the <span class="math inline">\(T\times1\)</span> vector of the errors <span class="math inline">\(\epsilon\)</span>. It is generally assumed that : <span id="eq-expectation_error"><span class="math display">\[
E(\epsilon) = 0
\tag{8}\]</span></span></p>
<p>and <span id="eq-expectation_error2"><span class="math display">\[
E(\epsilon\epsilon') = \sigma^2I
\tag{9}\]</span></span></p>
<p>where <span class="math inline">\(I\)</span> is the identity matrix.</p>
<p>A test of contribution of independent variable of the explanation of the dependent variable is the F-test. The null hypothesis of the test is given by:</p>
<p><span id="eq-null_hypothesis"><span class="math display">\[
H_0: \beta_1 = \beta_2 = \ldots = \beta_{K-1} = 0
\tag{10}\]</span></span></p>
<p>and the statistic of the test is given by:</p>
<p><span id="eq-f_test"><span class="math display">\[
F = \frac{(R^2/(K-1))}{(1-R^2)/(T-K)}
\tag{11}\]</span></span></p>
<p>where <span class="math inline">\(R^2\)</span> is the coefficient of determination.</p>
<p>If we want to construct the statistic of the test, let’s assume that the null hypothesis is true, and one try to fit a regression of the form (<a href="#eq-regression" class="quarto-xref">Equation&nbsp;7</a>) to the levels of economic time series. Suppose next that these series are not stationary, or highly autocorrelated. In such situation, the test procedure is invalid since F in(<a href="#eq-f_test" class="quarto-xref">Equation&nbsp;11</a>) is not distributed as an F-distribution under the null hypothesis (<a href="#eq-null_hypothesis" class="quarto-xref">Equation&nbsp;10</a>). In fact,under the null hypothesis, the errors or residuals from (<a href="#eq-regression" class="quarto-xref">Equation&nbsp;7</a>) is given by:</p>
<p><span class="math inline">\(\epsilon_t = Y_t - X\beta_0\)</span> ; t = 1, 2, …, T,</p>
<p>will have the same autocorrelation structure as the original series Y.</p>
<p>Some idea of the distribution problem can arise in the situation when :</p>
<p><span class="math display">\[
Y_t = \beta_0 + X_t\beta_1 + \epsilon_t
\]</span></p>
<p>where <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(X_t\)</span> follow the independent first-order autoregressive process:</p>
<p><span class="math inline">\(Y_t = \rho Y_{t-1} + \eta_t\)</span>, and <span class="math inline">\(X_t = \rho^* X_{t-1} + \nu_t\)</span></p>
<p>where <span class="math inline">\(\eta_t\)</span> and <span class="math inline">\(\nu_t\)</span> are white noise.</p>
<p>We know that in this case, <span class="math inline">\(R^2\)</span> is the square of the correlation between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(X_t\)</span>. Ils utilisent le résultat de Kendall dans l’article <span class="citation" data-cites="knowles1954exercises">Knowles (<a href="#ref-knowles1954exercises" role="doc-biblioref">1954</a>)</span> qui exprime la variance de <span class="math inline">\(R\)</span> :</p>
<p><span class="math display">\[
Var(R) = \frac{1}{T}\frac{1+\rho \rho^*}{1-\rho \rho^*}
\]</span></p>
<p>since R is constrained to lie between -1 and 1, if its variance is greater than 1/3, the distribution of R cannot have a mode at 0. This imply that <span class="math inline">\(\rho \rho^* &gt;\frac{T-1}{T+1}\)</span>. Thus, for example if T=20 and <span class="math inline">\(\rho = \rho^*\)</span>, a distribution that is not unimodal at O will be obtained if <span class="math inline">\(\rho &gt; 0.86\)</span>, and if <span class="math inline">\(\rho = 0.9\)</span>, <span class="math inline">\(var(R) = 0.47\)</span>. So the <span class="math inline">\(E(R^2)\)</span> will be close to 0.47.</p>
<p>Here’s an improved and corrected version, keeping your tone and touch while improving the fluency and clarity:</p>
<p>It has been shown that when <span class="math inline">\(\rho\)</span> is close to 1, <span class="math inline">\(R^2\)</span> can be <strong>very high</strong>, suggesting a strong relationship between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(X_t\)</span>. However, in reality, the two series are completely independent. When <span class="math inline">\(\rho\)</span> is near 1, both series behave like random walks or near-random walks. On top of that, both series are <strong>highly autocorrelated</strong>, which causes the <strong>residuals from the regression</strong> to also be strongly autocorrelated. As a result, the <strong>Durbin-Watson statistic</strong> d will be <strong>very low</strong>. This is why a high <span class="math inline">\(R^2\)</span> in this context should never be taken as evidence of a true relationship between the two series.</p>
<p>To explore the possibility of obtaining a spurious regression when regressing two independent random walks, a series of simulations proposed by <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> will be conducted in the next section.</p>
</section>
<section id="simulation-results-using-python." class="level1">
<h1>Simulation results using python.</h1>
<p>In this section, we will show using simulations that using the regression model with independent random walks bias the estimation of the coefficients and the hypothesis tests of the coefficients are invalid.</p>
<p>A regression equation proposed by <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> is given by: <span class="math display">\[
Y_t = \beta_0 + X_t\beta_1 + \epsilon_t
\]</span></p>
<p>where <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(X_t\)</span> were, in fact, generated as independent random walks each of length 50. The values <span class="math display">\[
S = \frac{\lvert \hat{\beta}_1 \rvert}{\sqrt{\hat{SE}(\hat{\beta}_1)}},
\]</span></p>
<p>representing the statistic for testing the significance of <span class="math inline">\(\beta_1\)</span>, for 100 simulations will be reported in the table below.</p>
<p>Let’s carry out the simulation using python.</p>
<div id="8e4fcf95" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> <span class="dv">100</span> </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>S <span class="op">=</span> np.zeros(M)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------------------------</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the data</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------------------------</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    espilon_y <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    espilon_x <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.cumsum(espilon_y)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.cumsum(espilon_x)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------------------------</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------------------------</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> sm.OLS(Y, X).fit()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------------------------</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the statistic</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    S[i] <span class="op">=</span> np.<span class="bu">abs</span>(model.params[<span class="dv">1</span>])<span class="op">/</span>model.bse[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="37ce2782" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------#    Maximum value of S</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>S_max <span class="op">=</span> <span class="bu">int</span>(np.ceil(<span class="bu">max</span>(S)))</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------#    Create bins</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> np.arange(<span class="dv">0</span>, S_max <span class="op">+</span> <span class="dv">2</span>, <span class="dv">1</span>)  </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------#    Compute the histogram</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>frequency, bin_edges <span class="op">=</span> np.histogram(S, bins<span class="op">=</span>bins)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------#    Create a dataframe</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"S Interval"</span>: [<span class="ss">f"</span><span class="sc">{</span><span class="bu">int</span>(bin_edges[i])<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span><span class="bu">int</span>(bin_edges[i<span class="op">+</span><span class="dv">1</span>])<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(bin_edges)<span class="op">-</span><span class="dv">1</span>)],</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Frequency"</span>: frequency</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.mean(S))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   S Interval  Frequency
0         0-1         13
1         1-2         16
2         2-3         12
3         3-4          8
4         4-5         14
5         5-6          8
6         6-7          7
7         7-8          5
8         8-9          7
9        9-10          0
10      10-11          3
11      11-12          4
12      12-13          0
13      13-14          1
14      14-15          1
15      15-16          1
16      16-17          0
4.58501785392309</code></pre>
</div>
</div>
<p>The null hypothesis of no relationship between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(X_t\)</span> is rejected at the 5% level if <span class="math inline">\(S &gt; 2\)</span>. This table shows that the null hypothesis (<span class="math inline">\(\beta =0\)</span>) is wrongly rejected in about a quarter (71 times) of all cases. This is awkward because the two variables are independent random walks, meaning there’s no actual relationship. Let’s break down why this happens.</p>
<p>If <span class="math inline">\(\frac{\hat{\beta}_1}{\hat{SE}}\)</span> follows a <span class="math inline">\(N(0,1)\)</span>, the expected value of S, its absolute value, should be <span class="math inline">\(\frac{\sqrt{2}}{\pi} \approx 0.8\)</span>( <span class="math inline">\(\frac{2}{\pi}\)</span> is the mean of the absolute value of a standard normal distribution). However, the simulation results show an average of 4.59, meaning the estimated S is underestimated by a factor of <span class="math inline">\(\frac{4.59}{0.8} = 5.7\)</span>.</p>
<p>In classical statistics, we usually use a t-test threshold of around 2 to check the significance of a coefficient. However, these results show that, in this case, you’d actually need to use a threshold of 11.4 to properly test for significancen :</p>
<p><span class="math display">\[
2\times \frac{4.59}{0.8} = 11.4.
\]</span></p>
<p>Interpretation: We’ve just shown that including variables that don’t belong in the model — especially random walks — can lead to completely invalid significance tests for the coefficients.</p>
<p>To make their simulations even clearer, <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> ran a series of regressions using variables that follow either a random walk or an ARIMA(0,1,1) process.</p>
<p>Here is how they set up their simulations:</p>
<p>They regressed a dependent series <span class="math inline">\(Y_t\)</span> on m series <span class="math inline">\(X_{j,t}\)</span> (with j = 1, 2, …, m), varying m from 1 to 5. varier m from 1 to 5. The dependent series <span class="math inline">\(Y_t\)</span> and the independent series <span class="math inline">\(X_{j,t}\)</span> follow the same types of process, and they tested four cases:</p>
<ul>
<li>Cas 1 (Levels) : <span class="math inline">\(Y_t\)</span> et <span class="math inline">\(X_{j,t}\)</span> follow random walk.</li>
<li>Cas 2 (Differences) : They use the first difference sof the random walk, which are stationary.</li>
<li>Cas 3 (Levels) : <span class="math inline">\(Y_t\)</span> et <span class="math inline">\(X_{j,t}\)</span> follow ARIMA(0,1,1).</li>
<li>Cas 4 (Differences) : They use the first differences of the previous ARIMA(0,1,1) which are stationary.</li>
</ul>
<p>Each series has a length of 50 observations, and they ran 100 simulations for each case.</p>
<p>All errors terms are distributed as <span class="math inline">\(N(0,1)\)</span> and the ARIMA(0,1,1) series are derived as the sum of the random walk and independent white noise. The simulation results, based on 100 replications with series of length 50, are summarized in the next table.</p>
<div id="d03e5b7e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.stattools <span class="im">import</span> durbin_watson</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tabulate <span class="im">import</span> tabulate</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)  <span class="co"># Pour rendre les résultats reproductibles</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Definition of functions</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_random_walk(T):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Génère une série de longueur T suivant un random walk :</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">        Y_t = Y_{t-1} + e_t,</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">    où e_t ~ N(0,1).</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    e <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>T)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.cumsum(e)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_arima_0_1_1(T):</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">    Génère un ARIMA(0,1,1) selon la méthode de Granger &amp; Newbold :</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co">    la série est obtenue en additionnant une marche aléatoire et un bruit blanc indépendant.</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    rw <span class="op">=</span> generate_random_walk(T)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    wn <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>T)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rw <span class="op">+</span> wn</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> difference(series):</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcule la différence première d'une série unidimensionnelle.</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co">    Retourne une série de longueur T-1.</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.diff(series)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Paramètres</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="co">#------------------------------------------------------</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">50</span>           <span class="co"># longueur de chaque série</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>n_sims <span class="op">=</span> <span class="dv">100</span>     <span class="co"># nombre de simulations Monte Carlo</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span>     <span class="co"># seuil de significativité</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5109d5eb" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_simulation_case(case_name, m_values<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">    case_name : un identifiant pour le type de génération :</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">        - 'rw-levels' : random walk (levels)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">        - 'rw-diffs'  : differences of RW (white noise)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">        - 'arima-levels' : ARIMA(0,1,1) en niveaux</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">        - 'arima-diffs'  : différences d'un ARIMA(0,1,1) =&gt; MA(1)</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">    m_values : liste du nombre de régresseurs.</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Retourne un DataFrame avec pour chaque m :</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">        - % de rejets de H0</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">        - Durbin-Watson moyen</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">        - R^2_adj moyen</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">        - % de R^2 &gt; 0.1</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> m <span class="kw">in</span> m_values:</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        count_reject <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        dw_list <span class="op">=</span> []</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        r2_adjusted_list <span class="op">=</span> []</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_sims):</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------------------</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) Generation of independents de Y_t and X_{j,t}.</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> case_name <span class="op">==</span> <span class="st">'rw-levels'</span>:</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>                Y <span class="op">=</span> generate_random_walk(T)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>                Xs <span class="op">=</span> [generate_random_walk(T) <span class="cf">for</span> __ <span class="kw">in</span> <span class="bu">range</span>(m)]</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> case_name <span class="op">==</span> <span class="st">'rw-diffs'</span>:</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Y et X sont les différences d'un RW, i.e. ~ white noise</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>                Y_rw <span class="op">=</span> generate_random_walk(T)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>                Y <span class="op">=</span> difference(Y_rw)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>                Xs <span class="op">=</span> []</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> __ <span class="kw">in</span> <span class="bu">range</span>(m):</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>                    X_rw <span class="op">=</span> generate_random_walk(T)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>                    Xs.append(difference(X_rw))</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>                <span class="co"># NB : maintenant Y et Xs ont longueur T-1</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>                <span class="co"># =&gt; ajuster T_effectif = T-1</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>                <span class="co"># =&gt; on prendra T_effectif points pour la régression</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> case_name <span class="op">==</span> <span class="st">'arima-levels'</span>:</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>                Y <span class="op">=</span> generate_arima_0_1_1(T)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>                Xs <span class="op">=</span> [generate_arima_0_1_1(T) <span class="cf">for</span> __ <span class="kw">in</span> <span class="bu">range</span>(m)]</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> case_name <span class="op">==</span> <span class="st">'arima-diffs'</span>:</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Différences d'un ARIMA(0,1,1) =&gt; MA(1)</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>                Y_arima <span class="op">=</span> generate_arima_0_1_1(T)</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>                Y <span class="op">=</span> difference(Y_arima)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>                Xs <span class="op">=</span> []</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> __ <span class="kw">in</span> <span class="bu">range</span>(m):</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>                    X_arima <span class="op">=</span> generate_arima_0_1_1(T)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>                    Xs.append(difference(X_arima))</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 2) Prépare les données pour la régression</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>            <span class="co">#    Selon le cas, la longueur est T ou T-1</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> case_name <span class="kw">in</span> [<span class="st">'rw-levels'</span>,<span class="st">'arima-levels'</span>]:</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>                Y_reg <span class="op">=</span> Y</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>                X_reg <span class="op">=</span> np.column_stack(Xs) <span class="cf">if</span> m<span class="op">&gt;</span><span class="dv">0</span> <span class="cf">else</span> np.array([])</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>                <span class="co"># dans les cas de différences, la longueur est T-1</span></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>                Y_reg <span class="op">=</span> Y</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>                X_reg <span class="op">=</span> np.column_stack(Xs) <span class="cf">if</span> m<span class="op">&gt;</span><span class="dv">0</span> <span class="cf">else</span> np.array([])</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 3) Régression OLS</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>            X_with_const <span class="op">=</span> sm.add_constant(X_reg)  <span class="co"># Ajout de l'ordonnée à l'origine</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sm.OLS(Y_reg, X_with_const).fit()</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 4) Test global F : H0 : tous les beta_j = 0</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>            <span class="co">#    On regarde si p-value &lt; alpha</span></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model.f_pvalue <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> model.f_pvalue <span class="op">&lt;</span> alpha:</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>                count_reject <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 5) R^2, Durbin-Watson</span></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>            r2_adjusted_list.append(model.rsquared_adj)</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>            dw_list.append(durbin_watson(model.resid))</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Statistiques sur n_sims répétitions</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>        reject_percent <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> count_reject <span class="op">/</span> n_sims</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>        dw_mean <span class="op">=</span> np.mean(dw_list)</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        r2_mean <span class="op">=</span> np.mean(r2_adjusted_list)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        r2_above_0_7_percent <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> np.mean(np.array(r2_adjusted_list) <span class="op">&gt;</span> <span class="fl">0.7</span>)</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>        results.append({</span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>            <span class="st">'m'</span>: m,</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Reject %'</span>: reject_percent,</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mean DW'</span>: dw_mean,</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Mean R^2'</span>: r2_mean,</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>            <span class="st">'% R^2_adj&gt;0.7'</span>: r2_above_0_7_percent</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3c068a3a" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>cases <span class="op">=</span> [<span class="st">'rw-levels'</span>, <span class="st">'rw-diffs'</span>, <span class="st">'arima-levels'</span>, <span class="st">'arima-diffs'</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>all_results <span class="op">=</span> {}</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> cases:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    df_res <span class="op">=</span> run_simulation_case(c, m_values<span class="op">=</span>[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>])</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    all_results[c] <span class="op">=</span> df_res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="346e7203" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> case, df_res <span class="kw">in</span> all_results.items():</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n\n</span><span class="sc">{</span>case<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(tabulate(df_res, headers<span class="op">=</span><span class="st">'keys'</span>, tablefmt<span class="op">=</span><span class="st">'fancy_grid'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>

rw-levels
╒════╤═════╤════════════╤═══════════╤════════════╤═════════════════╕
│    │   m │   Reject % │   Mean DW │   Mean R^2 │   % R^2_adj&gt;0.7 │
╞════╪═════╪════════════╪═══════════╪════════════╪═════════════════╡
│  0 │   1 │         74 │  0.33973  │   0.240534 │               4 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  1 │   2 │         86 │  0.481779 │   0.416778 │              15 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  2 │   3 │         93 │  0.561673 │   0.493484 │              23 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  3 │   4 │         98 │  0.679036 │   0.570376 │              28 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  4 │   5 │         96 │  0.800295 │   0.58997  │              35 │
╘════╧═════╧════════════╧═══════════╧════════════╧═════════════════╛


rw-diffs
╒════╤═════╤════════════╤═══════════╤═════════════╤═════════════════╕
│    │   m │   Reject % │   Mean DW │    Mean R^2 │   % R^2_adj&gt;0.7 │
╞════╪═════╪════════════╪═══════════╪═════════════╪═════════════════╡
│  0 │   1 │          5 │   1.99294 │  0.00168242 │               0 │
├────┼─────┼────────────┼───────────┼─────────────┼─────────────────┤
│  1 │   2 │          9 │   1.97273 │  0.00602094 │               0 │
├────┼─────┼────────────┼───────────┼─────────────┼─────────────────┤
│  2 │   3 │          6 │   1.95948 │  0.00387684 │               0 │
├────┼─────┼────────────┼───────────┼─────────────┼─────────────────┤
│  3 │   4 │          9 │   1.97925 │  0.00627632 │               0 │
├────┼─────┼────────────┼───────────┼─────────────┼─────────────────┤
│  4 │   5 │          2 │   1.93948 │ -0.00971288 │               0 │
╘════╧═════╧════════════╧═══════════╧═════════════╧═════════════════╛


arima-levels
╒════╤═════╤════════════╤═══════════╤════════════╤═════════════════╕
│    │   m │   Reject % │   Mean DW │   Mean R^2 │   % R^2_adj&gt;0.7 │
╞════╪═════╪════════════╪═══════════╪════════════╪═════════════════╡
│  0 │   1 │         64 │  0.698287 │   0.206495 │               2 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  1 │   2 │         73 │  0.886599 │   0.299502 │               6 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  2 │   3 │         87 │  1.03089  │   0.364599 │               6 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  3 │   4 │         94 │  1.19611  │   0.447544 │              13 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  4 │   5 │         89 │  1.26888  │   0.421604 │              19 │
╘════╧═════╧════════════╧═══════════╧════════════╧═════════════════╛


arima-diffs
╒════╤═════╤════════════╤═══════════╤════════════╤═════════════════╕
│    │   m │   Reject % │   Mean DW │   Mean R^2 │   % R^2_adj&gt;0.7 │
╞════╪═════╪════════════╪═══════════╪════════════╪═════════════════╡
│  0 │   1 │         10 │   2.6299  │ 0.00465141 │               0 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  1 │   2 │         16 │   2.55665 │ 0.0173058  │               0 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  2 │   3 │          5 │   2.59995 │ 0.00913797 │               0 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  3 │   4 │          6 │   2.5216  │ 0.0139963  │               0 │
├────┼─────┼────────────┼───────────┼────────────┼─────────────────┤
│  4 │   5 │          6 │   2.47298 │ 0.00864894 │               0 │
╘════╧═════╧════════════╧═══════════╧════════════╧═════════════════╛</code></pre>
</div>
</div>
<p>Interpretation of the results :</p>
<ul>
<li><p>It is seen that the probability of no rejecting the null hypothesis of no relationship between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(X_{j,t}\)</span> becomes very small when m&gt;=3 when regressions are made with random walk series (rw-levels). The <span class="math inline">\(R^2\)</span> and the Mean Durbin-Watson increase. Simalar results are obtained when the regressions are made with ARIMA(0,1,1) series (arima-levels).</p></li>
<li><p>When white noise series (rw-diffs) are used, classical regression analysis is valid, since the errors series will be white noise and least squares will be efficient.</p></li>
<li><p>However, when the regressions are made with the differences of ARIMA(0,1,1) series (arima-diffs) or first order moving average series MA(1) process, the null hypothesis is rejected, on average <span class="math inline">\(\frac{10+16+5+6+6}{5} = 8.6\)</span> greater than 5% of the time.</p></li>
</ul>
<p>If your variables are random walks or close to them, and you include unnecessary variables in your regression, you will often get fallacious results. High <span class="math inline">\(R^2\)</span> or <span class="math inline">\(R^2_{adjusted}\)</span> and low Durbin-Watson values do not confirm a true relationship, but instead indicate a likely spurious one.</p>
</section>
<section id="how-to-avoid-spurious-regression-in-time-series" class="level1">
<h1>How to avoid spurious regression in time series</h1>
<p>If one performs a regression analysis with time series data, and finds that the residuals are strongly autocorrelated, there is a serious problem when it comes to interpreting the coefficients of the equation. To check for autocorrelation in the residuals, one can use the Durbin-Watson test, the Ljung-Box or the Portmanteau test.</p>
<p>Based on the study above, we can conclude that if a regression analysis performed with economical variables produces strongly autocorrelated residuals, meaning to a law low Durbin-Watson statistic, then the results of the analysis are likely to be spurious whatever the value of the coefficient of determination <span class="math inline">\(R^2\)</span> observed.</p>
<p>In such cases, it is important to understand where is the mis-specification comes from. According to the litterature, mis-specification usually falls into three categories : (i) the omission of a relevant variable, (ii) the inclusion of an irrelevant variable, or (iii) autocorrelation of the errors. Most of the time, mis-specification comes from a mix of these three sources.</p>
<p>To avoid spurious regression in time series, several recommendations can be made:</p>
<ul>
<li><p>The first recommendation is to select the right macroeconomic variables that are likely to explain the dependent variable. This can be done by reviewing the literature or consulting experts in the field.</p></li>
<li><p>The second recommendation is to stationarize the series by taking first differences. In most cases, the first differences of macroeconomic variables are stationary and still easy to interpret. For macroeconomic data, it’s strongly recommended to difference the series once to reduce the autocorrelation of the residuals, especially when the sample size is small. There is indeed sometimes strong serial correlation observed in these variables. A simple calculation shows that the first differences will almost always have much smaller serial correlations than the original series.</p></li>
<li><p>The third recommendation is to use the Box-Jenkins methodology to model each macroeconomic variable individually, and then search for relationships between the series by relating the residuals from each individual model. The idea here is that the Box-Jenkins process extracts the explained part of the series, leaving the residuals, which contain only what can’t be explained by the series’ own past behavior. This makes it easier to check whether these unexplained parts (residuals) are related across variables.</p></li>
</ul>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Many econometrics textbooks warn about specification errors in regression models, but the problem still shows up in many published papers. <span class="citation" data-cites="granger1974spurious">Granger and Newbold (<a href="#ref-granger1974spurious" role="doc-biblioref">1974</a>)</span> highlighted the risk of spurious regressions, where you get a high paired with very low Durbin-Watson statistics.</p>
<p>Using Python simulations, we showed some of the main causes of these spurious regressions, especially including variables that don’t belong in the model and are highly autocorrelated. We also demonstrated how these issues can completely distort hypothesis tests on the coefficients.</p>
<p>Hopefully, this post will help reduce the risk of spurious regressions in future econometric analyses.</p>



</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-granger1974spurious" class="csl-entry" role="listitem">
Granger, Clive WJ, and Paul Newbold. 1974. <span>“Spurious Regressions in Econometrics.”</span> <em>Journal of Econometrics</em> 2 (2): 111–20.
</div>
<div id="ref-knowles1954exercises" class="csl-entry" role="listitem">
Knowles, EAG. 1954. <span>“Exercises in Theoretical Statistics.”</span> Oxford University Press.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/Jumbong\.github\.io\/personal-website\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>